"""
VAE-based models for single-cell RNA sequencing data using odds ratio
unconstrained parameterization.

This parameterization differs from the standard parameterization in that the
mean parameter (mu) is linked to the odds ratio parameter (phi) through the
relationship:
    r = mu * phi
where r is the dispersion parameter.

The VAE architecture generates cell-specific mu parameters from a
low-dimensional latent space, while keeping the global parameter phi
interpretable. This allows for modeling cell-to-cell heterogeneity while
maintaining the interpretability of the odds ratio parameterization.

The VAE architecture consists of:
    1. A global parameter phi sampled in unconstrained space and transformed via
       exponential to (0, ∞)
    2. A latent variable z sampled from a standard Normal prior
    3. A decoder network that maps z to cell-specific mu parameters
    4. The odds ratio relationship that computes r from mu and phi

This approach allows for modeling cell-to-cell heterogeneity in mean expression
while maintaining interpretable global parameters. The VAE learns meaningful
representations of the data in the latent space, which can be useful for
downstream analysis tasks such as clustering and visualization.

Parameters are sampled in unconstrained space using Normal distributions and
transformed to their constrained spaces via appropriate transformations.
"""

import jax
import jax.numpy as jnp
import jax.scipy as jsp
import numpyro
import numpyro.distributions as dist
from numpyro.distributions import constraints
from numpyro.contrib.module import nnx_module
from typing import Dict, Optional

from .model_config import ModelConfig
from ..vae.architectures import (
    Encoder,
    EncoderVCP,
    Decoder,
    VAE,
    DecoupledPrior,
    DecoupledPriorDistribution,
)
from ..stats import BetaPrime

# ------------------------------------------------------------------------------
# NBDM VAE Model
# ------------------------------------------------------------------------------


def nbdm_vae_model(
    n_cells: int,
    n_genes: int,
    model_config: ModelConfig,
    decoder: Decoder,  # Pre-created decoder passed as argument
    counts=None,
    batch_size=None,
):
    """
    Implements the VAE-based Negative Binomial-Dirichlet Multinomial (NBDM)
    model using an odds ratio unconstrained parameterization suitable for
    variational inference in single-cell RNA sequencing data.

    This model extends the standard NBDM model by incorporating a Variational
    Autoencoder (VAE) architecture. The VAE generates cell-specific mean
    parameters (mu) from a low-dimensional latent space, while maintaining the
    global odds ratio parameter (phi) as an interpretable global parameter. The
    dispersion parameter r is linked to mu and phi through the relationship:

        r = mu * phi

    where:
        - mu > 0 is the mean expression for each cell and gene (generated by
          VAE),
        - phi > 0 is the global odds ratio parameter that controls dispersion,
        - r > 0 is the dispersion parameter.

    The model architecture consists of:
        1. A global parameter phi sampled in unconstrained space and transformed
           via exponential to (0, ∞)
        2. A latent variable z sampled from a standard Normal prior
        3. A decoder network that maps z to cell-specific mu parameters
        4. The odds ratio relationship that computes r from mu and phi

    For each cell, the observed counts vector (of length n_genes) is modeled as:

        counts[cell, :] ~ NegativeBinomialLogits(r[cell, :], -log(phi))

    where r[cell, :] is computed from the VAE-generated mu[cell, :] and the
    global parameter phi, and the NegativeBinomialLogits distribution uses the
    logits parameter -log(phi).

    The VAE architecture allows the model to:
        - Capture cell-to-cell heterogeneity in mean expression parameters
        - Learn meaningful low-dimensional representations of the data
        - Maintain interpretability through global parameters
        - Scale to large datasets through efficient latent space modeling

    The model supports optional batching over cells for scalable inference. If
    `counts` is provided, it is used as observed data; otherwise, the model
    samples counts from the generative process.

    Parameters
    ----------
    n_cells: int
        Number of cells in the dataset.
    n_genes: int
        Number of genes (features) per cell.
    model_config: ModelConfig
        ModelConfig object specifying prior parameters and VAE configuration.
    decoder: Decoder
        Pre-trained decoder network that maps latent variables to mu parameters.
    counts: Optional[jnp.ndarray], default=None
        Observed count data (not used in the model, but included for interface
        compatibility).
    batch_size: Optional[int], default=None
        If specified, enables subsampling of cells for stochastic variational
        inference.

    Returns
    -------
    None
        This function defines the probabilistic model for use with NumPyro.
    """
    # Define prior parameters for unconstrained variables
    phi_prior_params = model_config.phi_unconstrained_prior or (0.0, 1.0)

    # Sample unconstrained parameters
    phi_unconstrained = numpyro.sample(
        "phi_unconstrained", dist.Normal(*phi_prior_params)
    )

    # Transform to constrained space
    phi = numpyro.deterministic("phi", jnp.exp(phi_unconstrained))

    # Register the pre-created decoder as NumPyro module
    decoder_module = nnx_module("decoder", decoder)

    # Sample counts
    if counts is not None:
        if batch_size is None:
            # Without batching: sample counts for all cells
            with numpyro.plate("cells", n_cells):
                # Sample from latent space prior
                z = numpyro.sample(
                    "z",
                    dist.Normal(0, 1)
                    .expand([model_config.vae_latent_dim])
                    .to_event(1),
                )

                # Use decoder to generate mu parameters from latent space
                mu_unconstrained = numpyro.deterministic(
                    "mu_unconstrained", decoder_module(z)
                )
                mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

                # Compute r using the odds ratio parameterization
                r = numpyro.deterministic("r", mu * phi)

                # Define base distribution with VAE-generated r
                base_dist = dist.NegativeBinomialLogits(
                    r, -jnp.log(phi)
                ).to_event(1)
                numpyro.sample("counts", base_dist, obs=counts)
        else:
            # With batching: sample counts for a subset of cells
            with numpyro.plate(
                "cells", n_cells, subsample_size=batch_size
            ) as idx:
                # Sample from latent space prior
                z = numpyro.sample(
                    "z",
                    dist.Normal(0, 1)
                    .expand([model_config.vae_latent_dim])
                    .to_event(1),
                )

                # Use decoder to generate mu parameters from latent space
                mu_unconstrained = numpyro.deterministic(
                    "mu_unconstrained", decoder_module(z)
                )
                mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

                # Compute r using the odds ratio parameterization
                r = numpyro.deterministic("r", mu * phi)

                # Define base distribution with VAE-generated r
                base_dist = dist.NegativeBinomialLogits(
                    r, -jnp.log(phi)
                ).to_event(1)
                numpyro.sample("counts", base_dist, obs=counts[idx])
    else:
        # Without counts: for prior predictive sampling
        with numpyro.plate("cells", n_cells):
            # Sample from latent space prior
            z = numpyro.sample(
                "z",
                dist.Normal(0, 1)
                .expand([model_config.vae_latent_dim])
                .to_event(1),
            )

            # Use decoder to generate mu parameters from latent space
            mu_unconstrained = numpyro.deterministic(
                "mu_unconstrained", decoder_module(z)
            )
            mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

            # Compute r using the odds ratio parameterization
            r = numpyro.deterministic("r", mu * phi)

            # Define base distribution with VAE-generated r
            base_dist = dist.NegativeBinomialLogits(r, -jnp.log(phi)).to_event(
                1
            )
            numpyro.sample("counts", base_dist)

# ------------------------------------------------------------------------------
# NBDM VAE Guide
# ------------------------------------------------------------------------------


def nbdm_vae_guide(
    n_cells: int,
    n_genes: int,
    model_config: ModelConfig,
    encoder: Encoder,  # Pre-created encoder passed as argument
    counts=None,
    batch_size=None,
):
    """
    Mean-field variational guide for the VAE-based NBDM model with odds ratio
    unconstrained parameterization.

    This guide defines a variational approximation for the VAE-based NBDM model,
    which combines the benefits of variational inference with the
    interpretability of the odds ratio parameterization. The guide approximates
    the posterior distribution of the model parameters using a mean-field
    factorization.

    The variational family consists of:
        1. A global parameter phi_unconstrained with learnable location and
           scale
        2. Cell-specific latent variables z with encoder-derived parameters
        3. The encoder network that maps observed counts to latent space
           parameters

    The guide architecture:
        - phi_unconstrained ~ Normal(phi_loc, phi_scale) where phi_loc and
          phi_scale are learnable parameters
        - z[cell] ~ Normal(z_mean[cell], z_std[cell]) where z_mean and z_std are
          computed by the encoder network from the observed counts

    The encoder network takes the observed gene expression counts for each cell
    and outputs the mean and log-variance of the approximate posterior for the
    latent variable z. This allows the model to learn a meaningful
    representation of the data in the latent space while maintaining the
    interpretability of the global parameter phi.

    The VAE architecture provides several advantages:
        - Efficient learning of complex, non-linear relationships in the data
        - Automatic feature extraction and dimensionality reduction
        - Scalable inference through amortized variational inference
        - Meaningful latent representations for downstream analysis
        - Modeling of cell-to-cell heterogeneity through learned representations

    The guide supports optional batching over cells for scalable inference. When
    batching is enabled, the encoder processes only a subset of cells at a time,
    making it suitable for large datasets.

    Parameters
    ----------
    n_cells : int
        Number of cells (samples) in the dataset.
    n_genes : int
        Number of genes (features) in the dataset.
    model_config : ModelConfig
        Configuration object containing prior and guide parameter settings.
    encoder : Encoder
        Pre-trained encoder network that maps observed counts to latent space
        parameters.
    counts : Optional[jnp.ndarray], default=None
        Observed count data used by the encoder to compute latent space
        parameters.
    batch_size : Optional[int], default=None
        If specified, enables subsampling of cells for stochastic variational
        inference.

    Returns
    -------
    None
        This function defines the variational guide for use with NumPyro's
        inference machinery.
    """
    # Define guide parameters for unconstrained variables
    phi_guide_params = model_config.phi_unconstrained_guide or (0.0, 1.0)

    # Register unconstrained phi parameters
    phi_loc = numpyro.param("phi_unconstrained_loc", phi_guide_params[0])
    phi_scale = numpyro.param(
        "phi_unconstrained_scale",
        phi_guide_params[1],
        constraint=constraints.positive,
    )
    numpyro.sample("phi_unconstrained", dist.Normal(phi_loc, phi_scale))

    # Register the pre-created encoder as NumPyro module for the guide
    encoder_module = nnx_module("encoder", encoder)

    # Sample latent variables using encoder
    if counts is not None:
        if batch_size is None:
            # Without batching: sample latent variables for all cells
            with numpyro.plate("cells", n_cells):
                # Use encoder to get mean and log variance for latent space
                z_mean, z_logvar = encoder_module(counts)
                z_std = jnp.exp(0.5 * z_logvar)

                # Sample from variational distribution
                numpyro.sample("z", dist.Normal(z_mean, z_std).to_event(1))
        else:
            # With batching: sample latent variables for a subset of cells
            with numpyro.plate(
                "cells", n_cells, subsample_size=batch_size
            ) as idx:
                # Use encoder to get mean and log variance for latent space
                batch_data = counts[idx]
                z_mean, z_logvar = encoder_module(batch_data)
                z_std = jnp.exp(0.5 * z_logvar)

                # Sample from variational distribution
                numpyro.sample("z", dist.Normal(z_mean, z_std).to_event(1))
    else:
        # Without counts: for prior predictive sampling
        with numpyro.plate("cells", n_cells):
            # Sample from latent space prior
            numpyro.sample(
                "z",
                dist.Normal(0, 1)
                .expand([model_config.vae_latent_dim])
                .to_event(1),
            )

# ------------------------------------------------------------------------------
# NBVCP VAE Model
# ------------------------------------------------------------------------------


def nbvcp_vae_model(
    n_cells: int,
    n_genes: int,
    model_config: ModelConfig,
    decoder: Decoder,  # Pre-created decoder passed as argument
    counts=None,
    batch_size=None,
):
    """
    Implements the VAE-based Negative Binomial model with variable mRNA capture
    probability (NBVCP) using an odds ratio unconstrained parameterization
    suitable for variational inference in single-cell RNA sequencing data.

    This model extends the standard NBVCP model by incorporating a Variational
    Autoencoder (VAE) architecture. The VAE generates cell-specific mean
    parameters (mu) from a low-dimensional latent space, while maintaining the
    global odds ratio parameter (phi) and cell-specific capture probabilities
    (phi_capture) as interpretable parameters. The dispersion parameter r is
    linked to mu and phi through the relationship:

        r = mu * phi

    where:
        - mu > 0 is the mean expression for each cell and gene (generated by
          VAE),
        - phi > 0 is the global odds ratio parameter that controls dispersion,
        - r > 0 is the dispersion parameter.

    The model introduces a cell-specific mRNA capture probability phi_capture >
    0, which modifies the effective success probability for each cell and gene.
    The effective success probability for cell i and gene j is:

        p_hat[i, j] = 1 / (1 + phi + phi * phi_capture[i])

    The model architecture consists of:
        1. Global parameters phi and phi_capture sampled in unconstrained space
        2. A latent variable z sampled from a standard Normal prior
        3. A decoder network that maps z to cell-specific mu parameters
        4. The odds ratio relationship that computes r from mu and phi
        5. Cell-specific capture probabilities that modify the effective success
           probability

    For each cell, the observed counts vector (of length n_genes) is modeled as:

        counts[cell, :] ~ NegativeBinomialProbs(r[cell, :], p_hat[cell, :])

    where r[cell, :] is computed from the VAE-generated mu[cell, :] and the
    global parameter phi, and p_hat[cell, :] incorporates the cell-specific
    capture probability.

    The VAE architecture allows the model to:
        - Capture cell-to-cell heterogeneity in mean expression parameters
        - Model technical variation through cell-specific capture probabilities
        - Learn meaningful low-dimensional representations of the data
        - Maintain interpretability through global and cell-specific parameters
        - Scale to large datasets through efficient latent space modeling

    The model supports optional batching over cells for scalable inference. If
    `counts` is provided, it is used as observed data; otherwise, the model
    samples counts from the generative process.

    Parameters
    ----------
    n_cells : int
        Number of cells in the dataset.
    n_genes : int
        Number of genes (features) per cell.
    model_config : ModelConfig
        ModelConfig object specifying prior parameters and VAE configuration.
    decoder : Decoder
        Pre-trained decoder network that maps latent variables to mu parameters.
    counts : Optional[jnp.ndarray], default=None
        Observed count data (not used in the model, but included for interface
        compatibility).
    batch_size : Optional[int], default=None
        If specified, enables subsampling of cells for stochastic variational
        inference.

    Returns
    -------
    None
        This function defines the probabilistic model for use with NumPyro.
    """
    # Define prior parameters for unconstrained variables
    phi_prior_params = model_config.phi_unconstrained_prior or (0.0, 1.0)
    phi_capture_prior_params = model_config.phi_capture_unconstrained_prior or (
        0.0,
        1.0,
    )

    # Sample unconstrained parameters
    phi_unconstrained = numpyro.sample(
        "phi_unconstrained", dist.Normal(*phi_prior_params)
    )

    # Transform to constrained space
    phi = numpyro.deterministic("phi", jnp.exp(phi_unconstrained))

    # Register the pre-created decoder as NumPyro module
    decoder_module = nnx_module("decoder", decoder)

    # Sample counts
    if counts is not None:
        if batch_size is None:
            # Without batching: sample counts for all cells
            with numpyro.plate("cells", n_cells):
                # Sample from latent space prior
                z = numpyro.sample(
                    "z",
                    dist.Normal(0, 1)
                    .expand([model_config.vae_latent_dim])
                    .to_event(1),
                )

                # Use decoder to generate mu parameters from latent space
                mu_unconstrained = numpyro.deterministic(
                    "mu_unconstrained", decoder_module(z)
                )
                mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

                # Compute r using the odds ratio parameterization
                r = numpyro.deterministic("r", mu * phi)

                # Sample cell-specific capture probability from unconstrained
                # prior
                phi_capture_unconstrained = numpyro.sample(
                    "phi_capture_unconstrained",
                    dist.Normal(*phi_capture_prior_params),
                )
                # Transform to constrained space
                phi_capture = numpyro.deterministic(
                    "phi_capture", jnp.exp(phi_capture_unconstrained)
                )
                # Reshape phi_capture for broadcasting to (n_cells, n_genes)
                phi_capture_reshaped = phi_capture[:, None]
                # Compute p_hat using the derived formula
                p_hat = numpyro.deterministic(
                    "p_hat", 1.0 / (1 + phi + phi * phi_capture_reshaped)
                )

                # Define base distribution with VAE-generated r
                base_dist = dist.NegativeBinomialProbs(r, p_hat).to_event(1)
                numpyro.sample("counts", base_dist, obs=counts)
        else:
            # With batching: sample counts for a subset of cells
            with numpyro.plate(
                "cells", n_cells, subsample_size=batch_size
            ) as idx:
                # Sample from latent space prior
                z = numpyro.sample(
                    "z",
                    dist.Normal(0, 1)
                    .expand([model_config.vae_latent_dim])
                    .to_event(1),
                )

                # Use decoder to generate mu parameters from latent space
                mu_unconstrained = numpyro.deterministic(
                    "mu_unconstrained", decoder_module(z)
                )
                mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

                # Compute r using the odds ratio parameterization
                r = numpyro.deterministic("r", mu * phi)

                # Sample cell-specific capture probability from unconstrained
                # prior
                phi_capture_unconstrained = numpyro.sample(
                    "phi_capture_unconstrained",
                    dist.Normal(*phi_capture_prior_params),
                )
                # Transform to constrained space
                phi_capture = numpyro.deterministic(
                    "phi_capture", jnp.exp(phi_capture_unconstrained)
                )
                # Reshape phi_capture for broadcasting to (n_cells, n_genes)
                phi_capture_reshaped = phi_capture[:, None]
                # Compute p_hat using the derived formula
                p_hat = numpyro.deterministic(
                    "p_hat", 1.0 / (1 + phi + phi * phi_capture_reshaped)
                )

                # Define base distribution with VAE-generated r
                base_dist = dist.NegativeBinomialProbs(r, p_hat).to_event(1)
                numpyro.sample("counts", base_dist, obs=counts[idx])
    else:
        # Without counts: for prior predictive sampling
        with numpyro.plate("cells", n_cells):
            # Sample from latent space prior
            z = numpyro.sample(
                "z",
                dist.Normal(0, 1)
                .expand([model_config.vae_latent_dim])
                .to_event(1),
            )

            # Use decoder to generate mu parameters from latent space
            mu_unconstrained = numpyro.deterministic(
                "mu_unconstrained", decoder_module(z)
            )
            mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

            # Compute r using the odds ratio parameterization
            r = numpyro.deterministic("r", mu * phi)

            # Sample cell-specific capture probability from unconstrained prior
            phi_capture_unconstrained = numpyro.sample(
                "phi_capture_unconstrained",
                dist.Normal(*phi_capture_prior_params),
            )
            # Transform to constrained space
            phi_capture = numpyro.deterministic(
                "phi_capture", jnp.exp(phi_capture_unconstrained)
            )
            # Reshape p_capture for broadcasting to (n_cells, n_genes)
            phi_capture_reshaped = phi_capture[:, None]
            # Compute p_hat using the derived formula
            p_hat = numpyro.deterministic(
                "p_hat", 1.0 / (1 + phi + phi * phi_capture_reshaped)
            )

            # Define base distribution with VAE-generated r
            base_dist = dist.NegativeBinomialProbs(r, p_hat).to_event(1)
            numpyro.sample("counts", base_dist)


# ------------------------------------------------------------------------------
# NBVCP VAE Guide
# ------------------------------------------------------------------------------


def nbvcp_vae_guide(
    n_cells: int,
    n_genes: int,
    model_config: ModelConfig,
    encoder: Encoder,  # Pre-created encoder passed as argument
    counts=None,
    batch_size=None,
):
    """
    Mean-field variational guide for the VAE-based NBVCP model with odds ratio
    unconstrained parameterization.

    This guide defines a variational approximation for the VAE-based NBVCP
    model, which combines the benefits of variational inference with the
    interpretability of the odds ratio parameterization and cell-specific
    capture probabilities. The guide approximates the posterior distribution of
    the model parameters using a mean-field factorization.

    The variational family consists of:
        1. A global parameter phi_unconstrained with learnable location and
           scale
        2. Cell-specific latent variables z with encoder-derived parameters
        3. Cell-specific capture probability parameters phi_capture with
           encoder-derived parameters
        4. The encoder network that maps observed counts to latent space and
           capture parameters

    The guide architecture:
        - phi_unconstrained ~ Normal(phi_loc, phi_scale) where phi_loc and
          phi_scale are learnable parameters
        - z[cell] ~ Normal(z_mean[cell], z_std[cell]) where z_mean and z_std are
          computed by the encoder network from the observed counts
        - phi_capture_unconstrained[cell] ~ Normal(phi_capture_loc[cell],
          phi_capture_scale[cell]) where the parameters are computed by the
          encoder network

    The encoder network takes the observed gene expression counts for each cell
    and outputs:
        1. The mean and log-variance of the approximate posterior for the latent
           variable z
        2. The location and scale parameters for the cell-specific capture
           probabilities

    This allows the model to learn meaningful representations of the data in the
    latent space while maintaining the interpretability of the global parameter
    phi and capturing cell-specific technical effects through phi_capture.

    The VAE architecture provides several advantages:
        - Efficient learning of complex, non-linear relationships in the data
        - Automatic feature extraction and dimensionality reduction
        - Scalable inference through amortized variational inference
        - Meaningful latent representations for downstream analysis
        - Modeling of cell-to-cell heterogeneity through learned representations
        - Modeling of technical variation through capture probabilities

    The guide supports optional batching over cells for scalable inference. When
    batching is enabled, the encoder processes only a subset of cells at a time,
    making it suitable for large datasets.

    Parameters
    ----------
    n_cells : int
        Number of cells (samples) in the dataset.
    n_genes : int
        Number of genes (features) in the dataset.
    model_config : ModelConfig
        Configuration object containing prior and guide parameter settings.
    encoder : Encoder
        Pre-trained encoder network that maps observed counts to latent space
        parameters and capture probability parameters.
    counts : Optional[jnp.ndarray], default=None
        Observed count data used by the encoder to compute latent space and
        capture probability parameters.
    batch_size : Optional[int], default=None
        If specified, enables subsampling of cells for stochastic variational
        inference.

    Returns
    -------
    None
        This function defines the variational guide for use with NumPyro's
        inference machinery.
    """
    # Define guide parameters for unconstrained variables
    phi_guide_params = model_config.phi_unconstrained_guide or (0.0, 1.0)

    # Register unconstrained phi parameters
    phi_loc = numpyro.param("phi_unconstrained_loc", phi_guide_params[0])
    phi_scale = numpyro.param(
        "phi_unconstrained_scale",
        phi_guide_params[1],
        constraint=constraints.positive,
    )
    numpyro.sample("phi_unconstrained", dist.Normal(phi_loc, phi_scale))

    # Register the pre-created encoder as NumPyro module for the guide
    encoder_module = nnx_module("encoder", encoder)

    # Sample latent variables using encoder
    if counts is not None:
        if batch_size is None:
            # Without batching: sample latent variables for all cells
            with numpyro.plate("cells", n_cells):
                # Use encoder to get mean and log variance for latent space
                (
                    z_mean,
                    z_logvar,
                    phi_capture_loc,
                    phi_capture_logscale,
                ) = encoder_module(counts)
                z_std = jnp.exp(0.5 * z_logvar)

                # Sample from variational distribution
                numpyro.sample("z", dist.Normal(z_mean, z_std).to_event(1))

                # Sample cell-specific capture probability from unconstrained
                # guide
                numpyro.sample(
                    "phi_capture_unconstrained",
                    dist.Normal(
                        phi_capture_loc.squeeze(-1),
                        jnp.exp(phi_capture_logscale.squeeze(-1)),
                    ),
                )
        else:
            # With batching: sample latent variables for a subset of cells
            with numpyro.plate(
                "cells", n_cells, subsample_size=batch_size
            ) as idx:
                # Use encoder to get mean and log variance for latent space
                batch_data = counts[idx]
                (
                    z_mean,
                    z_logvar,
                    phi_capture_loc,
                    phi_capture_logscale,
                ) = encoder_module(batch_data)
                z_std = jnp.exp(0.5 * z_logvar)

                # Sample from variational distribution
                numpyro.sample("z", dist.Normal(z_mean, z_std).to_event(1))

                # Sample cell-specific capture probability from unconstrained
                # guide
                numpyro.sample(
                    "phi_capture_unconstrained",
                    dist.Normal(
                        phi_capture_loc.squeeze(-1),
                        jnp.exp(phi_capture_logscale.squeeze(-1)),
                    ),
                )
    else:
        # Without counts: for prior predictive sampling
        with numpyro.plate("cells", n_cells):
            phi_capture_prior_params = (
                model_config.phi_capture_unconstrained_prior
                or (
                    0.0,
                    1.0,
                )
            )
            # Sample from latent space prior
            numpyro.sample(
                "z",
                dist.Normal(0, 1)
                .expand([model_config.vae_latent_dim])
                .to_event(1),
            )

            # Sample cell-specific capture probability from Beta prior
            numpyro.sample(
                "phi_capture_unconstrained",
                dist.Normal(*phi_capture_prior_params),
            )

# ==============================================================================
# dpVAE Model Functions (for decoupled prior)
# ==============================================================================

# ------------------------------------------------------------------------------
# NBDM dpVAE Model
# ------------------------------------------------------------------------------


def nbdm_dpvae_model(
    n_cells: int,
    n_genes: int,
    model_config: ModelConfig,
    decoder: Decoder,
    decoupled_prior: DecoupledPrior,
    counts=None,
    batch_size=None,
):
    """
    Implements the decoupled prior VAE (dpVAE) model for Negative
    Binomial-Dirichlet Multinomial (NBDM) data using an odds ratio unconstrained
    parameterization.

    This model extends the standard VAE-based NBDM model by incorporating a
    decoupled prior architecture, which allows for more flexible and expressive
    prior distributions over the latent space. The key innovation is the use of
    a DecoupledPriorDistribution that combines a base distribution with a
    learned prior network.

    The model maintains the odds ratio parameterization where the dispersion
    parameter r is related to the mean (mu) and odds ratio parameter (phi)
    through:

        r = mu * phi

    where:
        - mu > 0 is the mean expression for each cell and gene (generated by
          VAE),
        - phi > 0 is the global odds ratio parameter that controls dispersion,
        - r > 0 is the dispersion parameter.

    The model architecture consists of:
        1. Global parameters phi and mu sampled in unconstrained space
        2. A latent variable z sampled from a decoupled prior distribution
        3. A decoder network that maps z to cell-specific mu parameters
        4. The odds ratio relationship that computes r from mu and phi
        5. A decoupled prior network that learns flexible prior distributions

    The decoupled prior combines a standard Normal base distribution with a
    learned prior network that can adapt to the structure of the data, providing
    more expressive modeling capabilities than standard VAEs.

    For each cell, the observed counts vector (of length n_genes) is modeled as:

        counts[cell, :] ~ NegativeBinomialLogits(r[cell, :], -log(phi))

    where r[cell, :] is computed from the VAE-generated mu[cell, :] and the
    global parameter phi, and the NegativeBinomialLogits distribution uses the
    logits parameter -log(phi).

    The decoupled prior architecture provides several advantages:
        - More flexible and expressive prior distributions
        - Better adaptation to the structure of the data
        - Improved posterior approximation quality
        - Enhanced latent space representations
        - Better handling of complex data distributions

    The model supports optional batching over cells for scalable inference. If
    `counts` is provided, it is used as observed data; otherwise, the model
    samples counts from the generative process.

    Parameters
    ----------
    n_cells : int
        Number of cells in the dataset.
    n_genes : int
        Number of genes (features) per cell.
    model_config : ModelConfig
        ModelConfig object specifying prior parameters and VAE configuration.
    decoder : Decoder
        Pre-trained decoder network that maps latent variables to mu parameters.
    decoupled_prior : DecoupledPrior
        Pre-trained decoupled prior network that learns flexible prior
        distributions.
    counts : Optional[jnp.ndarray], default=None
        Observed count data (not used in the model, but included for interface
        compatibility).
    batch_size : Optional[int], default=None
        If specified, enables subsampling of cells for stochastic variational
        inference.

    Returns
    -------
    None
        This function defines the probabilistic model for use with NumPyro.
    """
    # Define prior parameters for unconstrained variables
    phi_prior_params = model_config.phi_unconstrained_prior or (0.0, 1.0)
    mu_prior_params = model_config.mu_unconstrained_prior or (0.0, 1.0)

    # Sample unconstrained parameters
    phi_unconstrained = numpyro.sample(
        "phi_unconstrained", dist.Normal(*phi_prior_params)
    )
    phi = numpyro.deterministic("phi", jnp.exp(phi_unconstrained))

    # Register the decoder and decoupled prior as NumPyro modules
    decoder_module = nnx_module("decoder", decoder)
    decoupled_prior_module = nnx_module("decoupled_prior", decoupled_prior)

    # Create the decoupled prior distribution
    base_distribution = dist.Normal(
        jnp.zeros(model_config.vae_latent_dim),
        jnp.ones(model_config.vae_latent_dim),
    ).to_event(1)
    decoupled_prior_dist = DecoupledPriorDistribution(
        decoupled_prior=decoupled_prior_module,
        base_distribution=base_distribution,
    )

    # Sample latent variables and generate observations
    if counts is not None:
        if batch_size is None:
            with numpyro.plate("cells", n_cells):
                # Sample z from decoupled prior (KEY DIFFERENCE from standard
                # VAE)
                z = numpyro.sample("z", decoupled_prior_dist)

                # Use decoder to generate mu parameters from latent space
                mu_unconstrained = numpyro.deterministic(
                    "mu_unconstrained", decoder_module(z)
                )

                # Compute mu from log_mu
                mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

                # Compute r using the linked parameterization
                r = numpyro.deterministic("r", mu * phi)

                # Define base distribution with VAE-generated r
                base_dist = dist.NegativeBinomialLogits(
                    r, -jnp.log(phi)
                ).to_event(1)
                # Sample counts from the base distribution
                numpyro.sample("counts", base_dist, obs=counts)
        else:
            with numpyro.plate(
                "cells", n_cells, subsample_size=batch_size
            ) as idx:
                # Sample z from decoupled prior
                z = numpyro.sample("z", decoupled_prior_dist)

                # Use decoder to generate mu parameters from latent space
                mu_unconstrained = numpyro.deterministic(
                    "mu_unconstrained", decoder_module(z)
                )

                # Compute mu from log_mu
                mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

                # Compute r using the linked parameterization
                r = numpyro.deterministic("r", mu * phi)

                # Sample observed counts from the base distribution
                batch_counts = counts[idx] if counts is not None else None
                numpyro.sample(
                    "counts",
                    dist.NegativeBinomialLogits(r, -jnp.log(phi)).to_event(1),
                    obs=batch_counts,
                )
    else:
        # Without counts: for prior predictive sampling
        with numpyro.plate("cells", n_cells):
            # Sample from latent space prior
            z = numpyro.sample("z", decoupled_prior_dist)

            # Use decoder to generate mu parameters from latent space
            mu_unconstrained = numpyro.deterministic(
                "mu_unconstrained", decoder_module(z)
            )

            mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

            # Compute r using the linked parameterization
            r = numpyro.deterministic("r", mu * phi)

            # Define base distribution with VAE-generated r
            base_dist = dist.NegativeBinomialLogits(
                r, -jnp.log(phi)
            ).to_event(1)
            numpyro.sample("counts", base_dist)


# ------------------------------------------------------------------------------
# NBVCP dpVAE Model
# ------------------------------------------------------------------------------


def nbvcp_dpvae_model(
    n_cells: int,
    n_genes: int,
    model_config: ModelConfig,
    decoder: Decoder,
    decoupled_prior: DecoupledPrior,
    counts=None,
    batch_size=None,
):
    """
    Implements the decoupled prior VAE (dpVAE) model for Negative Binomial with
    variable mRNA capture probability (NBVCP) using an odds ratio unconstrained
    parameterization.

    This model extends the standard VAE-based NBVCP model by incorporating a
    decoupled prior architecture, which allows for more flexible and expressive
    prior distributions over the latent space. The key innovation is the use of
    a DecoupledPriorDistribution that combines a base distribution with a
    learned prior network.

    The model maintains the odds ratio parameterization where the dispersion
    parameter r is related to the mean (mu) and odds ratio parameter (phi)
    through:

        r = mu * phi

    where:
        - mu > 0 is the mean expression for each cell and gene (generated by
          VAE),
        - phi > 0 is the global odds ratio parameter that controls dispersion,
        - r > 0 is the dispersion parameter.

    The model introduces a cell-specific mRNA capture probability phi_capture >
    0, which modifies the effective success probability for each cell and gene.
    The effective success probability for cell i and gene j is:

        p_hat[i, j] = 1 / (1 + phi + phi * phi_capture[i])

    The model architecture consists of:
        1. Global parameters phi and phi_capture sampled in unconstrained space
        2. A latent variable z sampled from a decoupled prior distribution
        3. A decoder network that maps z to cell-specific mu parameters
        4. The odds ratio relationship that computes r from mu and phi
        5. Cell-specific capture probabilities that modify the effective success
           probability
        6. A decoupled prior network that learns flexible prior distributions

    The decoupled prior combines a standard Normal base distribution with a
    learned prior network that can adapt to the structure of the data, providing
    more expressive modeling capabilities than standard VAEs.

    For each cell, the observed counts vector (of length n_genes) is modeled as:

        counts[cell, :] ~ NegativeBinomialProbs(r[cell, :], p_hat[cell, :])

    where r[cell, :] is computed from the VAE-generated mu[cell, :] and the
    global parameter phi, and p_hat[cell, :] incorporates the cell-specific
    capture probability.

    The decoupled prior architecture provides several advantages:
        - More flexible and expressive prior distributions
        - Better adaptation to the structure of the data
        - Improved posterior approximation quality
        - Enhanced latent space representations
        - Better handling of complex data distributions
        - Modeling of technical variation through capture probabilities

    The model supports optional batching over cells for scalable inference. If
    `counts` is provided, it is used as observed data; otherwise, the model
    samples counts from the generative process.

    Parameters
    ----------
    n_cells : int
        Number of cells in the dataset.
    n_genes : int
        Number of genes (features) per cell.
    model_config : ModelConfig
        ModelConfig object specifying prior parameters and VAE configuration.
    decoder : Decoder
        Pre-trained decoder network that maps latent variables to mu parameters.
    decoupled_prior : DecoupledPrior
        Pre-trained decoupled prior network that learns flexible prior
        distributions.
    counts : Optional[jnp.ndarray], default=None
        Observed count data (not used in the model, but included for interface
        compatibility).
    batch_size : Optional[int], default=None
        If specified, enables subsampling of cells for stochastic variational
        inference.

    Returns
    -------
    None
        This function defines the probabilistic model for use with NumPyro.
    """
    # Define prior parameters for unconstrained variables
    phi_prior_params = model_config.phi_unconstrained_prior or (0.0, 1.0)
    phi_capture_prior_params = model_config.phi_capture_unconstrained_prior or (
        0.0,
        1.0,
    )

    # Sample unconstrained parameters
    phi_unconstrained = numpyro.sample(
        "phi_unconstrained", dist.Normal(*phi_prior_params)
    )
    phi = numpyro.deterministic("phi", jnp.exp(phi_unconstrained))

    # Register the decoder and decoupled prior as NumPyro modules
    decoder_module = nnx_module("decoder", decoder)
    decoupled_prior_module = nnx_module("decoupled_prior", decoupled_prior)

    # Create the decoupled prior distribution
    base_distribution = dist.Normal(
        jnp.zeros(model_config.vae_latent_dim),
        jnp.ones(model_config.vae_latent_dim),
    ).to_event(1)
    decoupled_prior_dist = DecoupledPriorDistribution(
        decoupled_prior=decoupled_prior_module,
        base_distribution=base_distribution,
    )

    # Sample counts
    if counts is not None:
        if batch_size is None:
            # Without batching: sample counts for all cells
            with numpyro.plate("cells", n_cells):
                # Sample z from decoupled prior (KEY DIFFERENCE from standard
                # VAE)
                z = numpyro.sample("z", decoupled_prior_dist)

                # Use decoder to generate mu parameters from latent space
                mu_unconstrained = numpyro.deterministic(
                    "mu_unconstrained", decoder_module(z)
                )
                mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

                # Compute r using the odds ratio parameterization
                r = numpyro.deterministic("r", mu * phi)

                # Sample cell-specific capture probability from unconstrained
                # prior
                phi_capture_unconstrained = numpyro.sample(
                    "phi_capture_unconstrained",
                    dist.Normal(*phi_capture_prior_params),
                )
                # Transform to constrained space
                phi_capture = numpyro.deterministic(
                    "phi_capture", jnp.exp(phi_capture_unconstrained)
                )
                # Reshape phi_capture for broadcasting to (n_cells, n_genes)
                phi_capture_reshaped = phi_capture[:, None]
                # Compute p_hat using the derived formula
                p_hat = numpyro.deterministic(
                    "p_hat", 1.0 / (1 + phi + phi * phi_capture_reshaped)
                )

                # Define base distribution with VAE-generated r
                base_dist = dist.NegativeBinomialProbs(r, p_hat).to_event(1)
                numpyro.sample("counts", base_dist, obs=counts)
        else:
            # With batching: sample counts for a subset of cells
            with numpyro.plate(
                "cells", n_cells, subsample_size=batch_size
            ) as idx:
                # Sample z from decoupled prior (KEY DIFFERENCE from standard
                # VAE)
                z = numpyro.sample("z", decoupled_prior_dist)

                # Use decoder to generate mu parameters from latent space
                mu_unconstrained = numpyro.deterministic(
                    "mu_unconstrained", decoder_module(z)
                )
                mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

                # Compute r using the odds ratio parameterization
                r = numpyro.deterministic("r", mu * phi)

                # Sample cell-specific capture probability from unconstrained
                # prior
                phi_capture_unconstrained = numpyro.sample(
                    "phi_capture_unconstrained",
                    dist.Normal(*phi_capture_prior_params),
                )
                # Transform to constrained space
                phi_capture = numpyro.deterministic(
                    "phi_capture", jnp.exp(phi_capture_unconstrained)
                )
                # Reshape p_capture for broadcasting to (n_cells, n_genes)
                phi_capture_reshaped = phi_capture[:, None]
                # Compute p_hat using the derived formula
                p_hat = numpyro.deterministic(
                    "p_hat", 1.0 / (1 + phi + phi * phi_capture_reshaped)
                )

                # Define base distribution with VAE-generated r
                base_dist = dist.NegativeBinomialProbs(r, p_hat).to_event(1)
                numpyro.sample("counts", base_dist, obs=counts[idx])
    else:
        # Without counts: for prior predictive sampling
        with numpyro.plate("cells", n_cells):
            # Sample z from decoupled prior (KEY DIFFERENCE from standard VAE)
            z = numpyro.sample("z", decoupled_prior_dist)

            # Use decoder to generate mu parameters from latent space
            mu_unconstrained = numpyro.deterministic(
                "mu_unconstrained", decoder_module(z)
            )
            mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

            # Compute r using the odds ratio parameterization
            r = numpyro.deterministic("r", mu * phi)

            # Sample cell-specific capture probability from unconstrained prior
            phi_capture_unconstrained = numpyro.sample(
                "phi_capture_unconstrained",
                dist.Normal(*phi_capture_prior_params),
            )
            # Transform to constrained space
            phi_capture = numpyro.deterministic(
                "phi_capture", jnp.exp(phi_capture_unconstrained)
            )
            # Reshape p_capture for broadcasting to (n_cells, n_genes)
            phi_capture_reshaped = phi_capture[:, None]
            # Compute effective success probability p_hat for each cell/gene
            p_hat = numpyro.deterministic(
                "p_hat", 1.0 / (1 + phi + phi * phi_capture_reshaped)
            )

            # Define base distribution with VAE-generated r
            base_dist = dist.NegativeBinomialProbs(r, p_hat).to_event(1)
            numpyro.sample("counts", base_dist)


# ------------------------------------------------------------------------------
# Posterior Distributions for VAE-based models with linked unconstrained
# parameterization
# ------------------------------------------------------------------------------


def get_posterior_distributions(
    params: Dict[str, jnp.ndarray],
    model_config: ModelConfig,
    vae_model: VAE,
) -> Dict[str, dist.Distribution]:
    """
    Construct posterior distributions for model parameters from variational
    guide outputs for VAE-based models with odds ratio unconstrained
    parameterization.

    This function builds the appropriate `numpyro` distributions based on the
    guide parameters found in the `params` dictionary for VAE-based models. It
    handles both standard VAE models and decoupled prior VAE (dpVAE) models.

    The function constructs posterior distributions for:
        - Global parameters (phi_unconstrained, mu_unconstrained, etc.)
        - VAE-specific parameters (latent variables z)
        - Optional parameters (gate_unconstrained, phi_capture_unconstrained,
          etc.)

    For VAE models, the latent variable z is obtained from the VAE model's prior
    distribution, which may be either a standard Normal distribution or a
    learned decoupled prior distribution.

    The function is designed to work with the odds ratio unconstrained
    parameterization where parameters are sampled in unconstrained space and
    transformed to their constrained spaces via appropriate transformations.

    Parameters
    ----------
    params : Dict[str, jnp.ndarray]
        Dictionary containing estimated variational parameters (means and
        standard deviations) for each unconstrained latent variable, as produced
        by the guide. Expected keys include:
            - "phi_unconstrained_loc", "phi_unconstrained_scale"
            - "mu_unconstrained_loc", "mu_unconstrained_scale"
            - "gate_unconstrained_loc", "gate_unconstrained_scale"
            - "phi_capture_unconstrained_loc", "phi_capture_unconstrained_scale"
            - "mixing_concentrations" (for mixture models)
        Each value is a JAX array of appropriate shape (scalar or vector).
    model_config : ModelConfig
        Model configuration object containing VAE-specific settings.
    vae_model : VAE
        The VAE model object that provides the prior distribution for latent
        variables z.

    Returns
    -------
    Dict[str, dist.Distribution]
        Dictionary mapping parameter names to their corresponding posterior
        distributions. All distributions are returned as batch distributions (no
        splitting or per-component/gene lists).
    """
    distributions = {}

    # p_unconstrained parameter (Normal distribution)
    if "phi_unconstrained_loc" in params and "phi_unconstrained_scale" in params:
        distributions["phi_unconstrained"] = dist.Normal(
            params["phi_unconstrained_loc"],
            params["phi_unconstrained_scale"],
        )

    # mu_unconstrained parameter (Normal distribution)
    if "mu_unconstrained_loc" in params and "mu_unconstrained_scale" in params:
        distributions["mu_unconstrained"] = dist.Normal(
            params["mu_unconstrained_loc"],
            params["mu_unconstrained_scale"],
        )

    # gate_unconstrained parameter (Normal distribution)
    if (
        "gate_unconstrained_loc" in params
        and "gate_unconstrained_scale" in params
    ):
        distributions["gate_unconstrained"] = dist.Normal(
            params["gate_unconstrained_loc"], params["gate_unconstrained_scale"]
        )

    # p_capture_unconstrained parameter (Normal distribution)
    if (
        "phi_capture_unconstrained_loc" in params
        and "phi_capture_unconstrained_scale" in params
    ):
        distributions["phi_capture_unconstrained"] = dist.Normal(
            params["phi_capture_unconstrained_loc"],
            params["phi_capture_unconstrained_scale"],
        )

    # Get the decoupled prior distribution
    distributions["z"] = vae_model.get_prior_distribution()

    return distributions
