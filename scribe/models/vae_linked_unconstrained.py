"""
VAE-based models for single-cell RNA sequencing data using linked unconstrained
parameterization.

This parameterization differs from the standard parameterization in that the
mean parameter (mu) is linked to the success probability parameter (p) through
the relationship:
    r = mu * (1 - p) / p
where r is the dispersion parameter.

The VAE architecture generates cell-specific mu parameters from a
low-dimensional latent space, while keeping the global parameter p
interpretable. This allows for modeling cell-to-cell heterogeneity while
maintaining the interpretability of the linked parameterization.

Parameters are sampled in unconstrained space using Normal distributions and
transformed to their constrained spaces via appropriate transformations.
"""

import jax
import jax.numpy as jnp
import jax.scipy as jsp
import numpyro
import numpyro.distributions as dist
from numpyro.distributions import constraints
from numpyro.contrib.module import nnx_module
from typing import Dict, Optional

from .model_config import ModelConfig
from ..vae.architectures import (
    Encoder,
    EncoderVCP,
    Decoder,
    VAE,
    DecoupledPrior,
    DecoupledPriorDistribution,
)


# ------------------------------------------------------------------------------
# NBDM VAE Model
# ------------------------------------------------------------------------------


def nbdm_vae_model(
    n_cells: int,
    n_genes: int,
    model_config: ModelConfig,
    decoder: Decoder,  # Pre-created decoder passed as argument
    counts=None,
    batch_size=None,
):
    """
    Implements the VAE-based Negative Binomial-Dirichlet Multinomial (NBDM)
    model using a linked unconstrained parameterization suitable for variational
    inference in single-cell RNA sequencing data.

    This model extends the standard NBDM model by incorporating a Variational
    Autoencoder (VAE) architecture. The VAE generates cell-specific mean
    parameters (mu) from a low-dimensional latent space, while maintaining the
    global success probability parameter (p) as an interpretable global
    parameter. The dispersion parameter r is linked to mu and p through the
    relationship:

        r = mu * (1 - p) / p

    where:
        - mu > 0 is the mean expression for each cell and gene (generated by
          VAE),
        - p âˆˆ (0, 1) is the global success probability for the Negative
          Binomial,
        - r > 0 is the dispersion parameter.

    The model architecture consists of:
        1. A global parameter p sampled in unconstrained space and transformed
           via sigmoid to (0, 1)
        2. A latent variable z sampled from a standard Normal prior
        3. A decoder network that maps z to cell-specific mu parameters
        4. The linked parameterization that computes r from mu and p

    For each cell, the observed counts vector (of length n_genes) is modeled as:

        counts[cell, :] ~ NegativeBinomialProbs(r[cell, :], p)

    where r[cell, :] is computed from the VAE-generated mu[cell, :] and the
    global parameter p.

    The model supports optional batching over cells for scalable inference. If
    `counts` is provided, it is used as observed data; otherwise, the model
    samples counts from the generative process.

    Parameters
    ----------
    n_cells: int
        Number of cells in the dataset.
    n_genes: int
        Number of genes (features) per cell.
    model_config: ModelConfig
        ModelConfig object specifying prior parameters and VAE configuration.
    decoder: Decoder
        Pre-trained decoder network that maps latent variables to mu parameters.
    counts: Optional[jnp.ndarray], default=None
        Observed count data (not used in the model, but included for interface
        compatibility).
    batch_size: Optional[int], default=None
        If specified, enables subsampling of cells for stochastic variational
        inference.

    Returns
    -------
    None
        This function defines the probabilistic model for use with NumPyro.
    """
    # Define prior parameters for unconstrained variables
    p_prior_params = model_config.p_unconstrained_prior or (0.0, 1.0)

    # Sample unconstrained parameters
    p_unconstrained = numpyro.sample(
        "p_unconstrained", dist.Normal(*p_prior_params)
    )

    # Transform to constrained space
    p = numpyro.deterministic("p", jsp.special.expit(p_unconstrained))

    # Register the pre-created decoder as NumPyro module
    decoder_module = nnx_module("decoder", decoder)

    # Sample counts
    if counts is not None:
        if batch_size is None:
            # Without batching: sample counts for all cells
            with numpyro.plate("cells", n_cells):
                # Sample from latent space prior
                z = numpyro.sample(
                    "z",
                    dist.Normal(0, 1)
                    .expand([model_config.vae_latent_dim])
                    .to_event(1),
                )

                # Use decoder to generate mu parameters from latent space
                mu_unconstrained = numpyro.deterministic(
                    "mu_unconstrained", decoder_module(z)
                )
                mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

                # Compute r using the linked parameterization
                r = numpyro.deterministic("r", mu * (1 - p) / p)

                # Define base distribution with VAE-generated r
                base_dist = dist.NegativeBinomialProbs(r, p).to_event(1)
                numpyro.sample("counts", base_dist, obs=counts)
        else:
            # With batching: sample counts for a subset of cells
            with numpyro.plate(
                "cells", n_cells, subsample_size=batch_size
            ) as idx:
                # Sample from latent space prior
                z = numpyro.sample(
                    "z",
                    dist.Normal(0, 1)
                    .expand([model_config.vae_latent_dim])
                    .to_event(1),
                )

                # Use decoder to generate mu parameters from latent space
                mu_unconstrained = numpyro.deterministic(
                    "mu_unconstrained", decoder_module(z)
                )
                mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

                # Compute r using the linked parameterization
                r = numpyro.deterministic("r", mu * (1 - p) / p)

                # Define base distribution with VAE-generated r
                base_dist = dist.NegativeBinomialProbs(r, p).to_event(1)
                numpyro.sample("counts", base_dist, obs=counts[idx])
    else:
        # Without counts: for prior predictive sampling
        with numpyro.plate("cells", n_cells):
            # Sample from latent space prior
            z = numpyro.sample(
                "z",
                dist.Normal(0, 1)
                .expand([model_config.vae_latent_dim])
                .to_event(1),
            )

            # Use decoder to generate mu parameters from latent space
            mu_unconstrained = numpyro.deterministic(
                "mu_unconstrained", decoder_module(z)
            )
            mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

            # Compute r using the linked parameterization
            r = numpyro.deterministic("r", mu * (1 - p) / p)

            # Define base distribution with VAE-generated r
            base_dist = dist.NegativeBinomialProbs(r, p).to_event(1)
            numpyro.sample("counts", base_dist)


# ------------------------------------------------------------------------------
# NBDM VAE Guide
# ------------------------------------------------------------------------------


def nbdm_vae_guide(
    n_cells: int,
    n_genes: int,
    model_config: ModelConfig,
    encoder: Encoder,  # Pre-created encoder passed as argument
    counts=None,
    batch_size=None,
):
    """
    Mean-field variational guide for the VAE-based NBDM model with linked
    unconstrained parameterization.

    This guide defines a variational approximation for the VAE-based NBDM model,
    which combines the benefits of variational inference with the
    interpretability of the linked parameterization. The guide approximates the
    posterior distribution of the model parameters using a mean-field
    factorization.

    The variational family consists of:
        1. A global parameter p_unconstrained with learnable location and scale
        2. Cell-specific latent variables z with encoder-derived parameters
        3. The encoder network that maps observed counts to latent space
           parameters

    The guide architecture:
        - p_unconstrained ~ Normal(p_loc, p_scale) where p_loc and p_scale are
          learnable parameters
        - z[cell] ~ Normal(z_mean[cell], z_std[cell]) where z_mean and z_std are
          computed by the encoder network from the observed counts

    The encoder network takes the observed gene expression counts for each cell
    and outputs the mean and log-variance of the approximate posterior for the
    latent variable z. This allows the model to learn a meaningful
    representation of the data in the latent space while maintaining the
    interpretability of the global parameter p.

    The guide supports optional batching over cells for scalable inference. When
    batching is enabled, the encoder processes only a subset of cells at a time,
    making it suitable for large datasets.

    Parameters
    ----------
    n_cells : int
        Number of cells (samples) in the dataset.
    n_genes : int
        Number of genes (features) in the dataset.
    model_config : ModelConfig
        Configuration object containing prior and guide parameter settings.
    encoder : Encoder
        Pre-trained encoder network that maps observed counts to latent space
        parameters.
    counts : Optional[jnp.ndarray], default=None
        Observed count data used by the encoder to compute latent space
        parameters.
    batch_size : Optional[int], default=None
        If specified, enables subsampling of cells for stochastic variational
        inference.

    Returns
    -------
    None
        This function defines the variational guide for use with NumPyro's
        inference machinery.
    """
    # Define guide parameters for unconstrained variables
    p_guide_params = model_config.p_unconstrained_guide or (0.0, 1.0)

    # Register unconstrained p parameters
    p_loc = numpyro.param("p_unconstrained_loc", p_guide_params[0])
    p_scale = numpyro.param(
        "p_unconstrained_scale",
        p_guide_params[1],
        constraint=constraints.positive,
    )
    numpyro.sample("p_unconstrained", dist.Normal(p_loc, p_scale))

    # Register the pre-created encoder as NumPyro module for the guide
    encoder_module = nnx_module("encoder", encoder)

    # Sample latent variables using encoder
    if counts is not None:
        if batch_size is None:
            # Without batching: sample latent variables for all cells
            with numpyro.plate("cells", n_cells):
                # Use encoder to get mean and log variance for latent space
                z_mean, z_logvar = encoder_module(counts)
                z_std = jnp.exp(0.5 * z_logvar)

                # Sample from variational distribution
                numpyro.sample("z", dist.Normal(z_mean, z_std).to_event(1))
        else:
            # With batching: sample latent variables for a subset of cells
            with numpyro.plate(
                "cells", n_cells, subsample_size=batch_size
            ) as idx:
                # Use encoder to get mean and log variance for latent space
                batch_data = counts[idx]
                z_mean, z_logvar = encoder_module(batch_data)
                z_std = jnp.exp(0.5 * z_logvar)

                # Sample from variational distribution
                numpyro.sample("z", dist.Normal(z_mean, z_std).to_event(1))
    else:
        # Without counts: for prior predictive sampling
        with numpyro.plate("cells", n_cells):
            # Sample from latent space prior
            numpyro.sample(
                "z",
                dist.Normal(0, 1)
                .expand([model_config.vae_latent_dim])
                .to_event(1),
            )


# ------------------------------------------------------------------------------
# NBVCP VAE Model
# ------------------------------------------------------------------------------


def nbvcp_vae_model(
    n_cells: int,
    n_genes: int,
    model_config: ModelConfig,
    decoder: Decoder,  # Pre-created decoder passed as argument
    counts=None,
    batch_size=None,
):
    """
    Implements the VAE-based Negative Binomial model with variable mRNA capture
    probability (NBVCP) using a linked unconstrained parameterization suitable
    for variational inference in single-cell RNA sequencing data.

    This model extends the standard NBVCP model by incorporating a Variational
    Autoencoder (VAE) architecture. The VAE generates cell-specific mean
    parameters (mu) from a low-dimensional latent space, while maintaining the
    global success probability parameter (p) and cell-specific capture
    probabilities (p_capture) as interpretable parameters. The dispersion
    parameter r is linked to mu and p through the relationship:

        r = mu * (1 - p) / p

    where:
        - mu > 0 is the mean expression for each cell and gene (generated by
          VAE),
        - p âˆˆ (0, 1) is the global success probability for the Negative
          Binomial,
        - r > 0 is the dispersion parameter.

    The model introduces a cell-specific mRNA capture probability p_capture âˆˆ
    (0, 1), which modifies the effective success probability for each cell and
    gene. The effective success probability for cell i and gene j is:

        p_hat[i, j] = p * p_capture[i] / (1 - p * (1 - p_capture[i]))

    The model architecture consists of:
        1. Global parameters p and p_capture sampled in unconstrained space
        2. A latent variable z sampled from a standard Normal prior
        3. A decoder network that maps z to cell-specific mu parameters
        4. The linked parameterization that computes r from mu and p
        5. Cell-specific capture probabilities that modify the effective success
           probability

    For each cell, the observed counts vector (of length n_genes) is modeled as:

        counts[cell, :] ~ NegativeBinomialProbs(r[cell, :], p_hat[cell, :])

    where r[cell, :] is computed from the VAE-generated mu[cell, :] and the
    global parameter p, and p_hat[cell, :] incorporates the cell-specific
    capture probability.

    The model supports optional batching over cells for scalable inference. If
    `counts` is provided, it is used as observed data; otherwise, the model
    samples counts from the generative process.

    Parameters
    ----------
    n_cells : int
        Number of cells in the dataset.
    n_genes : int
        Number of genes (features) per cell.
    model_config : ModelConfig
        ModelConfig object specifying prior parameters and VAE configuration.
    decoder : Decoder
        Pre-trained decoder network that maps latent variables to mu parameters.
    counts : Optional[jnp.ndarray], default=None
        Observed count data (not used in the model, but included for interface
        compatibility).
    batch_size : Optional[int], default=None
        If specified, enables subsampling of cells for stochastic variational
        inference.

    Returns
    -------
    None
        This function defines the probabilistic model for use with NumPyro.
    """
    # Define prior parameters for unconstrained variables
    p_prior_params = model_config.p_unconstrained_prior or (0.0, 1.0)
    p_capture_prior_params = model_config.p_capture_unconstrained_prior or (
        0.0,
        1.0,
    )

    # Sample unconstrained parameters
    p_unconstrained = numpyro.sample(
        "p_unconstrained", dist.Normal(*p_prior_params)
    )

    # Transform to constrained space
    p = numpyro.deterministic("p", jsp.special.expit(p_unconstrained))

    # Register the pre-created decoder as NumPyro module
    decoder_module = nnx_module("decoder", decoder)

    # Sample counts
    if counts is not None:
        if batch_size is None:
            # Without batching: sample counts for all cells
            with numpyro.plate("cells", n_cells):
                # Sample from latent space prior
                z = numpyro.sample(
                    "z",
                    dist.Normal(0, 1)
                    .expand([model_config.vae_latent_dim])
                    .to_event(1),
                )

                # Use decoder to generate mu parameters from latent space
                mu_unconstrained = numpyro.deterministic(
                    "mu_unconstrained", decoder_module(z)
                )
                mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

                # Compute r using the linked parameterization
                r = numpyro.deterministic("r", mu * (1 - p) / p)

                # Sample cell-specific capture probability from unconstrained
                # prior
                p_capture_unconstrained = numpyro.sample(
                    "p_capture_unconstrained",
                    dist.Normal(*p_capture_prior_params),
                )
                # Transform to constrained space
                p_capture = numpyro.deterministic(
                    "p_capture", jsp.special.expit(p_capture_unconstrained)
                )
                # Reshape p_capture for broadcasting to (n_cells, n_genes)
                p_capture_reshaped = p_capture[:, None]
                # Compute effective success probability p_hat for each cell/gene
                p_hat = (
                    p * p_capture_reshaped / (1 - p * (1 - p_capture_reshaped))
                )

                # Define base distribution with VAE-generated r
                base_dist = dist.NegativeBinomialProbs(r, p_hat).to_event(1)
                numpyro.sample("counts", base_dist, obs=counts)
        else:
            # With batching: sample counts for a subset of cells
            with numpyro.plate(
                "cells", n_cells, subsample_size=batch_size
            ) as idx:
                # Sample from latent space prior
                z = numpyro.sample(
                    "z",
                    dist.Normal(0, 1)
                    .expand([model_config.vae_latent_dim])
                    .to_event(1),
                )

                # Use decoder to generate mu parameters from latent space
                mu_unconstrained = numpyro.deterministic(
                    "mu_unconstrained", decoder_module(z)
                )
                mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

                # Compute r using the linked parameterization
                r = numpyro.deterministic("r", mu * (1 - p) / p)

                # Sample cell-specific capture probability for the batch
                p_capture_unconstrained = numpyro.sample(
                    "p_capture_unconstrained",
                    dist.Normal(*p_capture_prior_params),
                )
                # Transform to constrained space
                p_capture = numpyro.deterministic(
                    "p_capture", jsp.special.expit(p_capture_unconstrained)
                )
                # Reshape p_capture for broadcasting to (n_cells, n_genes)
                p_capture_reshaped = p_capture[:, None]
                # Compute effective success probability p_hat for each cell/gene
                p_hat = (
                    p * p_capture_reshaped / (1 - p * (1 - p_capture_reshaped))
                )

                # Define base distribution with VAE-generated r
                base_dist = dist.NegativeBinomialProbs(r, p_hat).to_event(1)
                numpyro.sample("counts", base_dist, obs=counts[idx])
    else:
        # Without counts: for prior predictive sampling
        with numpyro.plate("cells", n_cells):
            # Sample from latent space prior
            z = numpyro.sample(
                "z",
                dist.Normal(0, 1)
                .expand([model_config.vae_latent_dim])
                .to_event(1),
            )

            # Use decoder to generate mu parameters from latent space
            mu_unconstrained = numpyro.deterministic(
                "mu_unconstrained", decoder_module(z)
            )
            mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

            # Compute r using the linked parameterization
            r = numpyro.deterministic("r", mu * (1 - p) / p)

            # Sample cell-specific capture probability from unconstrained prior
            p_capture_unconstrained = numpyro.sample(
                "p_capture_unconstrained",
                dist.Normal(*p_capture_prior_params),
            )
            # Transform to constrained space
            p_capture = numpyro.deterministic(
                "p_capture", jsp.special.expit(p_capture_unconstrained)
            )
            # Reshape p_capture for broadcasting to (n_cells, n_genes)
            p_capture_reshaped = p_capture[:, None]
            # Compute effective success probability p_hat for each cell/gene
            p_hat = p * p_capture_reshaped / (1 - p * (1 - p_capture_reshaped))

            # Define base distribution with VAE-generated r
            base_dist = dist.NegativeBinomialProbs(r, p_hat).to_event(1)
            numpyro.sample("counts", base_dist)


# ------------------------------------------------------------------------------
# NBVCP VAE Guide
# ------------------------------------------------------------------------------


def nbvcp_vae_guide(
    n_cells: int,
    n_genes: int,
    model_config: ModelConfig,
    encoder: EncoderVCP,  # Pre-created encoder passed as argument
    counts=None,
    batch_size=None,
):
    """
    Mean-field variational guide for the VAE-based NBVCP model with linked
    unconstrained parameterization.

    This guide defines a variational approximation for the VAE-based NBVCP
    model, which combines the benefits of variational inference with the
    interpretability of the linked parameterization and cell-specific capture
    probabilities. The guide approximates the posterior distribution of the
    model parameters using a mean-field factorization.

    The variational family consists of:
        1. A global parameter p_unconstrained with learnable location and scale
        2. Cell-specific latent variables z with encoder-derived parameters
        3. Cell-specific capture probability parameters p_capture with
           encoder-derived parameters
        4. The encoder network that maps observed counts to latent space and
           capture parameters

    The guide architecture:
        - p_unconstrained ~ Normal(p_loc, p_scale) where p_loc and p_scale are
          learnable parameters
        - z[cell] ~ Normal(z_mean[cell], z_std[cell]) where z_mean and z_std are
          computed by the encoder network from the observed counts
        - p_capture_unconstrained[cell] ~ Normal(p_capture_loc[cell],
          p_capture_scale[cell]) where the parameters are computed by the
          encoder network

    The encoder network takes the observed gene expression counts for each cell
    and outputs:
        1. The mean and log-variance of the approximate posterior for the latent
           variable z
        2. The location and scale parameters for the cell-specific capture
           probabilities

    This allows the model to learn meaningful representations of the data in the
    latent space while maintaining the interpretability of the global parameter
    p and capturing cell-specific technical effects through p_capture.

    The guide supports optional batching over cells for scalable inference. When
    batching is enabled, the encoder processes only a subset of cells at a time,
    making it suitable for large datasets.

    Parameters
    ----------
    n_cells : int
        Number of cells (samples) in the dataset.
    n_genes : int
        Number of genes (features) in the dataset.
    model_config : ModelConfig
        Configuration object containing prior and guide parameter settings.
    encoder : EncoderVCP
        Pre-trained encoder network that maps observed counts to latent space
        parameters and capture probability parameters.
    counts : Optional[jnp.ndarray], default=None
        Observed count data used by the encoder to compute latent space and
        capture probability parameters.
    batch_size : Optional[int], default=None
        If specified, enables subsampling of cells for stochastic variational
        inference.

    Returns
    -------
    None
        This function defines the variational guide for use with NumPyro's
        inference machinery.
    """
    # Define guide parameters for unconstrained variables
    p_guide_params = model_config.p_unconstrained_guide or (0.0, 1.0)

    # Register unconstrained p parameters
    p_loc = numpyro.param("p_unconstrained_loc", p_guide_params[0])
    p_scale = numpyro.param(
        "p_unconstrained_scale",
        p_guide_params[1],
        constraint=constraints.positive,
    )
    numpyro.sample("p_unconstrained", dist.Normal(p_loc, p_scale))

    # Register the pre-created encoder as NumPyro module for the guide
    encoder_module = nnx_module("encoder", encoder)

    # Sample latent variables using encoder
    if counts is not None:
        if batch_size is None:
            # Without batching: sample latent variables for all cells
            with numpyro.plate("cells", n_cells):
                # Use encoder to get mean and log variance for latent space
                (
                    z_mean,
                    z_logvar,
                    p_capture_loc,
                    p_capture_logscale,
                ) = encoder_module(counts)
                z_std = jnp.exp(0.5 * z_logvar)

                # Sample from variational distribution
                numpyro.sample("z", dist.Normal(z_mean, z_std).to_event(1))

                # Sample cell-specific capture probability from prior
                numpyro.sample(
                    "p_capture_unconstrained",
                    dist.Normal(
                        p_capture_loc.squeeze(-1),
                        jnp.exp(p_capture_logscale.squeeze(-1)),
                    ),
                )
        else:
            # With batching: sample latent variables for a subset of cells
            with numpyro.plate(
                "cells", n_cells, subsample_size=batch_size
            ) as idx:
                # Use encoder to get mean and log variance for latent space
                batch_data = counts[idx]
                (
                    z_mean,
                    z_logvar,
                    p_capture_loc,
                    p_capture_logscale,
                ) = encoder_module(batch_data)
                z_std = jnp.exp(0.5 * z_logvar)

                # Sample from variational distribution
                numpyro.sample("z", dist.Normal(z_mean, z_std).to_event(1))

                # Sample cell-specific capture probability from prior
                numpyro.sample(
                    "p_capture_unconstrained",
                    dist.Normal(
                        p_capture_loc.squeeze(-1),
                        jnp.exp(p_capture_logscale.squeeze(-1)),
                    ),
                )
    else:
        # Without counts: for prior predictive sampling
        with numpyro.plate("cells", n_cells):
            p_capture_prior_params = (
                model_config.p_capture_unconstrained_prior
                or (
                    0.0,
                    1.0,
                )
            )
            # Sample from latent space prior
            numpyro.sample(
                "z",
                dist.Normal(0, 1)
                .expand([model_config.vae_latent_dim])
                .to_event(1),
            )

            # Sample cell-specific capture probability from Beta prior
            numpyro.sample(
                "p_capture_unconstrained", dist.Normal(*p_capture_prior_params)
            )


# ==============================================================================
# dpVAE Model Functions (for decoupled prior)
# ==============================================================================

# ------------------------------------------------------------------------------
# NBDM dpVAE Model
# ------------------------------------------------------------------------------


def nbdm_dpvae_model(
    n_cells: int,
    n_genes: int,
    model_config: ModelConfig,
    decoder: Decoder,
    decoupled_prior: DecoupledPrior,
    counts=None,
    batch_size=None,
):
    """
    Implements the decoupled prior VAE (dpVAE) model for Negative
    Binomial-Dirichlet Multinomial (NBDM) data using a linked unconstrained
    parameterization.

    This model extends the standard VAE-based NBDM model by incorporating a
    decoupled prior architecture, which allows for more flexible and expressive
    prior distributions over the latent space. The key innovation is the use of
    a DecoupledPriorDistribution that combines a base distribution with a
    learned prior network.

    The model maintains the linked parameterization where the dispersion
    parameter r is related to the mean (mu) and success probability (p) through:

        r = mu * (1 - p) / p

    where:
        - mu > 0 is the mean expression for each cell and gene (generated by
          VAE),
        - p âˆˆ (0, 1) is the global success probability for the Negative
          Binomial,
        - r > 0 is the dispersion parameter.

    The model architecture consists of:
        1. Global parameters p and mu sampled in unconstrained space
        2. A latent variable z sampled from a decoupled prior distribution
        3. A decoder network that maps z to cell-specific mu parameters
        4. The linked parameterization that computes r from mu and p
        5. A decoupled prior network that learns flexible prior distributions

    The decoupled prior combines a standard Normal base distribution with a
    learned prior network that can adapt to the structure of the data, providing
    more expressive modeling capabilities than standard VAEs.

    For each cell, the observed counts vector (of length n_genes) is modeled as:

        counts[cell, :] ~ NegativeBinomialProbs(r[cell, :], p)

    where r[cell, :] is computed from the VAE-generated mu[cell, :] and the
    global parameter p.

    The model supports optional batching over cells for scalable inference. If
    `counts` is provided, it is used as observed data; otherwise, the model
    samples counts from the generative process.

    Parameters
    ----------
    n_cells : int
        Number of cells in the dataset.
    n_genes : int
        Number of genes (features) per cell.
    model_config : ModelConfig
        ModelConfig object specifying prior parameters and VAE configuration.
    decoder : Decoder
        Pre-trained decoder network that maps latent variables to mu parameters.
    decoupled_prior : DecoupledPrior
        Pre-trained decoupled prior network that learns flexible prior
        distributions.
    counts : Optional[jnp.ndarray], default=None
        Observed count data (not used in the model, but included for interface
        compatibility).
    batch_size : Optional[int], default=None
        If specified, enables subsampling of cells for stochastic variational
        inference.

    Returns
    -------
    None
        This function defines the probabilistic model for use with NumPyro.
    """
    # Define prior parameters for unconstrained variables
    p_prior_params = model_config.p_unconstrained_prior or (0.0, 1.0)

    # Sample unconstrained parameters
    p_unconstrained = numpyro.sample(
        "p_unconstrained", dist.Normal(*p_prior_params)
    )
    # Transform to constrained space
    p = numpyro.deterministic("p", jsp.special.expit(p_unconstrained))

    # Register the decoder and decoupled prior as NumPyro modules
    decoder_module = nnx_module("decoder", decoder)
    decoupled_prior_module = nnx_module("decoupled_prior", decoupled_prior)

    # Create the decoupled prior distribution
    base_distribution = dist.Normal(
        jnp.zeros(model_config.vae_latent_dim),
        jnp.ones(model_config.vae_latent_dim),
    ).to_event(1)
    decoupled_prior_dist = DecoupledPriorDistribution(
        decoupled_prior=decoupled_prior_module,
        base_distribution=base_distribution,
    )

    # Sample latent variables and generate observations
    if counts is not None:
        if batch_size is None:
            with numpyro.plate("cells", n_cells):
                # Sample z from decoupled prior (KEY DIFFERENCE from standard VAE)
                z = numpyro.sample("z", decoupled_prior_dist)

                # Use decoder to generate mu parameters from latent space
                mu_unconstrained = numpyro.deterministic(
                    "mu_unconstrained", decoder_module(z)
                )

                # Compute mu from log_mu
                mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

                # Compute r using the linked parameterization
                r = numpyro.deterministic("r", mu * (1 - p) / p)

                # Define base distribution with VAE-generated r
                base_dist = dist.NegativeBinomialProbs(r, p).to_event(1)
                # Sample counts from the base distribution
                numpyro.sample("counts", base_dist, obs=counts)
        else:
            with numpyro.plate(
                "cells", n_cells, subsample_size=batch_size
            ) as idx:
                # Sample z from decoupled prior
                z = numpyro.sample("z", decoupled_prior_dist)

                # Use decoder to generate mu parameters from latent space
                mu_unconstrained = numpyro.deterministic(
                    "mu_unconstrained", decoder_module(z)
                )

                # Compute mu from log_mu
                mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

                # Compute r using the linked parameterization
                r = numpyro.deterministic("r", mu * (1 - p) / p)

                # Sample observed counts from the base distribution
                batch_counts = counts[idx] if counts is not None else None
                numpyro.sample(
                    "counts",
                    dist.NegativeBinomialProbs(r, p).to_event(1),
                    obs=batch_counts,
                )
    else:
        # Without counts: for prior predictive sampling
        with numpyro.plate("cells", n_cells):
            # Sample from latent space prior
            z = numpyro.sample("z", decoupled_prior_dist)

            # Use decoder to generate mu parameters from latent space
            mu_unconstrained = numpyro.deterministic(
                "mu_unconstrained", decoder_module(z)
            )

            mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

            # Compute r using the linked parameterization
            r = numpyro.deterministic("r", mu * (1 - p) / p)

            # Define base distribution with VAE-generated r
            base_dist = dist.NegativeBinomialProbs(r, p).to_event(1)
            numpyro.sample("counts", base_dist)


# ------------------------------------------------------------------------------
# NBVCP dpVAE Model
# ------------------------------------------------------------------------------


def nbvcp_dpvae_model(
    n_cells: int,
    n_genes: int,
    model_config: ModelConfig,
    decoder: Decoder,
    decoupled_prior: DecoupledPrior,
    counts=None,
    batch_size=None,
):
    """
    Implements the decoupled prior VAE (dpVAE) model for Negative Binomial with
    variable mRNA capture probability (NBVCP) using a linked unconstrained
    parameterization.

    This model extends the standard VAE-based NBVCP model by incorporating a
    decoupled prior architecture, which allows for more flexible and expressive
    prior distributions over the latent space. The key innovation is the use of
    a DecoupledPriorDistribution that combines a base distribution with a
    learned prior network.

    The model maintains the linked parameterization where the dispersion
    parameter r is related to the mean (mu) and success probability (p) through:

        r = mu * (1 - p) / p

    where:
        - mu > 0 is the mean expression for each cell and gene (generated by
          VAE),
        - p âˆˆ (0, 1) is the global success probability for the Negative
          Binomial,
        - r > 0 is the dispersion parameter.

    The model introduces a cell-specific mRNA capture probability p_capture âˆˆ
    (0, 1), which modifies the effective success probability for each cell and
    gene. The effective success probability for cell i and gene j is:

        p_hat[i, j] = p * p_capture[i] / (1 - p * (1 - p_capture[i]))

    The model architecture consists of:
        1. Global parameters p, mu, and p_capture sampled in unconstrained space
        2. A latent variable z sampled from a decoupled prior distribution
        3. A decoder network that maps z to cell-specific mu parameters
        4. The linked parameterization that computes r from mu and p
        5. Cell-specific capture probabilities that modify the effective success
           probability
        6. A decoupled prior network that learns flexible prior distributions

    The decoupled prior combines a standard Normal base distribution with a
    learned prior network that can adapt to the structure of the data, providing
    more expressive modeling capabilities than standard VAEs.

    For each cell, the observed counts vector (of length n_genes) is modeled as:

        counts[cell, :] ~ NegativeBinomialProbs(r[cell, :], p_hat[cell, :])

    where r[cell, :] is computed from the VAE-generated mu[cell, :] and the
    global parameter p, and p_hat[cell, :] incorporates the cell-specific
    capture probability.

    The model supports optional batching over cells for scalable inference. If
    `counts` is provided, it is used as observed data; otherwise, the model
    samples counts from the generative process.

    Parameters
    ----------
    n_cells : int
        Number of cells in the dataset.
    n_genes : int
        Number of genes (features) per cell.
    model_config : ModelConfig
        ModelConfig object specifying prior parameters and VAE configuration.
    decoder : Decoder
        Pre-trained decoder network that maps latent variables to mu parameters.
    decoupled_prior : DecoupledPrior
        Pre-trained decoupled prior network that learns flexible prior
        distributions.
    counts : Optional[jnp.ndarray], default=None
        Observed count data (not used in the model, but included for interface
        compatibility).
    batch_size : Optional[int], default=None
        If specified, enables subsampling of cells for stochastic variational
        inference.

    Returns
    -------
    None
        This function defines the probabilistic model for use with NumPyro.
    """
    # Define prior parameters for unconstrained variables
    p_prior_params = model_config.p_unconstrained_prior or (0.0, 1.0)
    p_capture_prior_params = model_config.p_capture_unconstrained_prior or (
        0.0,
        1.0,
    )

    # Sample unconstrained parameters
    p_unconstrained = numpyro.sample(
        "p_unconstrained", dist.Normal(*p_prior_params)
    )
    # Transform to constrained space
    p = numpyro.deterministic("p", jsp.special.expit(p_unconstrained))

    # Register the decoder and decoupled prior as NumPyro modules
    decoder_module = nnx_module("decoder", decoder)
    decoupled_prior_module = nnx_module("decoupled_prior", decoupled_prior)

    # Create the decoupled prior distribution
    base_distribution = dist.Normal(
        jnp.zeros(model_config.vae_latent_dim),
        jnp.ones(model_config.vae_latent_dim),
    ).to_event(1)
    decoupled_prior_dist = DecoupledPriorDistribution(
        decoupled_prior=decoupled_prior_module,
        base_distribution=base_distribution,
    )

    # Sample counts
    if counts is not None:
        if batch_size is None:
            # Without batching: sample counts for all cells
            with numpyro.plate("cells", n_cells):
                # Sample z from decoupled prior (KEY DIFFERENCE from standard VAE)
                z = numpyro.sample("z", decoupled_prior_dist)

                # Use decoder to generate mu parameters from latent space
                mu_unconstrained = numpyro.deterministic(
                    "mu_unconstrained", decoder_module(z)
                )
                mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

                # Compute r using the linked parameterization
                r = numpyro.deterministic("r", mu * (1 - p) / p)

                # Sample cell-specific capture probability from unconstrained prior
                p_capture_unconstrained = numpyro.sample(
                    "p_capture_unconstrained",
                    dist.Normal(*p_capture_prior_params),
                )
                # Transform to constrained space
                p_capture = numpyro.deterministic(
                    "p_capture", jsp.special.expit(p_capture_unconstrained)
                )
                # Reshape p_capture for broadcasting to (n_cells, n_genes)
                p_capture_reshaped = p_capture[:, None]
                # Compute effective success probability p_hat for each cell/gene
                p_hat = (
                    p * p_capture_reshaped / (1 - p * (1 - p_capture_reshaped))
                )

                # Define base distribution with VAE-generated r
                base_dist = dist.NegativeBinomialProbs(r, p_hat).to_event(1)
                numpyro.sample("counts", base_dist, obs=counts)
        else:
            # With batching: sample counts for a subset of cells
            with numpyro.plate(
                "cells", n_cells, subsample_size=batch_size
            ) as idx:
                # Sample z from decoupled prior (KEY DIFFERENCE from standard VAE)
                z = numpyro.sample("z", decoupled_prior_dist)

                # Use decoder to generate mu parameters from latent space
                mu_unconstrained = numpyro.deterministic(
                    "mu_unconstrained", decoder_module(z)
                )
                mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

                # Compute r using the linked parameterization
                r = numpyro.deterministic("r", mu * (1 - p) / p)

                # Sample cell-specific capture probability from unconstrained prior
                p_capture_unconstrained = numpyro.sample(
                    "p_capture_unconstrained",
                    dist.Normal(*p_capture_prior_params),
                )
                # Transform to constrained space
                p_capture = numpyro.deterministic(
                    "p_capture", jsp.special.expit(p_capture_unconstrained)
                )
                # Reshape p_capture for broadcasting to (n_cells, n_genes)
                p_capture_reshaped = p_capture[:, None]
                # Compute effective success probability p_hat for each cell/gene
                p_hat = (
                    p * p_capture_reshaped / (1 - p * (1 - p_capture_reshaped))
                )

                # Define base distribution with VAE-generated r
                base_dist = dist.NegativeBinomialProbs(r, p_hat).to_event(1)
                numpyro.sample("counts", base_dist, obs=counts[idx])
    else:
        # Without counts: for prior predictive sampling
        with numpyro.plate("cells", n_cells):
            # Sample z from decoupled prior (KEY DIFFERENCE from standard VAE)
            z = numpyro.sample("z", decoupled_prior_dist)

            # Use decoder to generate mu parameters from latent space
            mu_unconstrained = numpyro.deterministic(
                "mu_unconstrained", decoder_module(z)
            )
            mu = numpyro.deterministic("mu", jnp.exp(mu_unconstrained))

            # Compute r using the linked parameterization
            r = numpyro.deterministic("r", mu * (1 - p) / p)

            # Sample cell-specific capture probability from unconstrained prior
            p_capture_unconstrained = numpyro.sample(
                "p_capture_unconstrained",
                dist.Normal(*p_capture_prior_params),
            )
            # Transform to constrained space
            p_capture = numpyro.deterministic(
                "p_capture", jsp.special.expit(p_capture_unconstrained)
            )
            # Reshape p_capture for broadcasting to (n_cells, n_genes)
            p_capture_reshaped = p_capture[:, None]
            # Compute effective success probability p_hat for each cell/gene
            p_hat = p * p_capture_reshaped / (1 - p * (1 - p_capture_reshaped))

            # Define base distribution with VAE-generated r
            base_dist = dist.NegativeBinomialProbs(r, p_hat).to_event(1)
            numpyro.sample("counts", base_dist)


# ------------------------------------------------------------------------------
# Posterior Distributions for VAE-based models with linked unconstrained
# parameterization
# ------------------------------------------------------------------------------


def get_posterior_distributions(
    params: Dict[str, jnp.ndarray],
    model_config: ModelConfig,
    vae_model: VAE,
) -> Dict[str, dist.Distribution]:
    """
    Construct posterior distributions for model parameters from variational
    guide outputs for VAE-based models with linked unconstrained
    parameterization.

    This function builds the appropriate `numpyro` distributions based on the
    guide parameters found in the `params` dictionary for VAE-based models. It
    handles both standard VAE models and decoupled prior VAE (dpVAE) models.

    The function constructs posterior distributions for:
        - Global parameters (p_unconstrained, mu_unconstrained, etc.)
        - VAE-specific parameters (latent variables z)
        - Optional parameters (gate_unconstrained, p_capture_unconstrained,
          etc.)

    For VAE models, the latent variable z is obtained from the VAE model's prior
    distribution, which may be either a standard Normal distribution or a
    learned decoupled prior distribution.

    Parameters
    ----------
    params : Dict[str, jnp.ndarray]
        Dictionary containing estimated variational parameters (means and
        standard deviations) for each unconstrained latent variable, as produced
        by the guide. Expected keys include:
            - "p_unconstrained_loc", "p_unconstrained_scale"
            - "mu_unconstrained_loc", "mu_unconstrained_scale"
            - "gate_unconstrained_loc", "gate_unconstrained_scale"
            - "p_capture_unconstrained_loc", "p_capture_unconstrained_scale"
        Each value is a JAX array of appropriate shape (scalar or vector).
    model_config : ModelConfig
        Model configuration object containing VAE-specific settings.
    vae_model : VAE
        The VAE model object that provides the prior distribution for latent
        variables z.

    Returns
    -------
    Dict[str, dist.Distribution]
        Dictionary mapping parameter names to their corresponding posterior
        distributions. All distributions are returned as batch distributions (no
        splitting or per-component/gene lists).
    """
    distributions = {}

    # p_unconstrained parameter (Normal distribution)
    if "p_unconstrained_loc" in params and "p_unconstrained_scale" in params:
        distributions["p_unconstrained"] = dist.Normal(
            params["p_unconstrained_loc"], params["p_unconstrained_scale"]
        )

    # mu_unconstrained parameter (Normal distribution)
    if "mu_unconstrained_loc" in params and "mu_unconstrained_scale" in params:
        distributions["mu_unconstrained"] = dist.Normal(
            params["mu_unconstrained_loc"], params["mu_unconstrained_scale"]
        )

    # gate_unconstrained parameter (Normal distribution)
    if (
        "gate_unconstrained_loc" in params
        and "gate_unconstrained_scale" in params
    ):
        distributions["gate_unconstrained"] = dist.Normal(
            params["gate_unconstrained_loc"], params["gate_unconstrained_scale"]
        )

    # p_capture_unconstrained parameter (Normal distribution)
    if (
        "p_capture_unconstrained_loc" in params
        and "p_capture_unconstrained_scale" in params
    ):
        distributions["p_capture_unconstrained"] = dist.Normal(
            params["p_capture_unconstrained_loc"],
            params["p_capture_unconstrained_scale"],
        )

    # Get the decoupled prior distribution
    distributions["z"] = vae_model.get_prior_distribution()

    return distributions
