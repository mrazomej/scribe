{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Quickstart with 10x Genomics Data\n\nThis tutorial will walk you through analyzing a real-world single-cell RNA-seq\ndataset using SCRIBE. For this tutorial, we will use the Jurkat cells dataset\nfrom 10x Genomics (available [here](https://www.10xgenomics.com/datasets/jurkat-cells-1-standard-1-1-0)). To\nilustrate ``SCRIBE``'s flexibility, we will explore several models available,\nstarting from the basic Negative Binomial-Dirichlet Multinomial (NBDM) model\nwhere all genes are negative binomially distributed with a shared success\nprobability $p$ and a gene-specific $r_g$ parameter. Later on, we\nwill account for the cell-to-cell variation in mRNA-to-UMI conversion efficiency\nby explicitly modeling the mRNA capture efficiency. Finally, we will explore a\ndifferent parameterization of the model to help with convergence and\nperformance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n\nFirst, let's import the necessary libraries and set up our directories.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nfrom jax import random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scanpy as sc  # to load the data\nimport scribe  # our main library\nimport pickle  # to save the results\n\n# Define directories\nOUTPUT_DIR = \"output\"\nFIG_DIR = os.path.join(OUTPUT_DIR, \"figures\")\n\n# Create output directory\nos.makedirs(OUTPUT_DIR, exist_ok=True)\nos.makedirs(FIG_DIR, exist_ok=True)\n\n# Simple cache directory. This directory is used to store the results of the\n# models for this tutorial to avoid re-running the models as we work through the\n# tutorial. YOU DO NOT NEED TO DO THIS IN YOUR OWN ANALYSIS.\nCACHE_DIR = \"../../../CACHE\"\nos.makedirs(CACHE_DIR, exist_ok=True)\n\n\n# Set plotting style and scanpy settings\nscribe.viz.matplotlib_style()\nsc.settings.verbosity = 1  # Reduce scanpy output verbosity for cleaner tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the Data\n\nWe will use the Jurkat cell dataset from 10x Genomics. This dataset consists\nof ~3,200 human Jurkat cells, a T-lymphocyte cell line. For this tutorial,\nwe'll use the full transcriptome to demonstrate ``SCRIBE``'s ability to handle\nlarge-scale single-cell datasets.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>``SCRIBE`` is designed to work with the **entire transcriptome** and\n  can easily handle datasets with 20,000+ genes, as long as you have the right\n  hardware. This is the recommended approach for comprehensive analysis.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define path to the data\ndata_path = os.path.abspath(\n    os.path.join(\n        os.path.dirname(scribe.__file__),\n        # Here, put the path to the data.h5ad file in your computer.\n        \"../../data/10xGenomics/Jurkat_cells/data.h5ad\",\n    )\n)\n\n# Load the data using scanpy\nadata = sc.read_h5ad(data_path)\n\n# Extract raw counts for ``SCRIBE`` (``SCRIBE`` works with raw integer counts)\ncounts = adata.X.toarray()\n\n# Define number of cells and genes\nn_cells = adata.n_obs\nn_genes = adata.n_vars\n\nprint(f\"Count matrix data type: {counts.dtype}\")\nprint(f\"Total UMIs in dataset: {counts.sum():,.0f}\")\nprint(f\"Mean UMIs per cell: {counts.sum(axis=1).mean():.1f}\")\nprint(f\"Mean UMIs per gene: {counts.sum(axis=0).mean():.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 1: Negative Binomial-Dirichlet Multinomial (NBDM)\n\nThe core of ``SCRIBE`` is the Negative Binomial-Dirichlet Multinomial (NBDM)\nmodel. This model is derived from first principles, where a two-state promoter\nmodel can be shown to lead to a steady-state mRNA distribution that follows a\nNegative Binomial (NB) distribution. The only extra-ingredient ``SCRIBE`` adds\nis to assume that all genes share the same success probability parameter\n$p$. Biophysically, this is equivalent to assuming that all genes share\nthe same burst size.\n\nA key insight from this model is that if all genes share the same success\nprobability parameter $p$ in their NB distributions, the joint\ndistribution of UMI counts for a cell can be factorized into two components:\n\n1.  A Negative Binomial distribution for the total number of UMIs in the cell.\n2.  A Dirichlet-Multinomial (DM) distribution for the relative proportions of\n    gene counts.\n\nThis factorization allows ``SCRIBE`` to normalize gene expression levels as\nthe math reveals a natural scheme where the gene-specific $r_g$\nparameters can be used to compute the fraction of the transcriptome that each\ngene occupies.\n\nLet's fit the basic NBDM model to our data using Stochastic Variational\nInference (SVI). SVI is a type of variational inference that, although only\napproximately correct, is very fast and scalable, perfect for exploring large\ndatasets quickly. For ``SCRIBE``, all we need to specify is the number of\nsteps to run the inference for (think of stochastic gradient descent for\noptimization), the batch size (how many cells to process at once for each\noptimization step), and a random seed for reproducibility.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define inference parameters\nn_steps = 30_000\nbatch_size = 512\nseed = 42\n\n# Simple caching for NBDM model. Again, you do not need to do this in your own\n# analysis if you don't want to; this is just not to re-run the model if we\n# already have the results.\ncache_file = os.path.join(\n    CACHE_DIR, f\"svi_quickstart_nbdm_standard_{n_genes}genes_{n_steps}steps.pkl\"\n)\nif os.path.exists(cache_file):\n    print(f\"Loading NBDM results from {cache_file}\")\n    with open(cache_file, \"rb\") as f:\n        results_nbdm = pickle.load(f)\nelse:\n    print(\"Running NBDM model...\")\n    results_nbdm = scribe.run_scribe(\n        counts=counts,  # The count matrix\n        n_steps=n_steps,  # The number of steps to run the inference for\n        batch_size=batch_size,  # The batch size\n        seed=seed,  # The random seed\n    )\n    # Save the results to a file.\n    with open(cache_file, \"wb\") as f:\n        pickle.dump(results_nbdm, f)\n    print(f\"Saved NBDM results to {cache_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing Results for NBDM\n\nAfter fitting the model, we should always perform diagnostic checks to assess\nthe model fit. We'll look at the ELBO loss history first. What we are looking\nfor is that the loss is decreasing over time, and that it plateaus at some\npoint. Empirically, we have seen that anything between 25,000 and 50,000 steps\nis usually enough to get a good fit.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Although SVI aims to maximize the ELBO, here we are\n  looking for a decreasing loss function, this is because the actual loss\n  function implemented in SVI is the negative ELBO, also known as the\n  Variational Free Energy.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot ELBO loss history\nfig, ax = plt.subplots(figsize=(3.5, 3))\nax.plot(results_nbdm.loss_history)\nax.set_xlabel(\"step\")\nax.set_ylabel(\"ELBO Loss\")\nax.set_title(\"NBDM ELBO Loss\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This looks good. The loss is decreasing over time, and it plateaus at some\npoint.\n\nAfter confirming that the optimization is converging, one of the most\nimportant steps in any Bayesian model (and one could argue in any statistical\nmodel) is to perform posterior predictive checks (PPCs).\n\nPPCs are a way to check if the model is able to reproduce the key features of\nthe observed data. The logic is straightforward:\n\n1. **Generate Synthetic Data**: Use the fitted model to generate new datasets\n   that should resemble the original data if the model is appropriate. This\n   means that we take a sample of the posterior parameters and run them\n   through the likelihood function to simulate a new dataset. We repeat this\n   process multiple times to get a distribution of the predicted data.\n\n2. **Compare Distributions**: Plot the distribution of observed counts\n   alongside the distribution of model-predicted counts for the same genes.\n   This is done by plotting the distribution of the observed counts alongside\n   the distribution of the predicted counts for the same genes. Usually, we\n   can plot quantiles of the predicted data to get a sense of the\n   distribution.\n\n3. **Assess Model Fit**: If the model is good, the observed data should fall\n   within the credible intervals of the predicted data most of the time.\n\n.. important::\n   This is not a common practice in the field of single-cell RNA-seq analysis,\n   but we argue it should be! A simple visual inspection of the quality of the\n   fit is vital to understand how well the model is able to capture the data.\n\n### Strategic Gene Selection for Posterior Predictive Checks\n\nBefore generating PPC samples, we need to select a subset of genes to analyze.\nThis is because generating PPC samples is a computationally and memory\nintensive process. Usually, we would like to generate between 100 and 1000\nsamples; each sample being a full count matrix with the same number of cells\nand genes as the original data. You can see how this can get out of hand very\nquickly. Fortunately, ``SCRIBE``'s results objects are **indexable**, allowing\nus to subset the results to only the genes we want to visualize.\n\nRather than randomly selecting genes for visualization, we'll use a strategic\napproach that ensures we capture genes across different expression levels.\nThis is done by calculating the median expression for each gene across all\ncells in the dataset, filtering out completely unexpressed genes (median = 0),\nsorting genes by their median expression, and selecting evenly spaced genes\nacross the expression spectrum. However, feel free to use whatever method you\nprefer.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>We filter genes with median expression equal to 0 for visualization\n  purposes. However, these genes were taken into account for the model fit.\n  This is the power of the full Bayesian framework ``SCRIBE`` offers.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def select_genes_for_visualization(counts, n_genes=25):\n    \"\"\"\n    Select a representative subset of genes for visualization based on their\n    expression levels.\n\n    This function implements a stratified sampling approach that:\n        1. Calculates median expression for each gene across all cells\n        2. Filters out completely unexpressed genes (median = 0)\n        3. Sorts genes by their median expression\n        4. Selects evenly spaced genes across the expression spectrum\n\n    Parameters\n    ----------\n    counts : array-like, shape (n_cells, n_genes)\n        The count matrix where rows are cells and columns are genes.\n    n_genes : int, default=25\n        Number of genes to select for visualization.\n\n    Returns\n    -------\n    selected_idx : array\n        Indices of selected genes, sorted by expression level.\n    median_expr : array\n        Median expression values for all genes.\n    \"\"\"\n    # Calculate median expression across cells for each gene\n    # We use median instead of mean because it's more robust to outliers\n    # and better represents the typical expression level\n    median_expr = np.median(counts, axis=0)\n\n    # Find genes that are expressed in at least some cells\n    # Genes with median = 0 are likely unexpressed or very lowly expressed\n    expressed_idx = np.where(median_expr > 0)[0]\n\n    # Sort expressed genes by their median expression level\n    sorted_idx = expressed_idx[np.argsort(median_expr[expressed_idx])]\n\n    # Select evenly spaced genes across the expression spectrum\n    # This ensures we sample from low, medium, and high expression ranges\n    spaced_indices = np.linspace(0, len(sorted_idx) - 1, num=n_genes, dtype=int)\n    selected_idx = sorted_idx[spaced_indices]\n\n    return selected_idx, median_expr\n\n\n# Select genes using our strategic approach\nn_genes_to_plot = 25\nselected_idx, median_expr = select_genes_for_visualization(\n    counts, n_genes=n_genes_to_plot\n)\n\n# Sort selected indices - this is crucial for proper indexing of results!\n# This ensures correspondence between subset results and original gene indices\nselected_idx = np.sort(selected_idx)\n\nprint(f\"Selected {len(selected_idx)} genes for PPC analysis\")\nprint(\n    f\"Expression range: {median_expr[selected_idx].min():.2f} - \"\n    f\"{median_expr[selected_idx].max():.2f}\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are now ready to generate the PPC samples. We will generate 500 samples,\ni.e., 500 simulated datasets with the same number of cells $\\times$ the\nnumber of genes we selected.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_samples = (\n    500  # Can use more samples now since we're only doing selected genes\n)\n\n# Subset results to selected genes before generating samples (major memory\n# savings!)\nresults_nbdm_subset = results_nbdm[selected_idx]\n# Generate the PPC samples\nppc_nbdm = results_nbdm_subset.get_ppc_samples(\n    n_samples=n_samples, rng_key=random.PRNGKey(seed)\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, since we will generate a plot for each selected gene, we need to\ncalculate the optimal number of rows and columns for the plot grid. Let's\ndefine a simple function to do this.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def calculate_subplot_grid(n_plots):\n    \"\"\"\n    Calculate optimal subplot grid dimensions for a given number of plots.\n\n    Tries to create a square or near-square grid that accommodates all plots.\n\n    Parameters\n    ----------\n    n_plots : int\n        Number of subplots needed\n\n    Returns\n    -------\n    nrows, ncols : int, int\n        Number of rows and columns for the subplot grid\n    \"\"\"\n    import math\n\n    # For perfect squares, use square grid\n    sqrt_n = int(math.sqrt(n_plots))\n    if sqrt_n * sqrt_n == n_plots:\n        return sqrt_n, sqrt_n\n\n    # For non-perfect squares, find the closest rectangular grid\n    # that minimizes empty subplots\n    for cols in range(sqrt_n, n_plots + 1):\n        rows = math.ceil(n_plots / cols)\n        if (\n            rows * cols >= n_plots and abs(rows - cols) <= 2\n        ):  # Prefer near-square\n            return rows, cols\n\n    # Fallback: use ceiling of square root\n    rows = math.ceil(math.sqrt(n_plots))\n    cols = math.ceil(n_plots / rows)\n    return rows, cols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Posterior Predictive Check Visualization\n\nWe are ready to plot the PPCs. We will plot the credible regions for each gene\nas colored bands, and the observed data as a black line. We will also plot the\nmedian expression for each gene. `SCRIBE` provides several useful functions to\ngenerate these plots.\n\n.. admonition:: Interpreting the Plots\n  - The colored regions show credible intervals (95%, 68%, 50%) of the model's\n  predictions across multiple posterior samples.\n  -  The black line shows the actual observed data distribution.\n  - Good fit: observed data falls mostly within the credible regions.\n  - Poor fit: observed data consistently falls outside credible regions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot PPCs for selected genes with dynamic grid layout\nn_genes_to_plot = len(selected_idx)\nnrows, ncols = calculate_subplot_grid(n_genes_to_plot)\nfig_width = max(12, ncols * 3)  # Minimum 12 inches, scale with columns\nfig_height = max(8, nrows * 2.5)  # Minimum 8 inches, scale with rows\n\n# Print the number of rows and columns for the plot grid\nprint(f\"Creating {nrows}x{ncols} grid for {n_genes_to_plot} genes\")\n\n# Initialize the plot\nfig, axes = plt.subplots(nrows, ncols, figsize=(fig_width, fig_height))\n# Flatten the axes if we have more than one gene to plot\naxes = axes.flatten() if n_genes_to_plot > 1 else [axes]\n\n# Add a title to the plot\nfig.suptitle(\n    f\"NBDM Posterior Predictive Checks ({n_genes_to_plot} genes)\",\n    y=0.98,\n    fontsize=16,\n)\n\n# Loop over the genes to plot\nfor i in range(n_genes_to_plot):\n    ax = axes[i]\n    gene_idx = selected_idx[i]\n    gene_median_expr = median_expr[gene_idx]\n\n    print(\n        f\"Generating PPC for gene {gene_idx} \"\n        f\"(median expression: {gene_median_expr:.2f})\"\n    )\n\n    # Compute credible regions for this gene's predicted counts\n    # Note: gene_idx is now the index within selected genes, not the original\n    # dataset\n    credible_regions = scribe.stats.compute_histogram_credible_regions(\n        ppc_nbdm[\"predictive_samples\"][\n            :, :, i\n        ],  # Use i (position in selected genes)\n        credible_regions=[95, 68, 50],\n    )\n\n    # Plot the credible regions as colored bands\n    scribe.viz.plot_histogram_credible_regions_stairs(\n        ax, credible_regions, cmap=\"Blues\", alpha=0.5\n    )\n\n    # Calculate and plot the observed data histogram\n    bin_edges = credible_regions[\"bin_edges\"]\n    hist, _ = np.histogram(counts[:, gene_idx], bins=bin_edges, density=True)\n    ax.stairs(\n        hist, bin_edges, color=\"black\", alpha=0.8, linewidth=2, label=\"Observed\"\n    )\n\n    # Enhanced axis labels with expression information\n    ax.set_xlabel(f\"UMI counts\")\n    ax.set_ylabel(\"density\")\n    ax.set_title(\n        f\"{adata.var.index.values[gene_idx]}\\n\"\n        f\"(Median expr: {gene_median_expr:.1f})\",\n        fontsize=10,\n    )\n    ax.legend(fontsize=8)\n\n    # Improve readability for low-count genes\n    if gene_median_expr < 1.0:\n        ax.set_xlim(0, max(10, np.percentile(counts[:, gene_idx], 95)))\n\n# Hide empty subplots if we have more subplot positions than genes\nfor j in range(n_genes_to_plot, len(axes)):\n    axes[j].axis(\"off\")\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the fit is already pretty good. Most of the observed counts\nfall within the colored regions, meaning that the inferred parameters are able\nto capture the observed data. However, we can improve the fit by using a more\nsophisticated model.\n\n## Model 2: NBDM with Variable Capture Probability (NBVCP)\n\nThe basic NBDM model assumes that the capture efficiency\u2014the probability of an\nmRNA molecule being captured and sequenced as a UMI\u2014is constant for all cells.\nHowever, this is often not true in practice due to technical variations. To\ndemonstrate this, let's plot the distribution of total UMI counts for each\ncell.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Initialize figure\nfig, ax = plt.subplots(figsize=(3.5, 3))\nsns.histplot(counts.sum(axis=1), bins=100, ax=ax)\nax.set_xlabel(\"total UMI counts\")\nax.set_ylabel(\"count\")\nax.set_title(\"Distribution of Total UMI Counts\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These cells were already filtered for quality and still we have cells with\n$\\approx$ 5,000 UMIs vs cells with $\\approx$ 40,000 UMIs. This is\nunlikely to be due to biological differences, but rather to technical\ndifferences in the capture efficiency.\n\n``SCRIBE`` can account for this by using a Variable Capture Probability (VCP)\nmodel. As mentioned earlier, in the derivation of the NBDM model, we assumed\nall mRNA counts to be negative-binomially distributed. However, what we\nobserve in an experiment are not the mRNA counts, but the UMIs. The simplest\nway to account for this conversion is to assume that each mRNA molecule in\ncell $c$ has a probability $\\nu^{(c)}$ of being captured and\nsequenced as a UMI. We can show that after accounting for this effect, the\nresulting UMI counts distribution is also negative-binomially distributed.\nHowever, the parameter $p$ is modified in a non-linear was as\n\n\\begin{align}\\hat{p}^{(c)} = \\frac{p}{\\nu^{(c)} + p (1 - \\nu^{(c)})}.\\end{align}\n\nIn this model, the capture efficiency $\\nu^{(c)}$ is a cell-specific\nlatent variable that is inferred from the data. This allows the model to\ndistinguish between biological zeros (genes not expressed) and technical zeros\n(genes expressed but not detected).\n\n.. important::\n  Note that this is very different from the conventional approach of assuming\n  a zero-inflated negative binomial distribution (which ``SCRIBE`` also\n  supports). Zero-inflation in that sense is a per-gene parameter, while our\n  approach is a per-cell parameter. Although it might be possible that there\n  is a per-gene capture efficiency across all cells, we find it much more\n  likely that the tehcnical variation comes from processing each cell\n  separately.\n\nLet's fit the NBVCP model. The beauty of the API is that we can fit this\nvariant by simply passing the ``variable_capture=True`` flag.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Simple caching for NBVCP model\ncache_file = os.path.join(\n    CACHE_DIR,\n    f\"svi_quickstart_nbvcp_standard_{n_genes}genes_{n_steps}steps.pkl\",\n)\nif os.path.exists(cache_file):\n    print(f\"Loading NBVCP results from {cache_file}\")\n    with open(cache_file, \"rb\") as f:\n        results_vcp = pickle.load(f)\nelse:\n    print(\"Running NBVCP model...\")\n    results_vcp = scribe.run_scribe(\n        counts=counts,\n        variable_capture=True,  # this is the only difference from the NBDM model\n        n_steps=n_steps,\n        batch_size=batch_size,\n        seed=seed,\n    )\n    with open(cache_file, \"wb\") as f:\n        pickle.dump(results_vcp, f)\n    print(f\"Saved NBVCP results to {cache_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing Results for NBVCP\n\nNow, let's look at the diagnostics for the NBVCP model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot ELBO loss history\nfig, ax = plt.subplots(figsize=(3.5, 3))\nax.plot(results_vcp.loss_history)\nax.set_xlabel(\"Step\")\nax.set_ylabel(\"ELBO Loss\")\nax.set_title(\"NBVCP ELBO Loss\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As before, we can visualize the posterior predictive checks for the NBVCP\nmodel. The unified API makes it straightforward to do so by following the same\nsteps as before.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Generate PPC samples for the NBVCP model (using same gene subset)\nresults_vcp_subset = results_vcp[selected_idx]\nppc_vcp = results_vcp_subset.get_ppc_samples(\n    n_samples=n_samples, rng_key=random.PRNGKey(seed)\n)\n\n# Plot PPCs using the same strategically selected genes for fair comparison\nfig, axes = plt.subplots(nrows, ncols, figsize=(fig_width, fig_height))\naxes = axes.flatten() if n_genes_to_plot > 1 else [axes]\nfig.suptitle(\n    f\"NBVCP Posterior Predictive Checks ({n_genes_to_plot} genes)\\n\"\n    f\"(Same Gene Selection for Comparison)\",\n    y=0.98,\n    fontsize=16,\n)\n\nfor i in range(n_genes_to_plot):\n    ax = axes[i]\n    gene_idx = selected_idx[i]\n    gene_median_expr = median_expr[gene_idx]\n\n    print(\n        f\"Generating NBVCP PPC for gene {gene_idx} \"\n        f\"(median expression: {gene_median_expr:.2f})\"\n    )\n\n    # Compute credible regions for this gene's predicted counts\n    credible_regions = scribe.stats.compute_histogram_credible_regions(\n        ppc_vcp[\"predictive_samples\"][\n            :, :, i\n        ],  # Use i (position in selected genes)\n        credible_regions=[95, 68, 50],\n    )\n\n    # Plot the credible regions using green colormap to distinguish from NBDM\n    scribe.viz.plot_histogram_credible_regions_stairs(\n        ax, credible_regions, cmap=\"Greens\", alpha=0.5\n    )\n\n    # Calculate and plot the observed data histogram\n    bin_edges = credible_regions[\"bin_edges\"]\n    hist, _ = np.histogram(counts[:, gene_idx], bins=bin_edges, density=True)\n    ax.stairs(\n        hist, bin_edges, color=\"black\", alpha=0.8, linewidth=2, label=\"Observed\"\n    )\n\n    # Enhanced axis labels with expression information\n    ax.set_xlabel(f\"UMI counts\")\n    ax.set_ylabel(\"density\")\n    ax.set_title(\n        f\"{adata.var.index.values[gene_idx]}\\n\"\n        f\"(Median expr: {gene_median_expr:.1f})\",\n        fontsize=10,\n    )\n    ax.legend(fontsize=8)\n\n    # Improve readability for low-count genes\n    if gene_median_expr < 1.0:\n        ax.set_xlim(0, max(10, np.percentile(counts[:, gene_idx], 95)))\n\n# Hide empty subplots if we have more subplot positions than genes\nfor j in range(n_genes_to_plot, len(axes)):\n    axes[j].axis(\"off\")\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this particular dataset, the difference between the NBDM and NBVCP models\nis not very pronounced. However, in general, we recommend using the NBVCP\nmodel when there is evidence of technical variation in the capture efficiency.\n\nMoreover, even though the data falls within the colored regions, there also\nseems to be \"unnecessary\" uncertainty. Take for example the HSP90AB1 gene\n(second row, third column). Even though the data falls within the colored\nregions, these regions seem to be unnecessarily wide. The reason for this is\nsubtle but important: When performing SVI, we use what is called a\n\"mean-field\" approximaiton. This means that we fit each parameter\nindependently, ignoring all possible correlations between parameters. This\nallows us to use the power of modern gradient-based optimizers to find the\noptimal parameters. However, this also bring an issue when working with the\nnegative binomial distribution, where the $r$ and $p$ parameters\ntrade-off with each other---meaning that increasing one parameter while\ndecreasing the other results in a distribution with a very similar shape.\n\nTo address this issue, ``SCRIBE`` comes with two other parameterizations of\nthe same base NBDM model:\n\n- the ``linked`` parameterization, in which we fit the same $p$\n  parameter, but instead of fitting the $r$ parameter, we fit the\n  distribution mean $\\mu$ parameter. We then can recover the $r$\n  parameter as $r = \\mu * (1 - p) / p$.\n- the ``odds-ratio`` parameterization, in which we fit the so-called\n  odds-ratio $\\phi = (1 - p) / p$ parameter, and the $\\mu$\n  parameter. We then can recover the $r$ parameter as $r = \\mu *\n  \\phi$.\n\nChanging between parameterizations is as simple as passing the appropriate\n``parameterization`` flag to the ``run_scribe`` function. Let's fit the NBVCP\nmodel with the odds-ratio parameterization.\n\n## Model 3: Odds-Ratio Parameterization\n\nThis reparameterization can lead to more stable and efficient inference,\nespecially when the success probability `p` is very close to 0 or 1. Moreover,\nbecause of the mean-field approximation done for stochastic variational\ninference, this parameterization captures the known correlation between the\n`r` and `p` parameters by fitting the mean `mu` instead of the dispersion `r`.\nThis results in much better posterior predictive checks.\n\nLet's fit the NBVCP model with the odds-ratio parameterization. Again, we can\ndo this by simply passing the `parameterization=\"odds_ratio\"` flag.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Simple caching for Odds-Ratio NBVCP model\ncache_file = os.path.join(\n    CACHE_DIR,\n    f\"svi_quickstart_nbvcp_odds-ratio_{n_genes}genes_{n_steps}steps.pkl\",\n)\nif os.path.exists(cache_file):\n    print(f\"Loading Odds-Ratio NBVCP results from {cache_file}\")\n    with open(cache_file, \"rb\") as f:\n        results_or = pickle.load(f)\nelse:\n    print(\"Running Odds-Ratio NBVCP model...\")\n    results_or = scribe.run_scribe(\n        counts=counts,\n        variable_capture=True,\n        parameterization=\"odds_ratio\",\n        n_steps=n_steps,\n        batch_size=batch_size,\n        seed=seed,\n    )\n    with open(cache_file, \"wb\") as f:\n        pickle.dump(results_or, f)\n    print(f\"Saved Odds-Ratio NBVCP results to {cache_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing Results for Odds-Ratio Model\n\nFinally, let's check the diagnostics for the odds-ratio model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot ELBO loss history\nfig, ax = plt.subplots(figsize=(3.5, 3))\nax.plot(results_or.loss_history)\nax.set_xlabel(\"Step\")\nax.set_ylabel(\"ELBO Loss\")\nax.set_title(\"Odds-Ratio NBVCP ELBO Loss\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the PPCs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Generate PPC samples for the odds-ratio model (using same gene subset)\nresults_or_subset = results_or[selected_idx]\nppc_or = results_or_subset.get_ppc_samples(\n    n_samples=n_samples, rng_key=random.PRNGKey(seed)\n)\n\n# Plot PPCs using the same strategically selected genes for consistent comparison\nfig, axes = plt.subplots(nrows, ncols, figsize=(fig_width, fig_height))\naxes = axes.flatten() if n_genes_to_plot > 1 else [axes]\nfig.suptitle(\n    f\"Odds-Ratio NBVCP Posterior Predictive Checks ({n_genes_to_plot} genes)\\n\"\n    f\"(Consistent Gene Selection)\",\n    y=0.98,\n    fontsize=16,\n)\n\nfor i in range(n_genes_to_plot):\n    ax = axes[i]\n    gene_idx = selected_idx[i]\n    gene_median_expr = median_expr[gene_idx]\n\n    print(\n        f\"Generating Odds-Ratio PPC for gene {gene_idx} \"\n        f\"(median expression: {gene_median_expr:.2f})\"\n    )\n\n    # Compute credible regions for this gene's predicted counts\n    credible_regions = scribe.stats.compute_histogram_credible_regions(\n        ppc_or[\"predictive_samples\"][\n            :, :, i\n        ],  # Use i (position in selected genes)\n        credible_regions=[95, 68, 50],\n    )\n\n    # Plot the credible regions using orange colormap to distinguish from other\n    # models\n    scribe.viz.plot_histogram_credible_regions_stairs(\n        ax, credible_regions, cmap=\"Oranges\", alpha=0.5\n    )\n\n    # Calculate and plot the observed data histogram\n    bin_edges = credible_regions[\"bin_edges\"]\n    hist, _ = np.histogram(counts[:, gene_idx], bins=bin_edges, density=True)\n    ax.stairs(\n        hist, bin_edges, color=\"black\", alpha=0.8, linewidth=2, label=\"Observed\"\n    )\n\n    # Enhanced axis labels with expression information\n    ax.set_xlabel(f\"UMI counts\")\n    ax.set_ylabel(\"density\")\n    ax.set_title(\n        f\"{adata.var.index.values[gene_idx]}\\n\"\n        f\"(Median expr: {gene_median_expr:.1f})\",\n        fontsize=10,\n    )\n    ax.legend(fontsize=8)\n\n    # Improve readability for low-count genes\n    if gene_median_expr < 1.0:\n        ax.set_xlim(0, max(10, np.percentile(counts[:, gene_idx], 95)))\n\n# Hide empty subplots if we have more subplot positions than genes\nfor j in range(n_genes_to_plot, len(axes)):\n    axes[j].axis(\"off\")\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, the posterior predictive checks for this parameterization look\nmuch tighter compared to the previous two models. Looking at our HSP90AB1 gene\n(second row, third column), we can see that the posterior predictive checks\nare much tighter compared to the previous two models.\n\nCapturing the correlation between the $r$ and $p$ parameters by\nfitting the mean and the odds-ratio parameter allows the simulated datasets to\nbetter match the observed data.\n\n## Conclusion\n\nIn this tutorial, we demonstrated how to use ``SCRIBE`` to fit the NBDM,\nNBVCP, and odds-ratio models to a single-cell RNA-seq dataset. We also\nvisualized the results of the models and compared the posterior predictive\nchecks. We saw that the odds-ratio parameterization leads to much tighter\nposterior predictive checks compared to the other two models. ``SCRIBE`` is a\nversatile tool that has more models and parameterizations to explore. We\ninvite you to explore the rest of the documentation to learn more about how\ncan ``SCRIBE`` help you analyze your own data.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}