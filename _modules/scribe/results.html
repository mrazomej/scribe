

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>scribe.results &mdash; SCRIBE  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            SCRIBE
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quickoverview.html">Quick Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quickstart</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Available Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../models/index.html">Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../results.html">Results Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/index.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/index.html">Examples</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">SCRIBE</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">scribe.results</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for scribe.results</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Results classes for SCRIBE inference.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Any</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">replace</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
<span class="kn">import</span> <span class="nn">jax.scipy</span> <span class="k">as</span> <span class="nn">jsp</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpyro.distributions</span> <span class="k">as</span> <span class="nn">dist</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">random</span><span class="p">,</span> <span class="n">jit</span><span class="p">,</span> <span class="n">vmap</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>

<span class="kn">from</span> <span class="nn">.sampling</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">sample_variational_posterior</span><span class="p">,</span> 
    <span class="n">generate_predictive_samples</span><span class="p">,</span> 
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">.stats</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">fit_dirichlet_minka</span><span class="p">,</span> 
    <span class="n">get_distribution_mode</span><span class="p">,</span>
    <span class="n">hellinger_gamma</span><span class="p">,</span>
    <span class="n">hellinger_lognormal</span><span class="p">,</span>
    <span class="n">kl_gamma</span><span class="p">,</span>
    <span class="n">kl_lognormal</span><span class="p">,</span>
    <span class="n">jensen_shannon_gamma</span><span class="p">,</span>
    <span class="n">jensen_shannon_lognormal</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">.model_config</span> <span class="kn">import</span> <span class="n">ModelConfig</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">numpyro_to_scipy</span>

<span class="kn">from</span> <span class="nn">.cell_assignment</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">temperature_scaling</span>
<span class="p">)</span>

<span class="c1"># ------------------------------------------------------------------------------</span>
<span class="c1"># Base class for inference results</span>
<span class="c1"># ------------------------------------------------------------------------------</span>

<div class="viewcode-block" id="ScribeResults">
<a class="viewcode-back" href="../../api/results.html#scribe.results.ScribeResults">[docs]</a>
<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">ScribeResults</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for SCRIBE inference results.</span>
<span class="sd">    </span>
<span class="sd">    This class stores the results from SCRIBE&#39;s variational inference procedure,</span>
<span class="sd">    including model parameters, loss history, dataset dimensions, and model</span>
<span class="sd">    configuration. It can optionally store metadata from an AnnData object and</span>
<span class="sd">    posterior/predictive samples.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    params : Dict</span>
<span class="sd">        Dictionary of inferred model parameters from SCRIBE</span>
<span class="sd">    loss_history : jnp.ndarray</span>
<span class="sd">        Array containing the ELBO loss values during training</span>
<span class="sd">    n_cells : int</span>
<span class="sd">        Number of cells in the dataset</span>
<span class="sd">    n_genes : int</span>
<span class="sd">        Number of genes in the dataset</span>
<span class="sd">    model_type : str</span>
<span class="sd">        Type of model used for inference</span>
<span class="sd">    model_config : ModelConfig</span>
<span class="sd">        Configuration object specifying model architecture and priors</span>
<span class="sd">    prior_params : Dict[str, Any]</span>
<span class="sd">        Dictionary of prior parameter values used during inference</span>
<span class="sd">    obs : Optional[pd.DataFrame]</span>
<span class="sd">        Cell-level metadata from adata.obs, if provided</span>
<span class="sd">    var : Optional[pd.DataFrame]</span>
<span class="sd">        Gene-level metadata from adata.var, if provided</span>
<span class="sd">    uns : Optional[Dict]</span>
<span class="sd">        Unstructured metadata from adata.uns, if provided</span>
<span class="sd">    n_obs : Optional[int]</span>
<span class="sd">        Number of observations (cells), if provided</span>
<span class="sd">    n_vars : Optional[int]</span>
<span class="sd">        Number of variables (genes), if provided</span>
<span class="sd">    posterior_samples : Optional[Dict]</span>
<span class="sd">        Samples of parameters from the posterior distribution, if generated</span>
<span class="sd">    predictive_samples : Optional[Dict]</span>
<span class="sd">        Predictive samples generated from the model, if generated</span>
<span class="sd">    n_components : Optional[int]</span>
<span class="sd">        Number of mixture components, if using a mixture model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Core inference results</span>
    <span class="n">params</span><span class="p">:</span> <span class="n">Dict</span>
    <span class="n">loss_history</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">n_cells</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">n_genes</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">model_type</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">model_config</span><span class="p">:</span> <span class="n">ModelConfig</span>
    <span class="n">prior_params</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>

    <span class="c1"># Standard metadata from AnnData object</span>
    <span class="n">obs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">var</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">uns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">n_obs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">n_vars</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    
    <span class="c1"># Optional results</span>
    <span class="n">posterior_samples</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">predictive_samples</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">n_components</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># --------------------------------------------------------------------------</span>

<div class="viewcode-block" id="ScribeResults.__post_init__">
<a class="viewcode-back" href="../../api/results.html#scribe.results.ScribeResults.__post_init__">[docs]</a>
    <span class="k">def</span> <span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Validate model configuration and parameters.&quot;&quot;&quot;</span>
        <span class="c1"># Set n_components from model_config if not explicitly provided</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">n_components</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">n_components</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_model_config</span><span class="p">()</span></div>


    <span class="c1"># --------------------------------------------------------------------------</span>

    <span class="k">def</span> <span class="nf">_validate_model_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Validate model configuration matches model type.&quot;&quot;&quot;</span>
        <span class="c1"># Validate base model</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">base_model</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Model type &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&#39; does not match config &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;base model &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">base_model</span><span class="si">}</span><span class="s2">&#39;&quot;</span>
            <span class="p">)</span>
        
        <span class="c1"># Validate n_components consistency</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_mix&#39;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Model type &#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="si">}</span><span class="s2">&#39; is not a mixture model &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;but n_components=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="si">}</span><span class="s2"> was specified&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">n_components</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;n_components mismatch: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="si">}</span><span class="s2"> vs &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">n_components</span><span class="si">}</span><span class="s2"> in model_config&quot;</span>
                <span class="p">)</span>
                
        <span class="c1"># Validate required distributions based on model type</span>
        <span class="k">if</span> <span class="s2">&quot;zinb&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">gate_distribution_model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> 
                <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">gate_distribution_guide</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;ZINB models require gate distributions&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">gate_distribution_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> 
                <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">gate_distribution_guide</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Non-ZINB models should not have gate distributions&quot;</span><span class="p">)</span>
                
        <span class="k">if</span> <span class="s2">&quot;vcp&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">p_capture_distribution_model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">p_capture_distribution_guide</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;VCP models require capture probability distributions&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">p_capture_distribution_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">p_capture_distribution_guide</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Non-VCP models should not have capture probability distributions&quot;</span>
                <span class="p">)</span>

    <span class="c1"># --------------------------------------------------------------------------</span>
    <span class="c1"># Create ScribeResults from AnnData object</span>
    <span class="c1"># --------------------------------------------------------------------------</span>

<div class="viewcode-block" id="ScribeResults.from_anndata">
<a class="viewcode-back" href="../../api/results.html#scribe.results.ScribeResults.from_anndata">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_anndata</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">adata</span><span class="p">:</span> <span class="s2">&quot;AnnData&quot;</span><span class="p">,</span>
        <span class="n">params</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">loss_history</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">model_config</span><span class="p">:</span> <span class="n">ModelConfig</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create ScribeResults from AnnData object.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
            <span class="n">loss_history</span><span class="o">=</span><span class="n">loss_history</span><span class="p">,</span>
            <span class="n">n_cells</span><span class="o">=</span><span class="n">adata</span><span class="o">.</span><span class="n">n_obs</span><span class="p">,</span>
            <span class="n">n_genes</span><span class="o">=</span><span class="n">adata</span><span class="o">.</span><span class="n">n_vars</span><span class="p">,</span>
            <span class="n">model_config</span><span class="o">=</span><span class="n">model_config</span><span class="p">,</span>
            <span class="n">obs</span><span class="o">=</span><span class="n">adata</span><span class="o">.</span><span class="n">obs</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
            <span class="n">var</span><span class="o">=</span><span class="n">adata</span><span class="o">.</span><span class="n">var</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
            <span class="n">uns</span><span class="o">=</span><span class="n">adata</span><span class="o">.</span><span class="n">uns</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
            <span class="n">n_obs</span><span class="o">=</span><span class="n">adata</span><span class="o">.</span><span class="n">n_obs</span><span class="p">,</span>
            <span class="n">n_vars</span><span class="o">=</span><span class="n">adata</span><span class="o">.</span><span class="n">n_vars</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span></div>

    
    <span class="c1"># --------------------------------------------------------------------------</span>
    <span class="c1"># Get distributions using configs</span>
    <span class="c1"># --------------------------------------------------------------------------</span>

<div class="viewcode-block" id="ScribeResults.get_distributions">
<a class="viewcode-back" href="../../api/results.html#scribe.results.ScribeResults.get_distributions">[docs]</a>
    <span class="k">def</span> <span class="nf">get_distributions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">backend</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;scipy&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the variational distributions for all parameters using model config.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        backend : str, default=&quot;scipy&quot;</span>
<span class="sd">            Statistical package to use for distributions. Must be one of:</span>
<span class="sd">            - &quot;scipy&quot;: Returns scipy.stats distributions</span>
<span class="sd">            - &quot;numpyro&quot;: Returns numpyro.distributions</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Dict[str, Any]</span>
<span class="sd">            Dictionary mapping parameter names to their distributions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">backend</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;scipy&quot;</span><span class="p">,</span> <span class="s2">&quot;numpyro&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid backend: </span><span class="si">{</span><span class="n">backend</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            
        <span class="n">distributions</span> <span class="o">=</span> <span class="p">{}</span>
        
        <span class="c1"># Handle r distribution</span>
        <span class="n">r_params</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">r_distribution_guide</span><span class="o">.</span><span class="n">arg_constraints</span><span class="p">:</span>
            <span class="n">r_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;r_</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span>
        
        <span class="k">if</span> <span class="n">backend</span> <span class="o">==</span> <span class="s2">&quot;scipy&quot;</span><span class="p">:</span>
            <span class="n">distributions</span><span class="p">[</span><span class="s1">&#39;r&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpyro_to_scipy</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">r_distribution_guide</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="o">**</span><span class="n">r_params</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># numpyro</span>
            <span class="n">distributions</span><span class="p">[</span><span class="s1">&#39;r&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">r_distribution_guide</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="o">**</span><span class="n">r_params</span><span class="p">)</span>
        
        <span class="c1"># Handle p distribution</span>
        <span class="n">p_params</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">p_distribution_guide</span><span class="o">.</span><span class="n">arg_constraints</span><span class="p">:</span>
            <span class="n">p_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;p_</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span>
        
        <span class="k">if</span> <span class="n">backend</span> <span class="o">==</span> <span class="s2">&quot;scipy&quot;</span><span class="p">:</span>
            <span class="n">distributions</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpyro_to_scipy</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">p_distribution_guide</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="o">**</span><span class="n">p_params</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># numpyro</span>
            <span class="n">distributions</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">p_distribution_guide</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="o">**</span><span class="n">p_params</span><span class="p">)</span>
        
        <span class="c1"># Add gate distribution if present</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">gate_distribution_guide</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">gate_params</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">gate_distribution_guide</span><span class="o">.</span><span class="n">arg_constraints</span><span class="p">:</span>
                <span class="n">gate_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;gate_</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span>
                
            <span class="k">if</span> <span class="n">backend</span> <span class="o">==</span> <span class="s2">&quot;scipy&quot;</span><span class="p">:</span>
                <span class="n">distributions</span><span class="p">[</span><span class="s1">&#39;gate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpyro_to_scipy</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">gate_distribution_guide</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="o">**</span><span class="n">gate_params</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># numpyro</span>
                <span class="n">distributions</span><span class="p">[</span><span class="s1">&#39;gate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">gate_distribution_guide</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="o">**</span><span class="n">gate_params</span><span class="p">)</span>
            
        <span class="c1"># Add p_capture distribution if present</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">p_capture_distribution_guide</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">p_capture_params</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">p_capture_distribution_guide</span><span class="o">.</span><span class="n">arg_constraints</span><span class="p">:</span>
                <span class="n">p_capture_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;p_capture_</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span>
                
            <span class="k">if</span> <span class="n">backend</span> <span class="o">==</span> <span class="s2">&quot;scipy&quot;</span><span class="p">:</span>
                <span class="n">distributions</span><span class="p">[</span><span class="s1">&#39;p_capture&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpyro_to_scipy</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">p_capture_distribution_guide</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="o">**</span><span class="n">p_capture_params</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># numpyro</span>
                <span class="n">distributions</span><span class="p">[</span><span class="s1">&#39;p_capture&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">p_capture_distribution_guide</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="o">**</span><span class="n">p_capture_params</span><span class="p">)</span>
            
        <span class="c1"># Add mixing weights if mixture model</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">n_components</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Extract mixing weights</span>
            <span class="n">mixing_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;mixing_concentration&quot;</span><span class="p">]</span>
            
            <span class="k">if</span> <span class="n">backend</span> <span class="o">==</span> <span class="s2">&quot;scipy&quot;</span><span class="p">:</span>
                <span class="n">distributions</span><span class="p">[</span><span class="s1">&#39;mixing_weights&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">numpyro_to_scipy</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">mixing_distribution_guide</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span>
                        <span class="n">concentration</span><span class="o">=</span><span class="n">mixing_params</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">distributions</span><span class="p">[</span><span class="s1">&#39;mixing_weights&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">mixing_distribution_guide</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span>
                    <span class="n">concentration</span><span class="o">=</span><span class="n">mixing_params</span>
                <span class="p">)</span>
        
        <span class="k">return</span> <span class="n">distributions</span></div>


    <span class="c1"># --------------------------------------------------------------------------</span>

<div class="viewcode-block" id="ScribeResults.get_map">
<a class="viewcode-back" href="../../api/results.html#scribe.results.ScribeResults.get_map">[docs]</a>
    <span class="k">def</span> <span class="nf">get_map</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">use_mean</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the maximum a posteriori (MAP) estimates from the variational</span>
<span class="sd">        posterior.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        use_mean : bool, default=False</span>
<span class="sd">            If True, replaces undefined MAP values (NaN) with posterior means</span>
<span class="sd">        verbose : bool, default=True</span>
<span class="sd">            If True, prints a warning if NaNs were replaced with means</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Dict[str, jnp.ndarray]</span>
<span class="sd">            Dictionary of MAP estimates for each parameter</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get distributions with NumPyro backend</span>
        <span class="n">distributions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_distributions</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s2">&quot;numpyro&quot;</span><span class="p">)</span>
        <span class="c1"># Get estimate of map</span>
        <span class="n">map_estimates</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">param</span><span class="p">:</span> <span class="n">get_distribution_mode</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span> 
            <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">dist</span> <span class="ow">in</span> <span class="n">distributions</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>

        <span class="c1"># Replace NaN values with means if requested</span>
        <span class="k">if</span> <span class="n">use_mean</span><span class="p">:</span>
            <span class="c1"># Initialize boolean to track if any NaNs were replaced</span>
            <span class="n">replaced_nans</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="c1"># Check each parameter for NaNs and replace with means</span>
            <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">map_estimates</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="c1"># Check if any values are NaN</span>
                <span class="k">if</span> <span class="n">jnp</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">value</span><span class="p">)):</span>
                    <span class="n">replaced_nans</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="c1"># Get mean value</span>
                    <span class="n">mean_value</span> <span class="o">=</span> <span class="n">distributions</span><span class="p">[</span><span class="n">param</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span>
                    <span class="c1"># Replace NaN values with means</span>
                    <span class="n">map_estimates</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                        <span class="n">jnp</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">value</span><span class="p">),</span>
                        <span class="n">mean_value</span><span class="p">,</span>
                        <span class="n">value</span>
                    <span class="p">)</span>
            <span class="c1"># Print warning if NaNs were replaced</span>
            <span class="k">if</span> <span class="n">replaced_nans</span> <span class="ow">and</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;NaN values were replaced with means of the distributions&quot;</span><span class="p">,</span>
                    <span class="ne">UserWarning</span>
                <span class="p">)</span>

        <span class="k">return</span> <span class="n">map_estimates</span></div>


    <span class="c1"># --------------------------------------------------------------------------</span>
    <span class="c1"># Indexing by genes</span>
    <span class="c1"># --------------------------------------------------------------------------</span>

    <span class="k">def</span> <span class="nf">_subset_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a new parameter dictionary for the given index.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
        
        <span class="c1"># Handle r parameters (always gene-specific)</span>
        <span class="n">r_param_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">r_distribution_guide</span><span class="o">.</span><span class="n">arg_constraints</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="n">r_param_names</span><span class="p">:</span>
            <span class="n">param_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;r_</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">if</span> <span class="n">param_key</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># Keep component dimension but subset gene dimension</span>
                    <span class="n">new_params</span><span class="p">[</span><span class="n">param_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="n">param_key</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="n">index</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Just subset gene dimension</span>
                    <span class="n">new_params</span><span class="p">[</span><span class="n">param_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="n">param_key</span><span class="p">][</span><span class="n">index</span><span class="p">]</span>
        
        <span class="c1"># Handle gate parameters if present (gene-specific)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">gate_distribution_guide</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">gate_param_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">gate_distribution_guide</span><span class="o">.</span><span class="n">arg_constraints</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="n">gate_param_names</span><span class="p">:</span>
                <span class="n">param_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;gate_</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="k">if</span> <span class="n">param_key</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="c1"># Keep component dimension but subset gene dimension</span>
                        <span class="n">new_params</span><span class="p">[</span><span class="n">param_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="n">param_key</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="n">index</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># Just subset gene dimension</span>
                        <span class="n">new_params</span><span class="p">[</span><span class="n">param_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="n">param_key</span><span class="p">][</span><span class="n">index</span><span class="p">]</span>
        
        <span class="k">return</span> <span class="n">new_params</span>

    <span class="c1"># --------------------------------------------------------------------------</span>

    <span class="k">def</span> <span class="nf">_subset_posterior_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a new posterior samples dictionary for the given index.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        samples : Dict</span>
<span class="sd">            Dictionary of samples from the posterior distribution, where each</span>
<span class="sd">            key represents a parameter type (&#39;r&#39;, &#39;p&#39;, &#39;gate&#39;, etc.) and values</span>
<span class="sd">            are arrays of samples</span>
<span class="sd">        index : array-like</span>
<span class="sd">            Boolean or integer index specifying which genes to keep</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Dict</span>
<span class="sd">            New dictionary containing posterior samples for the selected genes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
            
        <span class="n">new_posterior_samples</span> <span class="o">=</span> <span class="p">{}</span>
        
        <span class="c1"># Handle gene-specific parameters</span>
        
        <span class="c1"># r samples (always gene-specific)</span>
        <span class="k">if</span> <span class="s1">&#39;r&#39;</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Shape: (n_samples, n_components, n_genes)</span>
                <span class="n">new_posterior_samples</span><span class="p">[</span><span class="s1">&#39;r&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;r&#39;</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="n">index</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Shape: (n_samples, n_genes)</span>
                <span class="n">new_posterior_samples</span><span class="p">[</span><span class="s1">&#39;r&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;r&#39;</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="n">index</span><span class="p">]</span>
        
        <span class="c1"># gate samples (gene-specific if present)</span>
        <span class="k">if</span> <span class="s1">&#39;gate&#39;</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Shape: (n_samples, n_components, n_genes)</span>
                <span class="n">new_posterior_samples</span><span class="p">[</span><span class="s1">&#39;gate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;gate&#39;</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="n">index</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Shape: (n_samples, n_genes)</span>
                <span class="n">new_posterior_samples</span><span class="p">[</span><span class="s1">&#39;gate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;gate&#39;</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="n">index</span><span class="p">]</span>
        
        <span class="c1"># Copy non-gene-specific parameters as is</span>
        
        <span class="c1"># p samples (global)</span>
        <span class="k">if</span> <span class="s1">&#39;p&#39;</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
            <span class="c1"># Shape: (n_samples,) or (n_samples, n_components)</span>
            <span class="n">new_posterior_samples</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">]</span>
        
        <span class="c1"># p_capture samples (cell-specific)</span>
        <span class="k">if</span> <span class="s1">&#39;p_capture&#39;</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
            <span class="c1"># Shape: (n_samples, n_cells)</span>
            <span class="n">new_posterior_samples</span><span class="p">[</span><span class="s1">&#39;p_capture&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;p_capture&#39;</span><span class="p">]</span>
        
        <span class="c1"># mixing weights if present</span>
        <span class="k">if</span> <span class="s1">&#39;mixing_weights&#39;</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
            <span class="c1"># Shape: (n_samples, n_components)</span>
            <span class="n">new_posterior_samples</span><span class="p">[</span><span class="s1">&#39;mixing_weights&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;mixing_weights&#39;</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">new_posterior_samples</span>

    <span class="c1"># --------------------------------------------------------------------------</span>

    <span class="k">def</span> <span class="nf">_subset_predictive_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a new predictive samples array for the given index.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
            
        <span class="c1"># For predictive samples, subset the gene dimension (last dimension)</span>
        <span class="k">return</span> <span class="n">samples</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">index</span><span class="p">]</span>

    <span class="c1"># --------------------------------------------------------------------------</span>

<div class="viewcode-block" id="ScribeResults.__getitem__">
<a class="viewcode-back" href="../../api/results.html#scribe.results.ScribeResults.__getitem__">[docs]</a>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Enable indexing of ScribeResults object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle integer indexing</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="c1"># Initialize boolean index</span>
            <span class="n">bool_index</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_genes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
            <span class="c1"># Set True for the given index</span>
            <span class="n">bool_index</span> <span class="o">=</span> <span class="n">bool_index</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
            <span class="c1"># Set index to boolean index</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">bool_index</span>
        
        <span class="c1"># Handle slice indexing</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="nb">slice</span><span class="p">):</span>
            <span class="c1"># Get indices from slice</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_genes</span><span class="p">)[</span><span class="n">index</span><span class="p">]</span>
            <span class="c1"># Initialize boolean index</span>
            <span class="n">bool_index</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_genes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
            <span class="c1"># Set True for the given indices</span>
            <span class="n">bool_index</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_genes</span><span class="p">),</span> <span class="n">indices</span><span class="p">)</span>
            <span class="c1"># Set index to boolean index</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">bool_index</span>
        
        <span class="c1"># Handle list/array indexing</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="p">(</span><span class="nb">bool</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">bool_</span><span class="p">))</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="nb">bool</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">bool_</span><span class="p">)):</span>
            <span class="c1"># Get indices from list/array</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
            <span class="c1"># Initialize boolean index</span>
            <span class="n">bool_index</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_genes</span><span class="p">),</span> <span class="n">indices</span><span class="p">)</span>
            <span class="c1"># Set index to boolean index</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">bool_index</span>

        <span class="c1"># Create new params dict with subset of parameters</span>
        <span class="n">new_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_subset_params</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>
        
        <span class="c1"># Create new metadata if available</span>
        <span class="n">new_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">var</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">var</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="c1"># Create new posterior samples if available</span>
        <span class="n">new_posterior_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_subset_posterior_samples</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">posterior_samples</span><span class="p">,</span> <span class="n">index</span>
        <span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">posterior_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
            
        <span class="c1"># Create new predictive samples if available</span>
        <span class="n">new_predictive_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_subset_predictive_samples</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">predictive_samples</span><span class="p">,</span> <span class="n">index</span>
        <span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictive_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
            
        <span class="c1"># Create new instance with subset data</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_subset</span><span class="p">(</span>
            <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="p">,</span>
            <span class="n">new_params</span><span class="o">=</span><span class="n">new_params</span><span class="p">,</span>
            <span class="n">new_var</span><span class="o">=</span><span class="n">new_var</span><span class="p">,</span>
            <span class="n">new_posterior_samples</span><span class="o">=</span><span class="n">new_posterior_samples</span><span class="p">,</span>
            <span class="n">new_predictive_samples</span><span class="o">=</span><span class="n">new_predictive_samples</span>
        <span class="p">)</span></div>


    <span class="c1"># --------------------------------------------------------------------------</span>

    <span class="k">def</span> <span class="nf">_create_subset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">index</span><span class="p">,</span>
        <span class="n">new_params</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">new_var</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
        <span class="n">new_posterior_samples</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">],</span>
        <span class="n">new_predictive_samples</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;ScribeResults&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a new instance with a subset of genes.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)(</span>
            <span class="n">params</span><span class="o">=</span><span class="n">new_params</span><span class="p">,</span>
            <span class="n">loss_history</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="p">,</span>
            <span class="n">n_cells</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cells</span><span class="p">,</span>
            <span class="n">n_genes</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">index</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="s1">&#39;sum&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="n">index</span><span class="p">)),</span>
            <span class="n">model_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">,</span>
            <span class="n">model_config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="p">,</span>
            <span class="n">prior_params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_params</span><span class="p">,</span>
            <span class="n">obs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">obs</span><span class="p">,</span>
            <span class="n">var</span><span class="o">=</span><span class="n">new_var</span><span class="p">,</span>
            <span class="n">uns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">uns</span><span class="p">,</span>
            <span class="n">n_obs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_obs</span><span class="p">,</span>
            <span class="n">n_vars</span><span class="o">=</span><span class="n">new_var</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">new_var</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">posterior_samples</span><span class="o">=</span><span class="n">new_posterior_samples</span><span class="p">,</span>
            <span class="n">predictive_samples</span><span class="o">=</span><span class="n">new_predictive_samples</span><span class="p">,</span>
            <span class="n">n_components</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span>
        <span class="p">)</span>
    
    <span class="c1"># --------------------------------------------------------------------------</span>
    <span class="c1"># Indexing by component</span>
    <span class="c1"># --------------------------------------------------------------------------</span>

<div class="viewcode-block" id="ScribeResults.get_component">
<a class="viewcode-back" href="../../api/results.html#scribe.results.ScribeResults.get_component">[docs]</a>
    <span class="k">def</span> <span class="nf">get_component</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">component_index</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a view of the results selecting a specific mixture component.</span>
<span class="sd">        </span>
<span class="sd">        This method returns a new ScribeResults object that contains parameter</span>
<span class="sd">        values for the specified component, allowing for further gene-based</span>
<span class="sd">        indexing. Only applicable to mixture models.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        component_index : int</span>
<span class="sd">            Index of the component to select</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ScribeResults</span>
<span class="sd">            A new ScribeResults object with parameters for the selected component</span>
<span class="sd">            </span>
<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the model is not a mixture model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if this is a mixture model</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Component view only applies to mixture models with multiple components&quot;</span>
            <span class="p">)</span>
            
        <span class="c1"># Check if component_index is valid</span>
        <span class="k">if</span> <span class="n">component_index</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">component_index</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Component index </span><span class="si">{</span><span class="n">component_index</span><span class="si">}</span><span class="s2"> out of range [0, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s2">]&quot;</span>
            <span class="p">)</span>
        
        <span class="c1"># Create new params dict with component subset</span>
        <span class="n">new_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
        
        <span class="c1"># Handle r parameters (always gene-specific)</span>
        <span class="n">r_param_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">r_distribution_guide</span><span class="o">.</span><span class="n">arg_constraints</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="c1"># Loop through r parameters</span>
        <span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="n">r_param_names</span><span class="p">:</span>
            <span class="c1"># Create parameter key</span>
            <span class="n">param_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;r_</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="c1"># Check if parameter is present</span>
            <span class="k">if</span> <span class="n">param_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
                <span class="c1"># Select component dimension</span>
                <span class="n">new_params</span><span class="p">[</span><span class="n">param_key</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">param_key</span><span class="p">][</span><span class="n">component_index</span><span class="p">]</span>
        
        <span class="c1"># Handle gate parameters if present (gene-specific)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">gate_distribution_guide</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Get gate parameter names</span>
            <span class="n">gate_param_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">gate_distribution_guide</span><span class="o">.</span><span class="n">arg_constraints</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="c1"># Loop through gate parameters</span>
            <span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="n">gate_param_names</span><span class="p">:</span>
                <span class="c1"># Create parameter key</span>
                <span class="n">param_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;gate_</span><span class="si">{</span><span class="n">param_name</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="c1"># Check if parameter is present</span>
                <span class="k">if</span> <span class="n">param_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
                    <span class="c1"># Select component dimension</span>
                    <span class="n">new_params</span><span class="p">[</span><span class="n">param_key</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">param_key</span><span class="p">][</span><span class="n">component_index</span><span class="p">]</span>
        
        <span class="c1"># Create new posterior samples if available</span>
        <span class="n">new_posterior_samples</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">posterior_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">new_posterior_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_subset_posterior_samples_component</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">posterior_samples</span><span class="p">,</span> <span class="n">component_index</span>
            <span class="p">)</span>
        
        <span class="c1"># Create new predictive samples if available - this is more complex</span>
        <span class="c1"># as we would need to condition on the component</span>
        <span class="n">new_predictive_samples</span> <span class="o">=</span> <span class="kc">None</span>
        
        <span class="c1"># Create new instance with component subset</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_component_subset</span><span class="p">(</span>
            <span class="n">component_index</span><span class="o">=</span><span class="n">component_index</span><span class="p">,</span>
            <span class="n">new_params</span><span class="o">=</span><span class="n">new_params</span><span class="p">,</span>
            <span class="n">new_posterior_samples</span><span class="o">=</span><span class="n">new_posterior_samples</span><span class="p">,</span>
            <span class="n">new_predictive_samples</span><span class="o">=</span><span class="n">new_predictive_samples</span>
        <span class="p">)</span></div>


    <span class="c1"># --------------------------------------------------------------------------</span>

    <span class="k">def</span> <span class="nf">_subset_posterior_samples_component</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">component_index</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a new posterior samples dictionary for the given component index.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
            
        <span class="n">new_posterior_samples</span> <span class="o">=</span> <span class="p">{}</span>
        
            
        <span class="c1"># Handle r parameters (component and gene-specific)</span>
        <span class="k">if</span> <span class="s1">&#39;r&#39;</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
            <span class="c1"># Shape is typically (n_samples, n_components, n_genes)</span>
            <span class="c1"># Select component dimension to get (n_samples, n_genes)</span>
            <span class="n">new_posterior_samples</span><span class="p">[</span><span class="s1">&#39;r&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;r&#39;</span><span class="p">][:,</span> <span class="n">component_index</span><span class="p">,</span> <span class="p">:]</span>
        
        <span class="c1"># Handle gate parameters if present (component and gene-specific)</span>
        <span class="k">if</span> <span class="s1">&#39;gate&#39;</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
            <span class="c1"># Shape is typically (n_samples, n_components, n_genes)</span>
            <span class="c1"># Select component dimension to get (n_samples, n_genes)</span>
            <span class="n">new_posterior_samples</span><span class="p">[</span><span class="s1">&#39;gate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;gate&#39;</span><span class="p">][:,</span> <span class="n">component_index</span><span class="p">,</span> <span class="p">:]</span>
        
        <span class="c1"># Copy global parameters as is (p, mixing_weights)</span>
        <span class="k">if</span> <span class="s1">&#39;p&#39;</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
            <span class="n">new_posterior_samples</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">]</span>
        
        <span class="c1"># Handle p_capture parameters (cell-specific)</span>
        <span class="k">if</span> <span class="s1">&#39;p_capture&#39;</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
            <span class="n">new_posterior_samples</span><span class="p">[</span><span class="s1">&#39;p_capture&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;p_capture&#39;</span><span class="p">]</span>
        
        <span class="k">return</span> <span class="n">new_posterior_samples</span>
        
    <span class="c1"># --------------------------------------------------------------------------</span>

    <span class="k">def</span> <span class="nf">_create_component_subset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">component_index</span><span class="p">,</span>
        <span class="n">new_params</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">new_posterior_samples</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">],</span>
        <span class="n">new_predictive_samples</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;ScribeResults&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a new instance for a specific component.&quot;&quot;&quot;</span>
        <span class="c1"># Create a non-mixture model type</span>
        <span class="n">base_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;_mix&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>

        <span class="c1"># Create a modified model config with n_components=None to indicate</span>
        <span class="c1"># this is now a non-mixture result after component selection</span>
        <span class="n">new_model_config</span> <span class="o">=</span> <span class="n">replace</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="p">,</span>
            <span class="n">base_model</span><span class="o">=</span><span class="n">base_model</span><span class="p">,</span>
            <span class="n">n_components</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">mixing_distribution_model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">mixing_distribution_guide</span><span class="o">=</span><span class="kc">None</span>
        <span class="p">)</span>
               
        <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)(</span>
            <span class="n">params</span><span class="o">=</span><span class="n">new_params</span><span class="p">,</span>
            <span class="n">loss_history</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="p">,</span>
            <span class="n">n_cells</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cells</span><span class="p">,</span>
            <span class="n">n_genes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_genes</span><span class="p">,</span>
            <span class="n">model_type</span><span class="o">=</span><span class="n">base_model</span><span class="p">,</span>  <span class="c1"># Remove _mix suffix</span>
            <span class="n">model_config</span><span class="o">=</span><span class="n">new_model_config</span><span class="p">,</span>
            <span class="n">prior_params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_params</span><span class="p">,</span>
            <span class="n">obs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">obs</span><span class="p">,</span>
            <span class="n">var</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">var</span><span class="p">,</span>
            <span class="n">uns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">uns</span><span class="p">,</span>
            <span class="n">n_obs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_obs</span><span class="p">,</span>
            <span class="n">n_vars</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="p">,</span>
            <span class="n">posterior_samples</span><span class="o">=</span><span class="n">new_posterior_samples</span><span class="p">,</span>
            <span class="n">predictive_samples</span><span class="o">=</span><span class="n">new_predictive_samples</span><span class="p">,</span>
            <span class="n">n_components</span><span class="o">=</span><span class="kc">None</span>  <span class="c1"># No longer a mixture model</span>
        <span class="p">)</span>

    <span class="c1"># --------------------------------------------------------------------------</span>
    <span class="c1"># Get model and guide functions</span>
    <span class="c1"># --------------------------------------------------------------------------</span>

    <span class="k">def</span> <span class="nf">_model_and_guide</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Callable</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the model and guide functions based on model type.&quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">.model_registry</span> <span class="kn">import</span> <span class="n">get_model_and_guide</span>
        <span class="k">return</span> <span class="n">get_model_and_guide</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">)</span>

    <span class="c1"># --------------------------------------------------------------------------</span>
    <span class="c1"># Get log likelihood function</span>
    <span class="c1"># --------------------------------------------------------------------------</span>

    <span class="k">def</span> <span class="nf">_log_likelihood_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the log likelihood function for this model type.&quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">.model_registry</span> <span class="kn">import</span> <span class="n">get_log_likelihood_fn</span>
        <span class="k">return</span> <span class="n">get_log_likelihood_fn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_type</span><span class="p">)</span>

    <span class="c1"># --------------------------------------------------------------------------</span>
    <span class="c1"># Posterior sampling methods</span>
    <span class="c1"># --------------------------------------------------------------------------</span>

<div class="viewcode-block" id="ScribeResults.get_posterior_samples">
<a class="viewcode-back" href="../../api/results.html#scribe.results.ScribeResults.get_posterior_samples">[docs]</a>
    <span class="k">def</span> <span class="nf">get_posterior_samples</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">rng_key</span><span class="p">:</span> <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">42</span><span class="p">),</span>
        <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">store_samples</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sample parameters from the variational posterior distribution.&quot;&quot;&quot;</span>
        <span class="c1"># Get the guide function </span>
        <span class="n">_</span><span class="p">,</span> <span class="n">guide</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_and_guide</span><span class="p">()</span>
        
        <span class="c1"># Prepare base model arguments</span>
        <span class="n">model_args</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;n_cells&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_cells</span><span class="p">,</span>
            <span class="s1">&#39;n_genes&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_genes</span><span class="p">,</span>
            <span class="s1">&#39;model_config&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span>
        <span class="p">}</span>
        
        <span class="c1"># Add specialized arguments based on model type</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;nbdm&quot;</span><span class="p">:</span>
            <span class="n">model_args</span><span class="p">[</span><span class="s1">&#39;total_counts&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Will be filled during sampling</span>
            
        <span class="c1"># Sample from posterior</span>
        <span class="n">posterior_samples</span> <span class="o">=</span> <span class="n">sample_variational_posterior</span><span class="p">(</span>
            <span class="n">guide</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
            <span class="n">model_args</span><span class="p">,</span>
            <span class="n">rng_key</span><span class="o">=</span><span class="n">rng_key</span><span class="p">,</span>
            <span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span>
        <span class="p">)</span>
        
        <span class="c1"># Store samples if requested</span>
        <span class="k">if</span> <span class="n">store_samples</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">posterior_samples</span> <span class="o">=</span> <span class="n">posterior_samples</span>
            
        <span class="k">return</span> <span class="n">posterior_samples</span></div>


    <span class="c1"># --------------------------------------------------------------------------</span>

<div class="viewcode-block" id="ScribeResults.get_predictive_samples">
<a class="viewcode-back" href="../../api/results.html#scribe.results.ScribeResults.get_predictive_samples">[docs]</a>
    <span class="k">def</span> <span class="nf">get_predictive_samples</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">rng_key</span><span class="p">:</span> <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">42</span><span class="p">),</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">store_samples</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate predictive samples using posterior parameter samples.&quot;&quot;&quot;</span>
        <span class="c1"># Get the model and guide functions</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_and_guide</span><span class="p">()</span>
        
        <span class="c1"># Prepare base model arguments</span>
        <span class="n">model_args</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;n_cells&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_cells</span><span class="p">,</span>
            <span class="s1">&#39;n_genes&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_genes</span><span class="p">,</span>
            <span class="s1">&#39;model_config&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="p">,</span>
        <span class="p">}</span>
        
        <span class="c1"># Add specialized arguments based on model type</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_type</span> <span class="o">==</span> <span class="s2">&quot;nbdm&quot;</span><span class="p">:</span>
            <span class="n">model_args</span><span class="p">[</span><span class="s1">&#39;total_counts&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Will be filled during sampling</span>
            
        <span class="c1"># Check if posterior samples exist</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">posterior_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;No posterior samples found. Call get_posterior_samples() first.&quot;</span>
            <span class="p">)</span>
        
        <span class="c1"># Generate predictive samples</span>
        <span class="n">predictive_samples</span> <span class="o">=</span> <span class="n">generate_predictive_samples</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">posterior_samples</span><span class="p">,</span>
            <span class="n">model_args</span><span class="p">,</span>
            <span class="n">rng_key</span><span class="o">=</span><span class="n">rng_key</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span>
        <span class="p">)</span>
        
        <span class="c1"># Store samples if requested</span>
        <span class="k">if</span> <span class="n">store_samples</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">predictive_samples</span> <span class="o">=</span> <span class="n">predictive_samples</span>
            
        <span class="k">return</span> <span class="n">predictive_samples</span></div>


    <span class="c1"># --------------------------------------------------------------------------</span>

<div class="viewcode-block" id="ScribeResults.get_ppc_samples">
<a class="viewcode-back" href="../../api/results.html#scribe.results.ScribeResults.get_ppc_samples">[docs]</a>
    <span class="k">def</span> <span class="nf">get_ppc_samples</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">rng_key</span><span class="p">:</span> <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">42</span><span class="p">),</span>
        <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">store_samples</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">resample_parameters</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate posterior predictive check samples.&quot;&quot;&quot;</span>
        <span class="c1"># Check if we need to resample parameters</span>
        <span class="n">need_params</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">resample_parameters</span> <span class="ow">or</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">posterior_samples</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="p">)</span>

        <span class="c1"># Generate posterior samples if needed</span>
        <span class="k">if</span> <span class="n">need_params</span><span class="p">:</span>
            <span class="c1"># Sample parameters and generate predictive samples</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">get_posterior_samples</span><span class="p">(</span>
                <span class="n">rng_key</span><span class="o">=</span><span class="n">rng_key</span><span class="p">,</span>
                <span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span>
                <span class="n">store_samples</span><span class="o">=</span><span class="n">store_samples</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Generate predictive samples using existing parameters</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">key_pred</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng_key</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">get_predictive_samples</span><span class="p">(</span>
            <span class="n">rng_key</span><span class="o">=</span><span class="n">key_pred</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">store_samples</span><span class="o">=</span><span class="n">store_samples</span><span class="p">,</span>
        <span class="p">)</span>
            
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;parameter_samples&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">posterior_samples</span><span class="p">,</span>
            <span class="s1">&#39;predictive_samples&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictive_samples</span>
        <span class="p">}</span></div>

    <span class="c1"># --------------------------------------------------------------------------</span>
    <span class="c1"># Compute log likelihood methods </span>
    <span class="c1"># --------------------------------------------------------------------------</span>

<div class="viewcode-block" id="ScribeResults.log_likelihood">
<a class="viewcode-back" href="../../api/results.html#scribe.results.ScribeResults.log_likelihood">[docs]</a>
    <span class="k">def</span> <span class="nf">log_likelihood</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">counts</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_by</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;cell&#39;</span><span class="p">,</span>
        <span class="n">cells_axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">ignore_nans</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">split_components</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">weight_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute log likelihood of data under posterior samples.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        counts : jnp.ndarray</span>
<span class="sd">            Count data to evaluate likelihood on</span>
<span class="sd">        batch_size : Optional[int], default=None</span>
<span class="sd">            Size of mini-batches used for likelihood computation</span>
<span class="sd">        return_by : str, default=&#39;cell&#39;</span>
<span class="sd">            Specifies how to return the log probabilities. Must be one of:</span>
<span class="sd">                - &#39;cell&#39;: returns log probabilities summed over genes</span>
<span class="sd">                - &#39;gene&#39;: returns log probabilities summed over cells</span>
<span class="sd">        cells_axis : int, default=0</span>
<span class="sd">            Axis along which cells are arranged. 0 means cells are rows.</span>
<span class="sd">        ignore_nans : bool, default=False</span>
<span class="sd">            If True, removes any samples that contain NaNs.</span>
<span class="sd">        split_components : bool, default=False</span>
<span class="sd">            If True, returns log likelihoods for each mixture component</span>
<span class="sd">            separately. Only applicable for mixture models.</span>
<span class="sd">        weights : Optional[jnp.ndarray], default=None</span>
<span class="sd">            Array used to weight the log likelihoods (for mixture models).</span>
<span class="sd">        weight_type : Optional[str], default=None</span>
<span class="sd">            How to apply weights. Must be one of:</span>
<span class="sd">                - &#39;multiplicative&#39;: multiply log probabilities by weights</span>
<span class="sd">                - &#39;additive&#39;: add weights to log probabilities</span>
<span class="sd">        dtype : jnp.dtype, default=jnp.float32</span>
<span class="sd">            Data type for numerical precision in computations</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        jnp.ndarray</span>
<span class="sd">            Array of log likelihoods. Shape depends on model type, return_by and</span>
<span class="sd">            split_components parameters. For standard models:</span>
<span class="sd">                - &#39;cell&#39;: shape (n_samples, n_cells)</span>
<span class="sd">                - &#39;gene&#39;: shape (n_samples, n_genes)</span>
<span class="sd">            For mixture models with split_components=False:</span>
<span class="sd">                - &#39;cell&#39;: shape (n_samples, n_cells)</span>
<span class="sd">                - &#39;gene&#39;: shape (n_samples, n_genes)</span>
<span class="sd">            For mixture models with split_components=True:</span>
<span class="sd">                - &#39;cell&#39;: shape (n_samples, n_cells, n_components)</span>
<span class="sd">                - &#39;gene&#39;: shape (n_samples, n_genes, n_components)</span>
<span class="sd">                </span>
<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If posterior samples have not been generated yet</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if posterior samples exist</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">posterior_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;No posterior samples found. Call get_posterior_samples() first.&quot;</span>
            <span class="p">)</span>
        
        <span class="c1"># Get parameter samples</span>
        <span class="n">parameter_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">posterior_samples</span>
        
        <span class="c1"># Get number of samples from first parameter</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">parameter_samples</span><span class="p">[</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">parameter_samples</span><span class="p">))]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Get likelihood function</span>
        <span class="n">likelihood_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood_fn</span><span class="p">()</span>
        
        <span class="c1"># Determine if this is a mixture model</span>
        <span class="n">is_mixture</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">&gt;</span> <span class="mi">1</span>
        
        <span class="c1"># Define function to compute likelihood for a single sample</span>
        <span class="nd">@jit</span>
        <span class="k">def</span> <span class="nf">compute_sample_lik</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
            <span class="c1"># Extract parameters for this sample</span>
            <span class="n">params_i</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">parameter_samples</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
            <span class="c1"># For mixture models we need to pass split_components and weights</span>
            <span class="k">if</span> <span class="n">is_mixture</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">likelihood_fn</span><span class="p">(</span>
                    <span class="n">counts</span><span class="p">,</span> 
                    <span class="n">params_i</span><span class="p">,</span> 
                    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">cells_axis</span><span class="o">=</span><span class="n">cells_axis</span><span class="p">,</span>
                    <span class="n">return_by</span><span class="o">=</span><span class="n">return_by</span><span class="p">,</span>
                    <span class="n">split_components</span><span class="o">=</span><span class="n">split_components</span><span class="p">,</span>
                    <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
                    <span class="n">weight_type</span><span class="o">=</span><span class="n">weight_type</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">likelihood_fn</span><span class="p">(</span>
                    <span class="n">counts</span><span class="p">,</span> 
                    <span class="n">params_i</span><span class="p">,</span> 
                    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">cells_axis</span><span class="o">=</span><span class="n">cells_axis</span><span class="p">,</span>
                    <span class="n">return_by</span><span class="o">=</span><span class="n">return_by</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span>
                <span class="p">)</span>
        
        <span class="c1"># Use vmap for parallel computation (more memory intensive)</span>
        <span class="n">log_liks</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">compute_sample_lik</span><span class="p">)(</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_samples</span><span class="p">))</span>
        
        <span class="c1"># Handle NaNs if requested</span>
        <span class="k">if</span> <span class="n">ignore_nans</span><span class="p">:</span>
            <span class="c1"># Check for NaNs appropriately based on dimensions</span>
            <span class="k">if</span> <span class="n">is_mixture</span> <span class="ow">and</span> <span class="n">split_components</span><span class="p">:</span>
                <span class="c1"># Handle case with component dimension</span>
                <span class="n">valid_samples</span> <span class="o">=</span> <span class="o">~</span><span class="n">jnp</span><span class="o">.</span><span class="n">any</span><span class="p">(</span>
                    <span class="n">jnp</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">log_liks</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> 
                    <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Standard case</span>
                <span class="n">valid_samples</span> <span class="o">=</span> <span class="o">~</span><span class="n">jnp</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">log_liks</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                
            <span class="c1"># Filter out samples with NaNs</span>
            <span class="k">if</span> <span class="n">jnp</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="o">~</span><span class="n">valid_samples</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    - Fraction of samples removed: </span><span class="si">{</span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">valid_samples</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">log_liks</span><span class="p">[</span><span class="n">valid_samples</span><span class="p">]</span>
        
        <span class="k">return</span> <span class="n">log_liks</span></div>


    <span class="c1"># --------------------------------------------------------------------------</span>

<div class="viewcode-block" id="ScribeResults.log_likelihood_map">
<a class="viewcode-back" href="../../api/results.html#scribe.results.ScribeResults.log_likelihood_map">[docs]</a>
    <span class="k">def</span> <span class="nf">log_likelihood_map</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">counts</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">gene_batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_by</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;cell&#39;</span><span class="p">,</span>
        <span class="n">cells_axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">split_components</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">weight_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_mean</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute log likelihood of data using MAP parameter estimates.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        counts : jnp.ndarray</span>
<span class="sd">            Count data to evaluate likelihood on</span>
<span class="sd">        batch_size : Optional[int], default=None</span>
<span class="sd">            Size of mini-batches used for likelihood computation</span>
<span class="sd">        gene_batch_size : Optional[int], default=None</span>
<span class="sd">            Size of mini-batches used for likelihood computation by gene</span>
<span class="sd">        return_by : str, default=&#39;cell&#39;</span>
<span class="sd">            Specifies how to return the log probabilities. Must be one of:</span>
<span class="sd">                - &#39;cell&#39;: returns log probabilities summed over genes</span>
<span class="sd">                - &#39;gene&#39;: returns log probabilities summed over cells</span>
<span class="sd">        cells_axis : int, default=0</span>
<span class="sd">            Axis along which cells are arranged. 0 means cells are rows.</span>
<span class="sd">        split_components : bool, default=False</span>
<span class="sd">            If True, returns log likelihoods for each mixture component separately.</span>
<span class="sd">            Only applicable for mixture models.</span>
<span class="sd">        weights : Optional[jnp.ndarray], default=None</span>
<span class="sd">            Array used to weight the log likelihoods (for mixture models).</span>
<span class="sd">        weight_type : Optional[str], default=None</span>
<span class="sd">            How to apply weights. Must be one of:</span>
<span class="sd">                - &#39;multiplicative&#39;: multiply log probabilities by weights</span>
<span class="sd">                - &#39;additive&#39;: add weights to log probabilities</span>
<span class="sd">        use_mean : bool, default=False</span>
<span class="sd">            If True, replaces undefined MAP values (NaN) with posterior means</span>
<span class="sd">        verbose : bool, default=True</span>
<span class="sd">            If True, prints a warning if NaNs were replaced with means</span>
<span class="sd">        dtype : jnp.dtype, default=jnp.float32</span>
<span class="sd">            Data type for numerical precision in computations</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        jnp.ndarray</span>
<span class="sd">            Array of log likelihoods. Shape depends on model type, return_by and</span>
<span class="sd">            split_components parameters.</span>
<span class="sd">            For standard models:</span>
<span class="sd">                - &#39;cell&#39;: shape (n_cells,)</span>
<span class="sd">                - &#39;gene&#39;: shape (n_genes,)</span>
<span class="sd">            For mixture models with split_components=False:</span>
<span class="sd">                - &#39;cell&#39;: shape (n_cells,)</span>
<span class="sd">                - &#39;gene&#39;: shape (n_genes,)</span>
<span class="sd">            For mixture models with split_components=True:</span>
<span class="sd">                - &#39;cell&#39;: shape (n_cells, n_components)</span>
<span class="sd">                - &#39;gene&#39;: shape (n_genes, n_components)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get the log likelihood function</span>
        <span class="n">likelihood_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood_fn</span><span class="p">()</span>
        
        <span class="c1"># Determine if this is a mixture model</span>
        <span class="n">is_mixture</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">&gt;</span> <span class="mi">1</span>
        
        <span class="c1"># If computing by gene and gene_batch_size is provided, use batched computation</span>
        <span class="k">if</span> <span class="n">return_by</span> <span class="o">==</span> <span class="s1">&#39;gene&#39;</span> <span class="ow">and</span> <span class="n">gene_batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Determine output shape</span>
            <span class="k">if</span> <span class="n">is_mixture</span> <span class="ow">and</span> <span class="n">split_components</span><span class="p">:</span>
                <span class="n">result_shape</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_genes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">result_shape</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_genes</span><span class="p">,)</span>
                
            <span class="c1"># Initialize result array</span>
            <span class="n">log_liks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">result_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
            
            <span class="c1"># Process genes in batches</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_genes</span><span class="p">,</span> <span class="n">gene_batch_size</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Processing genes </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="nb">min</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="n">gene_batch_size</span><span class="p">,</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">n_genes</span><span class="p">)</span><span class="si">}</span><span class="s2"> of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_genes</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    
                <span class="c1"># Get gene indices for this batch</span>
                <span class="n">end_idx</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">gene_batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_genes</span><span class="p">)</span>
                <span class="n">gene_indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">end_idx</span><span class="p">))</span>
                
                <span class="c1"># Get subset of results for these genes</span>
                <span class="n">results_subset</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="n">gene_indices</span><span class="p">]</span>
                <span class="c1"># Get the MAP estimates</span>
                <span class="n">map_estimates</span> <span class="o">=</span> <span class="n">results_subset</span><span class="o">.</span><span class="n">get_map</span><span class="p">(</span>
                    <span class="n">use_mean</span><span class="o">=</span><span class="n">use_mean</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
                
                <span class="c1"># Get subset of counts for these genes</span>
                <span class="k">if</span> <span class="n">cells_axis</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">counts_subset</span> <span class="o">=</span> <span class="n">counts</span><span class="p">[:,</span> <span class="n">gene_indices</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">counts_subset</span> <span class="o">=</span> <span class="n">counts</span><span class="p">[</span><span class="n">gene_indices</span><span class="p">,</span> <span class="p">:]</span>
                    
                <span class="c1"># Get subset of weights if provided</span>
                <span class="n">weights_subset</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">weights</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Shape: (n_genes,)</span>
                        <span class="n">weights_subset</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">gene_indices</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">weights_subset</span> <span class="o">=</span> <span class="n">weights</span>
                
                <span class="c1"># Compute log likelihood for this gene batch</span>
                <span class="k">if</span> <span class="n">is_mixture</span><span class="p">:</span>
                    <span class="n">batch_log_liks</span> <span class="o">=</span> <span class="n">likelihood_fn</span><span class="p">(</span>
                        <span class="n">counts_subset</span><span class="p">,</span>
                        <span class="n">map_estimates</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                        <span class="n">cells_axis</span><span class="o">=</span><span class="n">cells_axis</span><span class="p">,</span>
                        <span class="n">return_by</span><span class="o">=</span><span class="n">return_by</span><span class="p">,</span>
                        <span class="n">split_components</span><span class="o">=</span><span class="n">split_components</span><span class="p">,</span>
                        <span class="n">weights</span><span class="o">=</span><span class="n">weights_subset</span><span class="p">,</span>
                        <span class="n">weight_type</span><span class="o">=</span><span class="n">weight_type</span><span class="p">,</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">batch_log_liks</span> <span class="o">=</span> <span class="n">likelihood_fn</span><span class="p">(</span>
                        <span class="n">counts_subset</span><span class="p">,</span>
                        <span class="n">map_estimates</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                        <span class="n">cells_axis</span><span class="o">=</span><span class="n">cells_axis</span><span class="p">,</span>
                        <span class="n">return_by</span><span class="o">=</span><span class="n">return_by</span><span class="p">,</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span>
                    <span class="p">)</span>
                
                <span class="c1"># Store results</span>
                <span class="n">log_liks</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">batch_log_liks</span><span class="p">)</span>
            
            <span class="c1"># Convert to JAX array for consistency</span>
            <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">log_liks</span><span class="p">)</span>
        
        <span class="c1"># Standard computation (no gene batching)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Get the MAP estimates</span>
            <span class="n">map_estimates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_map</span><span class="p">(</span><span class="n">use_mean</span><span class="o">=</span><span class="n">use_mean</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>

            <span class="c1"># Compute log-likelihood for mixture model</span>
            <span class="k">if</span> <span class="n">is_mixture</span><span class="p">:</span>
                <span class="n">log_liks</span> <span class="o">=</span> <span class="n">likelihood_fn</span><span class="p">(</span>
                    <span class="n">counts</span><span class="p">,</span>
                    <span class="n">map_estimates</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">cells_axis</span><span class="o">=</span><span class="n">cells_axis</span><span class="p">,</span>
                    <span class="n">return_by</span><span class="o">=</span><span class="n">return_by</span><span class="p">,</span>
                    <span class="n">split_components</span><span class="o">=</span><span class="n">split_components</span><span class="p">,</span>
                    <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
                    <span class="n">weight_type</span><span class="o">=</span><span class="n">weight_type</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span>
                <span class="p">)</span>
            <span class="c1"># Compute log-likelihood for non-mixture model</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">log_liks</span> <span class="o">=</span> <span class="n">likelihood_fn</span><span class="p">(</span>
                    <span class="n">counts</span><span class="p">,</span>
                    <span class="n">map_estimates</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">cells_axis</span><span class="o">=</span><span class="n">cells_axis</span><span class="p">,</span>
                    <span class="n">return_by</span><span class="o">=</span><span class="n">return_by</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span>
                <span class="p">)</span>
            
            <span class="k">return</span> <span class="n">log_liks</span></div>



    <span class="c1"># --------------------------------------------------------------------------</span>
    <span class="c1"># Compute entropy of component assignments</span>
    <span class="c1"># --------------------------------------------------------------------------</span>

<div class="viewcode-block" id="ScribeResults.assignment_entropy">
<a class="viewcode-back" href="../../api/results.html#scribe.results.ScribeResults.assignment_entropy">[docs]</a>
    <span class="k">def</span> <span class="nf">assignment_entropy</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">counts</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">return_by</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;gene&#39;</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cells_axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">ignore_nans</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">temperature</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the entropy of component assignment probabilities for mixture</span>
<span class="sd">        models.</span>
<span class="sd">        </span>
<span class="sd">        This method calculates the entropy of the posterior component assignment</span>
<span class="sd">        probabilities for each cell or gene, providing a measure of assignment</span>
<span class="sd">        uncertainty. Higher entropy values indicate more uncertainty in the</span>
<span class="sd">        component assignments, while lower values indicate more confident</span>
<span class="sd">        assignments.</span>
<span class="sd">        </span>
<span class="sd">        The entropy is calculated as:</span>
<span class="sd">            H = -(p_i * log(p_i))</span>
<span class="sd">        where p_i are the normalized probabilities for each component.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        counts : jnp.ndarray</span>
<span class="sd">            Input count data to evaluate component assignments for. Shape should</span>
<span class="sd">            be (n_cells, n_genes) if cells_axis=0, or (n_genes, n_cells) if</span>
<span class="sd">            cells_axis=1.</span>
<span class="sd">        </span>
<span class="sd">        return_by : str, default=&#39;cell&#39;</span>
<span class="sd">            Specifies how to compute and return the entropy. Must be one of:</span>
<span class="sd">                - &#39;cell&#39;: Compute entropy of component assignments for each cell</span>
<span class="sd">                - &#39;gene&#39;: Compute entropy of component assignments for each gene</span>
<span class="sd">        </span>
<span class="sd">        batch_size : Optional[int], default=None</span>
<span class="sd">            If provided, processes the data in batches of this size to reduce</span>
<span class="sd">            memory usage. Useful for large datasets.</span>
<span class="sd">        </span>
<span class="sd">        cells_axis : int, default=0</span>
<span class="sd">            Specifies which axis in the input counts contains the cells:</span>
<span class="sd">                - 0: cells are rows (shape: n_cells  n_genes)</span>
<span class="sd">                - 1: cells are columns (shape: n_genes  n_cells)</span>
<span class="sd">        </span>
<span class="sd">        ignore_nans : bool, default=False</span>
<span class="sd">            If True, excludes any samples containing NaN values from the entropy</span>
<span class="sd">            calculation.</span>
<span class="sd">        </span>
<span class="sd">        temperature : Optional[float], default=None</span>
<span class="sd">            If provided, applies temperature scaling to the log-likelihoods</span>
<span class="sd">            before computing entropy. Temperature scaling modifies the sharpness</span>
<span class="sd">            of probability distributions by dividing log probabilities by a</span>
<span class="sd">            temperature parameter T:</span>
<span class="sd">        </span>
<span class="sd">        dtype : jnp.dtype, default=jnp.float32</span>
<span class="sd">            Data type for numerical precision in computations.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        jnp.ndarray</span>
<span class="sd">            Array of entropy values. Shape depends on return_by:</span>
<span class="sd">                - If return_by=&#39;cell&#39;: shape is (n_samples, n_cells)</span>
<span class="sd">                - If return_by=&#39;gene&#39;: shape is (n_samples, n_genes)</span>
<span class="sd">            Higher values indicate more uncertainty in component assignments.</span>
<span class="sd">        </span>
<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the model is not a mixture model or if posterior samples haven&#39;t</span>
<span class="sd">            been generated.</span>
<span class="sd">        </span>
<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        - This method requires posterior samples to be available. Call</span>
<span class="sd">          get_posterior_samples() first if they haven&#39;t been generated.</span>
<span class="sd">        - The entropy is computed using the full posterior predictive</span>
<span class="sd">          distribution, accounting for uncertainty in the model parameters.</span>
<span class="sd">        - Normalization (normalize=True) is recommended when comparing entropy</span>
<span class="sd">          across datasets or between cells/genes with different numbers of</span>
<span class="sd">          observations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if this is a mixture model</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Component entropy calculation only applies to mixture models &quot;</span>
                <span class="s2">&quot;with multiple components&quot;</span>
            <span class="p">)</span>
        
        <span class="c1"># Check if posterior samples exist</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">posterior_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;No posterior samples found. Call get_posterior_samples() first.&quot;</span>
            <span class="p">)</span>
       
        <span class="c1"># Compute log-likelihoods for each component</span>
        <span class="n">log_liks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">(</span>
            <span class="n">counts</span><span class="p">,</span> 
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
            <span class="n">cells_axis</span><span class="o">=</span><span class="n">cells_axis</span><span class="p">,</span> 
            <span class="n">return_by</span><span class="o">=</span><span class="n">return_by</span><span class="p">,</span> 
            <span class="n">ignore_nans</span><span class="o">=</span><span class="n">ignore_nans</span><span class="p">,</span> 
            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">split_components</span><span class="o">=</span><span class="kc">True</span>  <span class="c1"># Ensure we get per-component likelihoods</span>
        <span class="p">)</span>

        <span class="c1"># Apply temperature scaling if requested</span>
        <span class="k">if</span> <span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log_liks</span> <span class="o">=</span> <span class="n">temperature_scaling</span><span class="p">(</span><span class="n">log_liks</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

        <span class="c1"># Compute log-sum-exp for normalization</span>
        <span class="n">log_sum_exp</span> <span class="o">=</span> <span class="n">jsp</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">log_liks</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Compute probabilities (avoiding log space for final entropy calculation)</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_liks</span> <span class="o">-</span> <span class="n">log_sum_exp</span><span class="p">)</span>

        <span class="c1"># Compute entropy: -(p_i * log(p_i))</span>
        <span class="c1"># Add small epsilon to avoid log(0)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>
        <span class="n">entropy</span> <span class="o">=</span> <span class="o">-</span><span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">probs</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span> <span class="o">+</span> <span class="n">eps</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">entropy</span></div>


    <span class="c1"># --------------------------------------------------------------------------</span>

<div class="viewcode-block" id="ScribeResults.assignment_entropy_map">
<a class="viewcode-back" href="../../api/results.html#scribe.results.ScribeResults.assignment_entropy_map">[docs]</a>
    <span class="k">def</span> <span class="nf">assignment_entropy_map</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">counts</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">return_by</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;gene&#39;</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cells_axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">temperature</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_mean</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the entropy of component assignments for each cell evaluated at</span>
<span class="sd">        the MAP.</span>

<span class="sd">        This method calculates the entropy of the posterior component assignment</span>
<span class="sd">        probabilities for each cell or gene, providing a measure of assignment</span>
<span class="sd">        uncertainty. Higher entropy values indicate more uncertainty in the</span>
<span class="sd">        component assignments, while lower values indicate more confident</span>
<span class="sd">        assignments.</span>
<span class="sd">        </span>
<span class="sd">        The entropy is calculated as:</span>
<span class="sd">            H = -(p_i * log(p_i))</span>
<span class="sd">        where p_i are the normalized probabilities for each component.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        counts : jnp.ndarray</span>
<span class="sd">            The count matrix with shape (n_cells, n_genes).</span>
<span class="sd">        return_by : str, default=&#39;gene&#39;</span>
<span class="sd">            Whether to return the entropy by cell or gene.</span>
<span class="sd">        batch_size : Optional[int], default=None</span>
<span class="sd">            Size of mini-batches for likelihood computation</span>
<span class="sd">        cells_axis : int, default=0</span>
<span class="sd">            Axis along which cells are arranged. 0 means cells are rows.</span>
<span class="sd">        temperature : Optional[float], default=None</span>
<span class="sd">            If provided, applies temperature scaling to the log-likelihoods</span>
<span class="sd">            before computing entropy.</span>
<span class="sd">        use_mean : bool, default=True</span>
<span class="sd">            If True, uses the mean of the posterior component probabilities</span>
<span class="sd">            instead of the MAP.</span>
<span class="sd">        verbose : bool, default=True</span>
<span class="sd">            If True, prints a warning if NaNs were replaced with means</span>
<span class="sd">        dtype : jnp.dtype, default=jnp.float32</span>
<span class="sd">            Data type for numerical precision in computations</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        jnp.ndarray</span>
<span class="sd">            The component entropy for each cell evaluated at the MAP. Shape:</span>
<span class="sd">            (n_cells,).</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            - If the model is not a mixture model</span>
<span class="sd">            - If posterior samples have not been generated yet</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if this is a mixture model</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Component entropy calculation only applies to mixture models &quot;</span>
                <span class="s2">&quot;with multiple components&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Compute log-likelihood at the MAP</span>
        <span class="n">log_liks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood_map</span><span class="p">(</span>
            <span class="n">counts</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">cells_axis</span><span class="o">=</span><span class="n">cells_axis</span><span class="p">,</span>
            <span class="n">use_mean</span><span class="o">=</span><span class="n">use_mean</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">return_by</span><span class="o">=</span><span class="n">return_by</span><span class="p">,</span>
            <span class="n">split_components</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Apply temperature scaling if requested</span>
        <span class="k">if</span> <span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log_liks</span> <span class="o">=</span> <span class="n">temperature_scaling</span><span class="p">(</span><span class="n">log_liks</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

        <span class="c1"># Compute log-sum-exp for normalization</span>
        <span class="n">log_sum_exp</span> <span class="o">=</span> <span class="n">jsp</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">log_liks</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Compute probabilities (avoiding log space for final entropy calculation)</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_liks</span> <span class="o">-</span> <span class="n">log_sum_exp</span><span class="p">)</span>

        <span class="c1"># Compute entropy: -(p_i * log(p_i))</span>
        <span class="c1"># Add small epsilon to avoid log(0)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>
        <span class="n">entropy</span> <span class="o">=</span> <span class="o">-</span><span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">probs</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span> <span class="o">+</span> <span class="n">eps</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">entropy</span></div>

    
    <span class="c1"># --------------------------------------------------------------------------</span>
    <span class="c1"># Hellinger distance for mixture models</span>
    <span class="c1"># --------------------------------------------------------------------------</span>

<div class="viewcode-block" id="ScribeResults.hellinger_distance">
<a class="viewcode-back" href="../../api/results.html#scribe.results.ScribeResults.hellinger_distance">[docs]</a>
    <span class="k">def</span> <span class="nf">hellinger_distance</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute pairwise Hellinger distances between mixture model components.</span>
<span class="sd">        </span>
<span class="sd">        This method calculates the Hellinger distance between each pair of</span>
<span class="sd">        components in the mixture model based on their inferred parameter</span>
<span class="sd">        distributions. The Hellinger distance is a metric that quantifies the</span>
<span class="sd">        similarity between two probability distributions, ranging from 0</span>
<span class="sd">        (identical) to 1 (completely different).</span>
<span class="sd">        </span>
<span class="sd">        The specific distance calculation depends on the distribution type used</span>
<span class="sd">        for the dispersion parameter (r): </span>
<span class="sd">            - For LogNormal: Uses location and scale parameters </span>
<span class="sd">            - For Gamma: Uses concentration and rate parameters</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dtype : jnp.dtype, default=jnp.float32</span>
<span class="sd">            Data type for numerical precision in computations</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Dict[str, jnp.ndarray]</span>
<span class="sd">            Dictionary containing pairwise Hellinger distances between</span>
<span class="sd">            components. Keys are of the form &#39;i_j&#39; where i,j are component</span>
<span class="sd">            indices. Values are the Hellinger distances between components i and</span>
<span class="sd">            j.</span>
<span class="sd">            </span>
<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the model is not a mixture model with multiple components, or if</span>
<span class="sd">            the distribution type is not supported (must be LogNormal or Gamma)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if this is a mixture model</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Hellinger distance calculation only applies to mixture models &quot;</span>
                <span class="s2">&quot;with multiple components&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Get r distribution from ModelConfig</span>
        <span class="n">r_distribution</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">r_distribution_guide</span><span class="p">)</span>
        <span class="c1"># Define corresponding Hellinger distance function</span>
        <span class="k">if</span> <span class="n">r_distribution</span> <span class="o">==</span> <span class="n">dist</span><span class="o">.</span><span class="n">LogNormal</span><span class="p">:</span>
            <span class="n">hellinger_distance_fn</span> <span class="o">=</span> <span class="n">hellinger_lognormal</span>
        <span class="k">elif</span> <span class="n">r_distribution</span> <span class="o">==</span> <span class="n">dist</span><span class="o">.</span><span class="n">Gamma</span><span class="p">:</span>
            <span class="n">hellinger_distance_fn</span> <span class="o">=</span> <span class="n">hellinger_gamma</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unsupported distribution type: </span><span class="si">{</span><span class="n">r_distribution</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="s2">&quot;Must be &#39;lognormal&#39; or &#39;gamma&#39;.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Extract parameters from r distribution based on distribution type</span>
        <span class="k">if</span> <span class="n">r_distribution</span> <span class="o">==</span> <span class="n">dist</span><span class="o">.</span><span class="n">LogNormal</span><span class="p">:</span>
            <span class="n">r_param1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;r_loc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">r_param2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;r_scale&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">r_distribution</span> <span class="o">==</span> <span class="n">dist</span><span class="o">.</span><span class="n">Gamma</span><span class="p">:</span>
            <span class="n">r_param1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;r_concentration&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">r_param2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;r_rate&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

        <span class="c1"># Initialize dictionary to store distances</span>
        <span class="n">hellinger_distances</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Compute pairwise distances for each component</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">):</span>
                <span class="c1"># Compute Hellinger distance between component i and j</span>
                <span class="n">hellinger_distances</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">hellinger_distance_fn</span><span class="p">(</span>
                    <span class="n">r_param1</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">r_param2</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">r_param1</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">r_param2</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                <span class="p">)</span>

        <span class="k">return</span> <span class="n">hellinger_distances</span></div>

                
    <span class="c1"># --------------------------------------------------------------------------</span>
    <span class="c1"># KL Divergence for mixture models</span>
    <span class="c1"># --------------------------------------------------------------------------</span>

<div class="viewcode-block" id="ScribeResults.kl_divergence">
<a class="viewcode-back" href="../../api/results.html#scribe.results.ScribeResults.kl_divergence">[docs]</a>
    <span class="k">def</span> <span class="nf">kl_divergence</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute pairwise KL divergences between mixture model components.</span>
<span class="sd">        </span>
<span class="sd">        This method calculates the Kullback-Leibler (KL) divergence between each</span>
<span class="sd">        pair of components in the mixture model based on their inferred</span>
<span class="sd">        parameter distributions. The KL divergence is a measure of how one</span>
<span class="sd">        probability distribution diverges from a second reference distribution,</span>
<span class="sd">        with larger values indicating greater difference.</span>
<span class="sd">        </span>
<span class="sd">        Note that KL divergence is asymmetric: KL(P||Q)  KL(Q||P).</span>
<span class="sd">        </span>
<span class="sd">        The specific divergence calculation depends on the distribution type</span>
<span class="sd">        used for the dispersion parameter (r): </span>
<span class="sd">            - For LogNormal: Uses location and scale parameters </span>
<span class="sd">            - For Gamma: Uses concentration and rate parameters</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dtype : jnp.dtype, default=jnp.float32</span>
<span class="sd">            Data type for numerical precision in computations</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Dict[str, jnp.ndarray]</span>
<span class="sd">            Dictionary containing pairwise KL divergences between components.</span>
<span class="sd">            Keys are of the form &#39;i_j&#39; where i,j are component indices. Values</span>
<span class="sd">            are the KL divergences from component i to component j.</span>
<span class="sd">            </span>
<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the model is not a mixture model with multiple components, or if</span>
<span class="sd">            the distribution type is not supported (must be LogNormal or Gamma)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if this is a mixture model</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;KL divergence calculation only applies to mixture models &quot;</span>
                <span class="s2">&quot;with multiple components&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Get r distribution from ModelConfig</span>
        <span class="n">r_distribution</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">r_distribution_guide</span><span class="p">)</span>
        <span class="c1"># Define corresponding KL divergence function</span>
        <span class="k">if</span> <span class="n">r_distribution</span> <span class="o">==</span> <span class="n">dist</span><span class="o">.</span><span class="n">LogNormal</span><span class="p">:</span>
            <span class="n">kl_divergence_fn</span> <span class="o">=</span> <span class="n">kl_lognormal</span>
        <span class="k">elif</span> <span class="n">r_distribution</span> <span class="o">==</span> <span class="n">dist</span><span class="o">.</span><span class="n">Gamma</span><span class="p">:</span>
            <span class="n">kl_divergence_fn</span> <span class="o">=</span> <span class="n">kl_gamma</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unsupported distribution type: </span><span class="si">{</span><span class="n">r_distribution</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="s2">&quot;Must be &#39;lognormal&#39; or &#39;gamma&#39;.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Extract parameters from r distribution based on distribution type</span>
        <span class="k">if</span> <span class="n">r_distribution</span> <span class="o">==</span> <span class="n">dist</span><span class="o">.</span><span class="n">LogNormal</span><span class="p">:</span>
            <span class="n">r_param1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;r_loc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">r_param2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;r_scale&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">r_distribution</span> <span class="o">==</span> <span class="n">dist</span><span class="o">.</span><span class="n">Gamma</span><span class="p">:</span>
            <span class="n">r_param1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;r_concentration&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">r_param2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;r_rate&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

        <span class="c1"># Initialize dictionary to store divergences</span>
        <span class="n">kl_divergences</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Compute pairwise divergences for each component</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">j</span><span class="p">:</span>  <span class="c1"># Skip self-comparisons</span>
                    <span class="c1"># Compute KL divergence from component i to j</span>
                    <span class="n">kl_divergences</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kl_divergence_fn</span><span class="p">(</span>
                        <span class="n">r_param1</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">r_param2</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">r_param1</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">r_param2</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                    <span class="p">)</span>

        <span class="k">return</span> <span class="n">kl_divergences</span></div>


    <span class="c1"># --------------------------------------------------------------------------</span>
    <span class="c1"># Jensen-Shannon divergence for mixture models</span>
    <span class="c1"># --------------------------------------------------------------------------</span>

<div class="viewcode-block" id="ScribeResults.jensen_shannon_divergence">
<a class="viewcode-back" href="../../api/results.html#scribe.results.ScribeResults.jensen_shannon_divergence">[docs]</a>
    <span class="k">def</span> <span class="nf">jensen_shannon_divergence</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute pairwise Jensen-Shannon divergences between mixture model</span>
<span class="sd">        components.</span>
<span class="sd">        </span>
<span class="sd">        This method calculates the Jensen-Shannon (JS) divergence between each</span>
<span class="sd">        pair of components in the mixture model based on their inferred</span>
<span class="sd">        parameter distributions. The JS divergence is a symmetrized and smoothed</span>
<span class="sd">        version of the Kullback-Leibler divergence, defined as:</span>
<span class="sd">        </span>
<span class="sd">            JSD(P||Q) = 1/2  KL(P||M) + 1/2  KL(Q||M)</span>
<span class="sd">            </span>
<span class="sd">        where M = 1/2  (P + Q) is the average of the two distributions.</span>
<span class="sd">        </span>
<span class="sd">        Unlike KL divergence, JS divergence is symmetric and bounded between 0</span>
<span class="sd">        and 1 (when using log base 2) or between 0 and ln(2) (when using natural</span>
<span class="sd">        logarithm).</span>
<span class="sd">        </span>
<span class="sd">        The specific divergence calculation depends on the distribution type</span>
<span class="sd">        used for the dispersion parameter (r): </span>
<span class="sd">            - For LogNormal: Uses location and scale parameters </span>
<span class="sd">            - For Gamma: Uses concentration and rate parameters</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dtype : jnp.dtype, default=jnp.float32</span>
<span class="sd">            Data type for numerical precision in computations</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Dict[str, jnp.ndarray]</span>
<span class="sd">            Dictionary containing pairwise JS divergences between components.</span>
<span class="sd">            Keys are of the form &#39;i_j&#39; where i,j are component indices. Values</span>
<span class="sd">            are the JS divergences between components i and j.</span>
<span class="sd">            </span>
<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the model is not a mixture model with multiple components, or if</span>
<span class="sd">            the distribution type is not supported (must be LogNormal or Gamma)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if this is a mixture model</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Jensen-Shannon divergence calculation only applies to mixture models &quot;</span>
                <span class="s2">&quot;with multiple components&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Get r distribution from ModelConfig</span>
        <span class="n">r_distribution</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">r_distribution_guide</span><span class="p">)</span>
        
        <span class="c1"># Define corresponding JS divergence function based on distribution type</span>
        <span class="k">if</span> <span class="n">r_distribution</span> <span class="o">==</span> <span class="n">dist</span><span class="o">.</span><span class="n">LogNormal</span><span class="p">:</span>
            <span class="n">js_divergence_fn</span> <span class="o">=</span> <span class="n">jensen_shannon_lognormal</span>
        <span class="k">elif</span> <span class="n">r_distribution</span> <span class="o">==</span> <span class="n">dist</span><span class="o">.</span><span class="n">Gamma</span><span class="p">:</span>
            <span class="n">js_divergence_fn</span> <span class="o">=</span> <span class="n">jensen_shannon_gamma</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unsupported distribution type: </span><span class="si">{</span><span class="n">r_distribution</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="s2">&quot;Must be &#39;lognormal&#39; or &#39;gamma&#39;.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Extract parameters from r distribution based on distribution type</span>
        <span class="k">if</span> <span class="n">r_distribution</span> <span class="o">==</span> <span class="n">dist</span><span class="o">.</span><span class="n">LogNormal</span><span class="p">:</span>
            <span class="n">r_param1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;r_loc&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">r_param2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;r_scale&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">r_distribution</span> <span class="o">==</span> <span class="n">dist</span><span class="o">.</span><span class="n">Gamma</span><span class="p">:</span>
            <span class="n">r_param1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;r_concentration&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">r_param2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;r_rate&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

        <span class="c1"># Initialize dictionary to store divergences</span>
        <span class="n">js_divergences</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Compute pairwise divergences for each component</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">):</span>  <span class="c1"># Only compute for i &lt; j since JS is symmetric</span>
                <span class="c1"># Compute JS divergence between components i and j</span>
                <span class="n">js_divergences</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">js_divergence_fn</span><span class="p">(</span>
                    <span class="n">r_param1</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">r_param2</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">r_param1</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">r_param2</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                <span class="p">)</span>

        <span class="k">return</span> <span class="n">js_divergences</span></div>


    <span class="c1"># --------------------------------------------------------------------------</span>
    <span class="c1"># Cell type assignment method for mixture models</span>
    <span class="c1"># --------------------------------------------------------------------------</span>
    
<div class="viewcode-block" id="ScribeResults.cell_type_assignments">
<a class="viewcode-back" href="../../api/results.html#scribe.results.ScribeResults.cell_type_assignments">[docs]</a>
    <span class="k">def</span> <span class="nf">cell_type_assignments</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">counts</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cells_axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">ignore_nans</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
        <span class="n">fit_distribution</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">temperature</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">weight_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute probabilistic cell type assignments and fit Dirichlet</span>
<span class="sd">        distributions to characterize assignment uncertainty.</span>

<span class="sd">        For each cell, this method:</span>
<span class="sd">            1. Computes component-specific log-likelihoods using posterior</span>
<span class="sd">               samples</span>
<span class="sd">            2. Converts these to probability distributions over cell types</span>
<span class="sd">            3. Fits a Dirichlet distribution to characterize the uncertainty in</span>
<span class="sd">               these assignments</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        counts : jnp.ndarray</span>
<span class="sd">            Count data to evaluate assignments for</span>
<span class="sd">        batch_size : Optional[int], default=None</span>
<span class="sd">            Size of mini-batches for likelihood computation</span>
<span class="sd">        cells_axis : int, default=0</span>
<span class="sd">            Axis along which cells are arranged. 0 means cells are rows.</span>
<span class="sd">        ignore_nans : bool, default=False</span>
<span class="sd">            If True, removes any samples that contain NaNs.</span>
<span class="sd">        dtype : jnp.dtype, default=jnp.float32</span>
<span class="sd">            Data type for numerical precision in computations</span>
<span class="sd">        fit_distribution : bool, default=True</span>
<span class="sd">            If True, fits a Dirichlet distribution to the assignment</span>
<span class="sd">            probabilities</span>
<span class="sd">        temperature : Optional[float], default=None</span>
<span class="sd">            If provided, apply temperature scaling to log probabilities</span>
<span class="sd">        weights : Optional[jnp.ndarray], default=None</span>
<span class="sd">            Array used to weight genes when computing log likelihoods</span>
<span class="sd">        weight_type : Optional[str], default=None</span>
<span class="sd">            How to apply weights. Must be one of:</span>
<span class="sd">                - &#39;multiplicative&#39;: multiply log probabilities by weights</span>
<span class="sd">                - &#39;additive&#39;: add weights to log probabilities</span>
<span class="sd">        verbose : bool, default=True</span>
<span class="sd">            If True, prints progress messages</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Dict[str, jnp.ndarray]</span>
<span class="sd">            Dictionary containing:</span>
<span class="sd">                - &#39;concentration&#39;: Dirichlet concentration parameters for each</span>
<span class="sd">                  cell. Shape: (n_cells, n_components). Only returned if</span>
<span class="sd">                  fit_distribution is True.</span>
<span class="sd">                - &#39;mean_probabilities&#39;: Mean assignment probabilities for each</span>
<span class="sd">                  cell. Shape: (n_cells, n_components). Only returned if</span>
<span class="sd">                  fit_distribution is True.</span>
<span class="sd">                - &#39;sample_probabilities&#39;: Assignment probabilities for each</span>
<span class="sd">                  posterior sample. Shape: (n_samples, n_cells, n_components)</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            - If the model is not a mixture model</span>
<span class="sd">            - If posterior samples have not been generated yet</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if this is a mixture model</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Cell type assignment only applies to mixture models with &quot;</span>
                <span class="s2">&quot;multiple components&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Computing component-specific log-likelihoods...&quot;</span><span class="p">)</span>

        <span class="c1"># Compute component-specific log-likelihoods</span>
        <span class="c1"># Shape: (n_samples, n_cells, n_components)</span>
        <span class="n">log_liks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">(</span>
            <span class="n">counts</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">return_by</span><span class="o">=</span><span class="s1">&#39;cell&#39;</span><span class="p">,</span>
            <span class="n">cells_axis</span><span class="o">=</span><span class="n">cells_axis</span><span class="p">,</span>
            <span class="n">ignore_nans</span><span class="o">=</span><span class="n">ignore_nans</span><span class="p">,</span>
            <span class="n">split_components</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
            <span class="n">weight_type</span><span class="o">=</span><span class="n">weight_type</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Converting log-likelihoods to probabilities...&quot;</span><span class="p">)</span>

        <span class="c1"># Apply temperature scaling if requested</span>
        <span class="k">if</span> <span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log_liks</span> <span class="o">=</span> <span class="n">temperature_scaling</span><span class="p">(</span><span class="n">log_liks</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

        <span class="c1"># Convert log-likelihoods to probabilities using log-sum-exp for</span>
        <span class="c1"># stability. First compute log(sum(exp(x))) along component axis.</span>
        <span class="n">log_sum_exp</span> <span class="o">=</span> <span class="n">jsp</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">log_liks</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># Then subtract and exponentiate to get probabilities</span>
        <span class="n">probabilities</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_liks</span> <span class="o">-</span> <span class="n">log_sum_exp</span><span class="p">)</span>

        <span class="c1"># Get shapes</span>
        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_cells</span><span class="p">,</span> <span class="n">n_components</span> <span class="o">=</span> <span class="n">probabilities</span><span class="o">.</span><span class="n">shape</span>

        <span class="k">if</span> <span class="n">fit_distribution</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Fitting Dirichlet distribution...&quot;</span><span class="p">)</span>

            <span class="c1"># Initialize array for Dirichlet concentration parameters</span>
            <span class="n">concentrations</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_cells</span><span class="p">,</span> <span class="n">n_components</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

            <span class="c1"># Fit Dirichlet distribution for each cell</span>
            <span class="k">for</span> <span class="n">cell</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_cells</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="n">cell</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    - Fitting Dirichlet distributions for &quot;</span>
                          <span class="sa">f</span><span class="s2">&quot;cells </span><span class="si">{</span><span class="n">cell</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="nb">min</span><span class="p">(</span><span class="n">cell</span><span class="o">+</span><span class="mi">1000</span><span class="p">,</span><span class="w"> </span><span class="n">n_cells</span><span class="p">)</span><span class="si">}</span><span class="s2"> out of &quot;</span>
                          <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">n_cells</span><span class="si">}</span><span class="s2"> cells&quot;</span><span class="p">)</span>
                    
                <span class="c1"># Get probability vectors for this cell across all samples</span>
                <span class="n">cell_probs</span> <span class="o">=</span> <span class="n">probabilities</span><span class="p">[:,</span> <span class="n">cell</span><span class="p">,</span> <span class="p">:]</span>
                <span class="c1"># Fit Dirichlet using Minka&#39;s fixed-point method</span>
                <span class="n">concentrations</span> <span class="o">=</span> <span class="n">concentrations</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">cell</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                    <span class="n">fit_dirichlet_minka</span><span class="p">(</span><span class="n">cell_probs</span><span class="p">)</span>
                <span class="p">)</span>

            <span class="c1"># Compute mean probabilities (Dirichlet mean)</span>
            <span class="n">concentration_sums</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">concentrations</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">mean_probabilities</span> <span class="o">=</span> <span class="n">concentrations</span> <span class="o">/</span> <span class="n">concentration_sums</span>

            <span class="k">return</span> <span class="p">{</span>
                <span class="s1">&#39;concentration&#39;</span><span class="p">:</span> <span class="n">concentrations</span><span class="p">,</span>
                <span class="s1">&#39;mean_probabilities&#39;</span><span class="p">:</span> <span class="n">mean_probabilities</span><span class="p">,</span>
                <span class="s1">&#39;sample_probabilities&#39;</span><span class="p">:</span> <span class="n">probabilities</span>
            <span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="s1">&#39;sample_probabilities&#39;</span><span class="p">:</span> <span class="n">probabilities</span>
            <span class="p">}</span></div>


    <span class="c1"># --------------------------------------------------------------------------</span>

<div class="viewcode-block" id="ScribeResults.cell_type_assignments_map">
<a class="viewcode-back" href="../../api/results.html#scribe.results.ScribeResults.cell_type_assignments_map">[docs]</a>
    <span class="k">def</span> <span class="nf">cell_type_assignments_map</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">counts</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cells_axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
        <span class="n">temperature</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">weight_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_mean</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute probabilistic cell type assignments using MAP estimates of</span>
<span class="sd">        parameters.</span>
<span class="sd">        </span>
<span class="sd">        For each cell, this method:</span>
<span class="sd">            1. Computes component-specific log-likelihoods using MAP parameter</span>
<span class="sd">            estimates</span>
<span class="sd">            2. Converts these to probability distributions over cell types</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        counts : jnp.ndarray</span>
<span class="sd">            Count data to evaluate assignments for</span>
<span class="sd">        batch_size : Optional[int], default=None</span>
<span class="sd">            Size of mini-batches for likelihood computation</span>
<span class="sd">        cells_axis : int, default=0</span>
<span class="sd">            Axis along which cells are arranged. 0 means cells are rows.</span>
<span class="sd">        dtype : jnp.dtype, default=jnp.float32</span>
<span class="sd">            Data type for numerical precision in computations</span>
<span class="sd">        temperature : Optional[float], default=None</span>
<span class="sd">            If provided, apply temperature scaling to log probabilities</span>
<span class="sd">        weights : Optional[jnp.ndarray], default=None</span>
<span class="sd">            Array used to weight genes when computing log likelihoods</span>
<span class="sd">        weight_type : Optional[str], default=None</span>
<span class="sd">            How to apply weights. Must be one of:</span>
<span class="sd">                - &#39;multiplicative&#39;: multiply log probabilities by weights</span>
<span class="sd">                - &#39;additive&#39;: add weights to log probabilities</span>
<span class="sd">        use_mean : bool, default=False</span>
<span class="sd">            If True, replaces undefined MAP values (NaN) with posterior means</span>
<span class="sd">        verbose : bool, default=True</span>
<span class="sd">            If True, prints progress messages</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Dict[str, jnp.ndarray]</span>
<span class="sd">            Dictionary containing:</span>
<span class="sd">                - &#39;probabilities&#39;: Assignment probabilities for each cell.</span>
<span class="sd">                Shape: (n_cells, n_components)</span>
<span class="sd">                </span>
<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the model is not a mixture model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if this is a mixture model</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Cell type assignment only applies to mixture models with &quot;</span>
                <span class="s2">&quot;multiple components&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Computing component-specific log-likelihoods...&quot;</span><span class="p">)</span>

        <span class="c1"># Get the log likelihood function</span>
        <span class="n">likelihood_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood_fn</span><span class="p">()</span>

        <span class="c1"># Get the MAP estimates</span>
        <span class="n">map_estimates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_map</span><span class="p">()</span>
        
        <span class="c1"># Replace NaN values with means if requested</span>
        <span class="k">if</span> <span class="n">use_mean</span><span class="p">:</span>
            <span class="c1"># Get distributions to compute means</span>
            <span class="n">distributions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_distributions</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s2">&quot;numpyro&quot;</span><span class="p">)</span>
            
            <span class="c1"># Check each parameter for NaNs and replace with means</span>
            <span class="n">any_replaced</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">map_estimates</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="c1"># Check if any values are NaN</span>
                <span class="k">if</span> <span class="n">jnp</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">value</span><span class="p">)):</span>
                    <span class="c1"># Update flag</span>
                    <span class="n">any_replaced</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="c1"># Get mean value</span>
                    <span class="n">mean_value</span> <span class="o">=</span> <span class="n">distributions</span><span class="p">[</span><span class="n">param</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span>
                    <span class="c1"># Replace NaN values with means</span>
                    <span class="n">map_estimates</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                        <span class="n">jnp</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">value</span><span class="p">),</span>
                        <span class="n">mean_value</span><span class="p">,</span>
                        <span class="n">value</span>
                    <span class="p">)</span>
            
            <span class="k">if</span> <span class="n">any_replaced</span> <span class="ow">and</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;    - Replaced undefined MAP values with posterior means&quot;</span><span class="p">)</span>
        
        <span class="c1"># Compute component-specific log-likelihoods using MAP estimates</span>
        <span class="c1"># Shape: (n_cells, n_components)</span>
        <span class="n">log_liks</span> <span class="o">=</span> <span class="n">likelihood_fn</span><span class="p">(</span>
            <span class="n">counts</span><span class="p">,</span>
            <span class="n">map_estimates</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">cells_axis</span><span class="o">=</span><span class="n">cells_axis</span><span class="p">,</span>
            <span class="n">return_by</span><span class="o">=</span><span class="s1">&#39;cell&#39;</span><span class="p">,</span>
            <span class="n">split_components</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
            <span class="n">weight_type</span><span class="o">=</span><span class="n">weight_type</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span>
        <span class="p">)</span>

        <span class="c1"># Assert shape of log_liks</span>
        <span class="k">assert</span> <span class="n">log_liks</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cells</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_components</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;- Converting log-likelihoods to probabilities...&quot;</span><span class="p">)</span>

        <span class="c1"># Apply temperature scaling if requested</span>
        <span class="k">if</span> <span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">log_liks</span> <span class="o">=</span> <span class="n">temperature_scaling</span><span class="p">(</span><span class="n">log_liks</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

        <span class="c1"># Convert log-likelihoods to probabilities using log-sum-exp for</span>
        <span class="c1"># stability. First compute log(sum(exp(x))) along component axis</span>
        <span class="n">log_sum_exp</span> <span class="o">=</span> <span class="n">jsp</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">log_liks</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># Then subtract and exponentiate to get probabilities</span>
        <span class="n">probabilities</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_liks</span> <span class="o">-</span> <span class="n">log_sum_exp</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;probabilities&#39;</span><span class="p">:</span> <span class="n">probabilities</span>
        <span class="p">}</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Manuel Razo.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>