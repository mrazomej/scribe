{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from utils import matplotlib_style\n",
    "cor, pal = matplotlib_style()\n",
    "\n",
    "# Set random seed\n",
    "RANDOM_SEED = 42\n",
    "rng = np.random.default_rng(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-molecule mRNA FISH inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will explore the validity of our statistical model using\n",
    "single-molecule mRNA FISH data from [this paper from the Elowitz\n",
    "lab](https://doi.org/10.1016/j.molcel.2014.06.029)\n",
    "\n",
    "Let us begin by importing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tidy dataframe with mRNA counts\n",
    "df_counts = pd.read_csv('../data/singer_transcript_counts.csv', comment='#')\n",
    "\n",
    "df_counts.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data has counts for four different genes: `Rex1`, `Rest`,\n",
    "`Nanog`, and `Prdm14`. Let's plot the individual ECDFs for each of these genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig, ax = plt.subplots(1, 1, figsize=(1.5, 1.5))\n",
    "\n",
    "# Extract column names\n",
    "genes = df_counts.columns\n",
    "\n",
    "# Loop throu each gene\n",
    "for (i, gene) in enumerate(genes):\n",
    "    # Plot the ECDF for each column in the DataFrame\n",
    "    sns.ecdfplot(\n",
    "        data=df_counts,\n",
    "        x=gene,\n",
    "        ax=ax,\n",
    "        color=pal[i],\n",
    "        label=gene,\n",
    "        lw=1\n",
    "    )\n",
    "\n",
    "# Add axis labels\n",
    "ax.set_xlabel('mRNA count')\n",
    "ax.set_ylabel('ECDF')\n",
    "\n",
    "# Add legend\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems like a very good dataset to tests the assumptions of our model as\n",
    "there is clear variability between the different genes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Binomial-Dirichlet-Multinomial model (`scrappy`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our main full model assumes that the joint distribution over all genes mRNA\n",
    "counts is given by the product of independent negative binomial distributions\n",
    "for each gene, with the strong assumption that all genes share the same $p$\n",
    "parameter (the probability of success in each trial). Therefore, our inference\n",
    "is over the parameters\n",
    "$$\n",
    "\\underline{r} = [r_1, r_2, \\cdots, r_G],\n",
    "\\tag{1}\n",
    "$$\n",
    "where $G$ is the number of genes, and $p$, the probability of success in each\n",
    "trial. By Bayes' theorem, we have\n",
    "$$\n",
    "\\pi(\\underline{r}, p | \\underline{\\underline{M}}) \\propto \n",
    "\\pi(\\underline{\\underline{M}} | \\underline{r}, p) \\pi(\\underline{r}, p),\n",
    "\\tag{2}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\underline{\\underline{M}} = \\begin{bmatrix} \n",
    "\\lvert & \\lvert & \\cdots & \\lvert \\\\\n",
    "\\underline{m}^{(1)} & \\underline{m}^{(2)} & \\cdots & \\underline{m}^{(C)} \\\\\n",
    "\\lvert & \\lvert & \\cdots & \\lvert \n",
    "\\end{bmatrix},\n",
    "\\tag{3}\n",
    "$$\n",
    "is the data matrix with $C$ cells and each column $\\underline{m}^{(c)}$ is the\n",
    "transcriptional profile of cell $c$, i.e., the mRNA counts for each gene in\n",
    "cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of assuming each gene is drawn from an indepdendent negative binomial, we\n",
    "assume each cell is indepedent, allowing us to write the likelihood as\n",
    "$$\n",
    "\\pi(\\underline{\\underline{M}} | \\underline{r}, p) =\n",
    "\\prod_{c=1}^C \\prod_{g=1}^G \\pi(m_g^{(c)} | r_g, p),\n",
    "\\tag{4}\n",
    "$$\n",
    "where $m_g^{(c)}$ is the mRNA count of gene $g$ in cell $c$. Furthermore, we \n",
    "assume that each parameter is independent and that all $r_g$ are drawn from the\n",
    "same prior distribution. Therefore, we can write the prior as\n",
    "$$\n",
    "\\pi(\\underline{r}, p) = \\pi(p) \\pi(r)^G,\n",
    "\\tag{5}\n",
    "$$\n",
    "where $\\pi(r)$ is the shared prior for all $r_g$.\n",
    "\n",
    "Putting all of these together, we can write the posterior as\n",
    "$$\n",
    "\\pi(\\underline{r}, p | \\underline{\\underline{M}}) \\propto\n",
    "\\pi(p) \\pi(r)^G \\prod_{c=1}^C \\prod_{g=1}^G \\pi(m_g^{(c)} | r_g, p).\n",
    "\\tag{6}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the functional forms, we established that the likelihood is a negative\n",
    "binomial distribution. It can be shown that the joint distribution of negative\n",
    "binomials with shared $p$ parameter is given by the product of a negative\n",
    "binomial for the total mRNA count and a dirichlet-multinomial for the partition\n",
    "of the total mRNA count among the different genes. Therefore, we can write the\n",
    "likelihood for each cell as\n",
    "$$\n",
    "\\begin{aligned}\n",
    "M^{(c)} | r_o, p &\\sim \\text{NegBinom}(r_o, p),\\\\\n",
    "\\underline{m}^{(c)} | M^{(c)},\\underline{r} &\\sim \n",
    "\\text{DirMult}(M^{(c)}, \\underline{r}), \n",
    "\\end{aligned}\n",
    "\\tag{7}\n",
    "$$\n",
    "where $M^{(c)}$ is the total mRNA count in cell $c$ and $r_o = \\sum_{g=1}^G\n",
    "r_g$.\n",
    "\n",
    "For the priors, we know that $p \\in [0, 1]$ and that $r_g$ are positive. We can\n",
    "therefore choose a $Beta$ prior for $p$ and a $Gamma$ prior for $r_g$. This\n",
    "leads to\n",
    "$$\n",
    "p \\sim \\text{Beta}(\\alpha_p, \\beta_p),\n",
    "\\tag{8}\n",
    "$$\n",
    "and \n",
    "$$\n",
    "r \\sim \\text{Gamma}(\\alpha_r, \\beta_r).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write this model in `PyMC`. First we define the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define total number of genes\n",
    "n_genes = len(genes)\n",
    "\n",
    "# Define total number of counts per cell as the sum per row\n",
    "M_cells = df_counts.sum(axis=1)\n",
    "\n",
    "# Define counts per cell\n",
    "m_cells = df_counts.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a `pm.Model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model\n",
    "with pm.Model() as scFISH_negbin_dirmult:\n",
    "    # Define prior on p\n",
    "    p = pm.Beta('p', alpha=1, beta=1)\n",
    "    # Define prior on all r parameters\n",
    "    r_vec = pm.Gamma('r_vec', alpha=2, beta=2, shape=df_counts.shape[1])\n",
    "\n",
    "    # Sum of r parameters\n",
    "    r_o = pm.math.sum(r_vec)\n",
    "\n",
    "    # Likelihood for Total observed counts\n",
    "    M = pm.NegativeBinomial(\"M\", p=p, alpha=r_o, observed=M_cells)\n",
    "\n",
    "    # Use Dirichlet-Multinomial distribution for observed counts\n",
    "    m_vec = pm.DirichletMultinomial(\n",
    "        \"counts\", n=M, a=r_vec, observed=m_cells\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined the model, let's generate prior predictive samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model to sample from the prior\n",
    "with scFISH_negbin_dirmult:\n",
    "    # sample from the prior\n",
    "    prior_pred_check_dm = pm.sample_prior_predictive(\n",
    "        draws=100, random_seed=rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's contrast the prior predictive samples with the data for the total counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig, ax = plt.subplots(1, 2, figsize=(3, 1.5))\n",
    "\n",
    "# Plot histogram of the real data total counts\n",
    "ax[0].hist(\n",
    "    M_cells,\n",
    "    bins=range(0, max(M_cells)),\n",
    "    alpha=0.75,\n",
    "    label='data',\n",
    "    density=True\n",
    ")\n",
    "\n",
    "# Plot histogram of prior predictive checks total counts\n",
    "ax[0].hist(\n",
    "    prior_pred_check_dm.prior_predictive.M.values.flatten(),\n",
    "    bins=range(0, max(M_cells)),\n",
    "    alpha=0.75,\n",
    "    label='PPC',\n",
    "    density=True\n",
    ")\n",
    "\n",
    "# Set log scale on y axis\n",
    "ax[0].set_yscale('log')\n",
    "\n",
    "# Plot ECDF of the real data total counts\n",
    "sns.ecdfplot(\n",
    "    M_cells,\n",
    "    ax=ax[1],\n",
    "    label='data',\n",
    ")\n",
    "\n",
    "# Plot ECDF of the prior predictive checks total counts\n",
    "sns.ecdfplot(\n",
    "    prior_pred_check_dm.prior_predictive.M.values.flatten(),\n",
    "    ax=ax[1],\n",
    "    label='PPC',\n",
    ")\n",
    "\n",
    "# Add legend\n",
    "ax[1].legend()\n",
    "\n",
    "# Add axis labels\n",
    "ax[0].set_xlabel('total counts')\n",
    "ax[1].set_xlabel('total counts')\n",
    "ax[0].set_ylabel('density')\n",
    "ax[1].set_ylabel('ECDF')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can sample from the posterior using the NUTS sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform MCMC sampling with 4 chains\n",
    "with scFISH_negbin_dirmult:\n",
    "    trace = pm.sample(4000, tune=1000, chains=4, cores=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the trace for each of the chains. For this, we will use the\n",
    "convenient `plot_trace` function from `ArviZ`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trace\n",
    "az.plot_trace(trace, compact=False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, what we look for are traces that are stable and do not show any\n",
    "obvious pathologies. These traces look reasonably stable, so we can proceed to\n",
    "examine the posterior distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot posterior\n",
    "az.plot_posterior(trace, var_names=['p', 'r_vec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a corner plot of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot corner plot\n",
    "axes = az.plot_pair(\n",
    "    trace, var_names=['p', 'r_vec'], kind=\"scatter\", marginals=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now sample from the posterior predictive distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with scFISH_negbin_dirmult:\n",
    "    post_pred_check_dm = pm.sample_posterior_predictive(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having these posterior predictive (retrodictive) checks in place allows us to\n",
    "compare the model's predictions with the observed data. Let's plot the ECDFs for\n",
    "the total mRNA count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Initialize figure\n",
    "fig, ax = plt.subplots(1, 1, figsize=(1.5, 1.5))\n",
    "\n",
    "# Define number of samples to plot\n",
    "n_samples = 200\n",
    "\n",
    "# Pick first dimension random indexes\n",
    "x_idx = rng.choice(\n",
    "    np.arange(post_pred_check_dm.posterior_predictive.M.values.shape[0]),\n",
    "    size=n_samples\n",
    ")\n",
    "# Pick second dimension random indexes\n",
    "y_idx = rng.choice(\n",
    "    np.arange(post_pred_check_dm.posterior_predictive.M.values.shape[1]),\n",
    "    size=n_samples\n",
    ")\n",
    "\n",
    "# Loop through samples\n",
    "for i in range(n_samples):\n",
    "    # Plot ECDF of the posterior predictive checks total counts\n",
    "    sns.ecdfplot(\n",
    "        post_pred_check_dm.posterior_predictive.M.values[x_idx[i], y_idx[i], :],\n",
    "        ax=ax,\n",
    "        color='gray',\n",
    "        alpha=0.1\n",
    "    )\n",
    "\n",
    "# Plot ECDF of the real data total counts\n",
    "sns.ecdfplot(\n",
    "    M_cells,\n",
    "    ax=ax,\n",
    "    label='data',\n",
    ")\n",
    "\n",
    "# Label axis\n",
    "ax.set_xlabel('total counts')\n",
    "ax.set_ylabel('ECDF')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the ECDFs for the mRNA counts of each gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Initialize figure\n",
    "fig, axes = plt.subplots(2, 2, figsize=(3, 3))\n",
    "\n",
    "# Flatten axes\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Define number of samples to plot\n",
    "n_samples = 200\n",
    "\n",
    "# Pick first dimension random indexes\n",
    "x_idx = rng.choice(\n",
    "    np.arange(post_pred_check_dm.posterior_predictive.M.values.shape[0]),\n",
    "    size=n_samples\n",
    ")\n",
    "# Pick second dimension random indexes\n",
    "y_idx = rng.choice(\n",
    "    np.arange(post_pred_check_dm.posterior_predictive.M.values.shape[1]),\n",
    "    size=n_samples\n",
    ")\n",
    "\n",
    "# Loop through each gene\n",
    "for (i, ax) in enumerate(axes):\n",
    "    # Loop through samples\n",
    "    for j in range(n_samples):\n",
    "        # Plot ECDF of the posterior predictive checks total counts\n",
    "        sns.ecdfplot(\n",
    "            post_pred_check_dm.posterior_predictive.counts.values[x_idx[j],\n",
    "                                                                  y_idx[j],\n",
    "                                                                  :, i],\n",
    "            ax=ax,\n",
    "            color='gray',\n",
    "            alpha=0.1\n",
    "        )\n",
    "    # Plot ECDF of the real data total counts\n",
    "    sns.ecdfplot(\n",
    "        m_cells[:, i],\n",
    "        ax=ax,\n",
    "        label='data',\n",
    "    )\n",
    "    # Label axis\n",
    "    ax.set_xlabel('counts')\n",
    "    ax.set_ylabel('ECDF')\n",
    "    # Set title\n",
    "    ax.set_title(genes[i])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is not completely able to capture the variability in the data. This\n",
    "is caused by the strong assumption that all genes share the same $p$ parameter.\n",
    "\n",
    "However, this needs to be contrasted with the state-of-the-art model for single\n",
    "cell RNA-seq data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson-Multinomial model (`sanity`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method published by [Breda et\n",
    "al.](https://www.nature.com/articles/s41587-021-00875-x), referred to as\n",
    "`sanity`, is considered the state-of-the-art for single-cell RNA-seq data \n",
    "Bayesian analysis. The novelty of this method is to bring the power of the \n",
    "Bayesian paradigm to large-scale single-cell RNA-seq datasets. However, because\n",
    "of the tremendous dimensionality of the parameter space, `sanity` uses several\n",
    "approximations that make it computationally feasible, albeit at the cost of\n",
    "loosing the ability to properly describe the data.\n",
    "\n",
    "To show this, we will attempt to fit the basis of the `sanity` model without the \n",
    "approximations needed for computational feasibility on this sc-FISH dataset. \n",
    "Although `sanity`'s model has sc-RNAseq data in mind, the generative model they\n",
    "define should be applicable regardless of how gene expression is measured.\n",
    "\n",
    "The basic structure of the model consits of having each mRNA count be drawn from\n",
    "a Poisson distribution whose parameter\n",
    "$$\n",
    "\\lambda_g = \\alpha_g \\langle M \\rangle,\n",
    "\\tag{9}\n",
    "$$\n",
    "is composed by the product of a gene-specific parameter $\\alpha_g$ and the mean\n",
    "number of total mRNA counts in a cell $\\langle M \\rangle$. The $\\alpha_g$ \n",
    "parameters must satisfy the constraint that\n",
    "$$\n",
    "\\sum_{g=1}^G \\alpha_g = 1, \\; \\forall \\; \\alpha_g \\geq 0,\n",
    "\\tag{10}\n",
    "$$\n",
    "i.e., they must form a probability simplex. This parameterization allows for\n",
    "the normalization of the gene expression levels as the parameter that matters\n",
    "for any experiment is this relative expression level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these two parameters in the model, by Bayes' theorem, we have\n",
    "$$\n",
    "\\pi(\\underline{\\alpha}, \\langle M \\rangle | \\underline{\\underline{M}}) \\propto\n",
    "\\pi(\\underline{\\underline{M}} | \\underline{\\alpha}, \\langle M \\rangle)\n",
    "\\pi(\\underline{\\alpha}, \\langle M \\rangle).\n",
    "\\tag{11}\n",
    "$$\n",
    "As before, we assume that both genes and cells are independent, so the\n",
    "likelihood can be expressed as\n",
    "$$\n",
    "\\pi(\\underline{\\underline{M}} | \\underline{\\alpha}, \\langle M \\rangle) =\n",
    "\\prod_{c=1}^C \\prod_{g=1}^G \\pi(m_g^{(c)} | \\alpha_g, \\langle M \\rangle).\n",
    "\\tag{12}\n",
    "$$\n",
    "For the prior, we cannot assume that the $\\alpha_g$ are independent, as they\n",
    "must add up to one. However, we can assume that the mean total mRNA count is\n",
    "indepedent of the $\\alpha_g$. Therefore, we can write the prior as\n",
    "$$\n",
    "\\pi(\\underline{\\alpha}, \\langle M \\rangle) = \n",
    "\\pi(\\langle M \\rangle) \\pi(\\underline{\\alpha}).\n",
    "\\tag{13}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the functional forms, we know that the likelihood is a Poisson distribution,\n",
    "i.e.,\n",
    "$$\n",
    "m_g^{(c)} | \\alpha_g, \\langle M \\rangle \\sim \n",
    "\\text{Poisson}(\\alpha_g \\langle M \\rangle).\n",
    "\\tag{14}\n",
    "$$\n",
    "The natural choice for the prior of the $\\alpha_g$ is the Dirichlet\n",
    "distribution, i.e.,\n",
    "$$\n",
    "\\underline{\\alpha} \\sim \\text{Dirichlet}(\\underline{\\beta}),\n",
    "\\tag{15}\n",
    "$$\n",
    "where $\\underline{\\beta}$ is a vector of concentration parameters. Finally, for\n",
    "the prior of the mean total mRNA count, we can choose a strictly positive\n",
    "distribution, such as the Gamma distribution or, as we will do below, a\n",
    "lognormal distribution, i.e.,\n",
    "$$\n",
    "\\langle M \\rangle \\sim \\text{LogNormal}(\\mu, \\sigma).\n",
    "\\tag{16}\n",
    "$$\n",
    "\n",
    "One can show that the joint distribution of independent Poisson distributions\n",
    "for each gene can be expressed as the product of a Poisson distribution for the\n",
    "total mRNA and a multinomial distribution for the partition of the total mRNA\n",
    "into the different genes. Therefore, the likelihood for each cell can be written\n",
    "as\n",
    "$$\n",
    "\\begin{aligned}\n",
    "M^{(c)} | \\langle M \\rangle &\\sim \\text{Poisson}(\\langle M \\rangle),\\\\\n",
    "\\underline{m}^{(c)} | M^{(c)}, \\underline{\\alpha} &\\sim\n",
    "\\text{Multinomial}(M^{(c)}, \\underline{\\alpha}).\n",
    "\\end{aligned}\n",
    "\\tag{17}\n",
    "$$\n",
    "\n",
    "We can now write the model in `PyMC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model\n",
    "with pm.Model() as scFISH_poisson_multinomial:\n",
    "    # Define prior on r_o for total counts\n",
    "    r_o = pm.LogNormal('r_o', mu=2, sigma=2.5)\n",
    "\n",
    "    # Define prior on p vector from a Dirichlet distribution\n",
    "    alpha_vec = pm.Dirichlet('alpha_vec', a=np.ones(df_counts.shape[1]))\n",
    "\n",
    "    # Likelihood for Total observed counts\n",
    "    M = pm.Poisson(\"M\", mu=r_o, observed=M_cells)\n",
    "\n",
    "    # Use Dirichlet-Multinomial distribution for observed counts\n",
    "    m_vec = pm.Multinomial(\n",
    "        \"counts\", n=M, p=alpha_vec, observed=m_cells\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined the model, let's generate prior predictive samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model to sample from the prior\n",
    "with scFISH_poisson_multinomial:\n",
    "    # sample from the prior\n",
    "    prior_pred_check_pm = pm.sample_prior_predictive(\n",
    "        draws=100, random_seed=rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's contrast the prior predictive samples with the data for the total counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig, ax = plt.subplots(1, 2, figsize=(3, 1.5))\n",
    "\n",
    "# Plot histogram of the real data total counts\n",
    "ax[0].hist(\n",
    "    M_cells,\n",
    "    bins=range(0, max(M_cells)),\n",
    "    alpha=0.75,\n",
    "    label='data',\n",
    "    density=True\n",
    ")\n",
    "\n",
    "# Plot histogram of prior predictive checks total counts\n",
    "ax[0].hist(\n",
    "    prior_pred_check_pm.prior_predictive.M.values.flatten(),\n",
    "    bins=range(0, max(M_cells)),\n",
    "    alpha=0.75,\n",
    "    label='PPC',\n",
    "    density=True\n",
    ")\n",
    "\n",
    "# Set log scale on y axis\n",
    "ax[0].set_yscale('log')\n",
    "\n",
    "# Plot ECDF of the real data total counts\n",
    "sns.ecdfplot(\n",
    "    M_cells,\n",
    "    ax=ax[1],\n",
    "    label='data',\n",
    ")\n",
    "\n",
    "# Plot ECDF of the prior predictive checks total counts\n",
    "sns.ecdfplot(\n",
    "    prior_pred_check_pm.prior_predictive.M.values.flatten(),\n",
    "    ax=ax[1],\n",
    "    label='PPC',\n",
    ")\n",
    "\n",
    "# Seet ylim\n",
    "ax[1].set_ylim(0, 1.05)\n",
    "# Add legend\n",
    "ax[1].legend()\n",
    "\n",
    "# Add axis labels\n",
    "ax[0].set_xlabel('total counts')\n",
    "ax[1].set_xlabel('total counts')\n",
    "ax[0].set_ylabel('density')\n",
    "ax[1].set_ylabel('ECDF')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can sample from the posterior using the NUTS sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform MCMC sampling with 4 chains\n",
    "with scFISH_poisson_multinomial:\n",
    "    trace_pm = pm.sample(4000, tune=1000, chains=4, cores=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the trace for each of the chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trace\n",
    "az.plot_trace(trace_pm, compact=False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the traces look reasonably stable, so we can proceed to examine the\n",
    "posterior distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot corner plot\n",
    "axes = az.plot_pair(\n",
    "    trace_pm, var_names=['r_o', 'alpha_vec'], kind=\"scatter\", marginals=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now sample from the posterior predictive distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with scFISH_poisson_multinomial:\n",
    "    post_pred_check_pm = pm.sample_posterior_predictive(trace_pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having these posterior predictive (retrodictive) checks in place allows us to\n",
    "compare the model's predictions with the observed data. Let's plot the ECDFs for\n",
    "the total mRNA count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Initialize figure\n",
    "fig, ax = plt.subplots(1, 1, figsize=(1.5, 1.5))\n",
    "\n",
    "# Define number of samples to plot\n",
    "n_samples = 200\n",
    "\n",
    "# Pick first dimension random indexes\n",
    "x_idx = rng.choice(\n",
    "    np.arange(post_pred_check_pm.posterior_predictive.M.values.shape[0]),\n",
    "    size=n_samples\n",
    ")\n",
    "# Pick second dimension random indexes\n",
    "y_idx = rng.choice(\n",
    "    np.arange(post_pred_check_pm.posterior_predictive.M.values.shape[1]),\n",
    "    size=n_samples\n",
    ")\n",
    "\n",
    "# Loop through samples\n",
    "for i in range(n_samples):\n",
    "    # Plot ECDF of the posterior predictive checks total counts\n",
    "    sns.ecdfplot(\n",
    "        post_pred_check_pm.posterior_predictive.M.values[x_idx[i], y_idx[i], :],\n",
    "        ax=ax,\n",
    "        color='gray',\n",
    "        alpha=0.1\n",
    "    )\n",
    "\n",
    "# Plot ECDF of the real data total counts\n",
    "sns.ecdfplot(\n",
    "    M_cells,\n",
    "    ax=ax,\n",
    "    label='data',\n",
    ")\n",
    "\n",
    "# Label axis\n",
    "ax.set_xlabel('total counts')\n",
    "ax.set_ylabel('ECDF')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the ECDFs for the mRNA counts of each gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Initialize figure\n",
    "fig, axes = plt.subplots(2, 2, figsize=(3, 3))\n",
    "\n",
    "# Flatten axes\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Define number of samples to plot\n",
    "n_samples = 200\n",
    "\n",
    "# Pick first dimension random indexes\n",
    "x_idx = rng.choice(\n",
    "    np.arange(post_pred_check_pm.posterior_predictive.M.values.shape[0]),\n",
    "    size=n_samples\n",
    ")\n",
    "# Pick second dimension random indexes\n",
    "y_idx = rng.choice(\n",
    "    np.arange(post_pred_check_pm.posterior_predictive.M.values.shape[1]),\n",
    "    size=n_samples\n",
    ")\n",
    "\n",
    "# Loop through each gene\n",
    "for (i, ax) in enumerate(axes):\n",
    "    # Loop through samples\n",
    "    for j in range(n_samples):\n",
    "        # Plot ECDF of the posterior predictive checks total counts\n",
    "        sns.ecdfplot(\n",
    "            post_pred_check_pm.posterior_predictive.counts.values[x_idx[j],\n",
    "                                                                  y_idx[j],\n",
    "                                                                  :, i],\n",
    "            ax=ax,\n",
    "            color='gray',\n",
    "            alpha=0.1\n",
    "        )\n",
    "    # Plot ECDF of the real data total counts\n",
    "    sns.ecdfplot(\n",
    "        m_cells[:, i],\n",
    "        ax=ax,\n",
    "        label='data',\n",
    "    )\n",
    "    # Label axis\n",
    "    ax.set_xlabel('counts')\n",
    "    ax.set_ylabel('ECDF')\n",
    "    # Set title\n",
    "    ax.set_title(genes[i])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is obviously a terrible fit. The Poisson model is not able to capture the\n",
    "overdispersion in the data. To emphasize this even more, let's plot both\n",
    "posterior predictive distributions for the total mRNA count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Initialize figure\n",
    "fig, ax = plt.subplots(1, 1, figsize=(1.5, 1.5))\n",
    "\n",
    "# Define number of samples to plot\n",
    "n_samples = 200\n",
    "\n",
    "# Pick first dimension random indexes\n",
    "x_idx = rng.choice(\n",
    "    np.arange(post_pred_check_dm.posterior_predictive.M.values.shape[0]),\n",
    "    size=n_samples\n",
    ")\n",
    "# Pick second dimension random indexes\n",
    "y_idx = rng.choice(\n",
    "    np.arange(post_pred_check_dm.posterior_predictive.M.values.shape[1]),\n",
    "    size=n_samples\n",
    ")\n",
    "\n",
    "# Loop through samples\n",
    "for i in range(n_samples):\n",
    "    # Plot ECDF of the posterior predictive checks total counts\n",
    "    sns.ecdfplot(\n",
    "        post_pred_check_dm.posterior_predictive.M.values[x_idx[i], y_idx[i], :],\n",
    "        ax=ax,\n",
    "        color=cor['pale_blue'],\n",
    "        alpha=0.1,\n",
    "    )\n",
    "\n",
    "# Loop through samples\n",
    "for i in range(n_samples):\n",
    "    # Plot ECDF of the posterior predictive checks total counts\n",
    "    sns.ecdfplot(\n",
    "        post_pred_check_pm.posterior_predictive.M.values[x_idx[i], y_idx[i], :],\n",
    "        ax=ax,\n",
    "        color=cor['pale_red'],\n",
    "        alpha=0.1,\n",
    "    )\n",
    "\n",
    "\n",
    "# Plot ECDF of the real data total counts\n",
    "sns.ecdfplot(\n",
    "    M_cells,\n",
    "    ax=ax,\n",
    "    label='data',\n",
    ")\n",
    "\n",
    "# Set fake plots not plotting anything for the legend\n",
    "ax.plot([], [], color=cor['pale_blue'], label='NegBin-DirMult')\n",
    "ax.plot([], [], color=cor['pale_red'], label='Poiss-Mult')\n",
    "\n",
    "# Add legend\n",
    "ax.legend(loc='lower right', fontsize=4)\n",
    "\n",
    "# Label axis\n",
    "ax.set_xlabel('total counts')\n",
    "ax.set_ylabel('ECDF')\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for the individual genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Initialize figure\n",
    "fig, axes = plt.subplots(2, 2, figsize=(3, 3))\n",
    "\n",
    "# Flatten axes\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Define number of samples to plot\n",
    "n_samples = 200\n",
    "\n",
    "# Pick first dimension random indexes\n",
    "x_idx = rng.choice(\n",
    "    np.arange(post_pred_check_dm.posterior_predictive.M.values.shape[0]),\n",
    "    size=n_samples\n",
    ")\n",
    "# Pick second dimension random indexes\n",
    "y_idx = rng.choice(\n",
    "    np.arange(post_pred_check_dm.posterior_predictive.M.values.shape[1]),\n",
    "    size=n_samples\n",
    ")\n",
    "\n",
    "# Loop through each gene\n",
    "for (i, ax) in enumerate(axes):\n",
    "    # Loop through samples\n",
    "    for j in range(n_samples):\n",
    "        # Plot ECDF of the posterior predictive checks total counts\n",
    "        sns.ecdfplot(\n",
    "            post_pred_check_dm.posterior_predictive.counts.values[x_idx[j],\n",
    "                                                                  y_idx[j],\n",
    "                                                                  :, i],\n",
    "            ax=ax,\n",
    "            color=cor['pale_blue'],\n",
    "            alpha=0.1\n",
    "        )\n",
    "        sns.ecdfplot(\n",
    "            post_pred_check_pm.posterior_predictive.counts.values[x_idx[j],\n",
    "                                                                  y_idx[j],\n",
    "                                                                  :, i],\n",
    "            ax=ax,\n",
    "            color=cor['pale_red'],\n",
    "            alpha=0.1\n",
    "        )\n",
    "    # Plot ECDF of the real data total counts\n",
    "    sns.ecdfplot(\n",
    "        m_cells[:, i],\n",
    "        ax=ax,\n",
    "        label='data',\n",
    "    )\n",
    "    # Label axis\n",
    "    ax.set_xlabel('counts')\n",
    "    ax.set_ylabel('ECDF')\n",
    "    # Set title\n",
    "    ax.set_title(genes[i])\n",
    "    # Set fake plots not plotting anything for the legend\n",
    "    ax.plot([], [], color=cor['pale_blue'], label='NegBin-DirMult')\n",
    "    ax.plot([], [], color=cor['pale_red'], label='Poiss-Mult')\n",
    "\n",
    "    # Add legend\n",
    "    ax.legend(loc='lower right', fontsize=4)\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative binomial-Dirichlet-multinomial model is able to much better capture\n",
    "the over-dispersion in the data. The challenge is now to work on the\n",
    "computational efficiency of the model to make it feasible for large-scale\n",
    "inference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrappy-jDg5b02t-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
